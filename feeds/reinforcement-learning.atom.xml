<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Δ ℚuantitative √ourney - Reinforcement-Learning</title><link href="/" rel="alternate"></link><link href="/feeds/reinforcement-learning.atom.xml" rel="self"></link><id>/</id><updated>2015-10-30T00:00:00-07:00</updated><entry><title>Q-learning with Neural Networks</title><link href="/rlpart3.html" rel="alternate"></link><published>2015-10-30T00:00:00-07:00</published><updated>2015-10-30T00:00:00-07:00</updated><author><name>outlace</name></author><id>tag:None,2015-10-30:/rlpart3.html</id><summary type="html">&lt;p&gt;In part 3 of the reinforcement learning series we implement a neural network as the action-value function and use the Q-learning algorithm to train an agent how to play Gridworld.&lt;/p&gt;</summary><content type="html">&lt;style type="text/css"&gt;/*!
*
* IPython notebook
*
*/
/* CSS font colors for translated ANSI colors. */
.ansibold {
  font-weight: bold;
}
/* use dark versions for foreground, to improve visibility */
.ansiblack {
  color: black;
}
.ansired {
  color: darkred;
}
.ansigreen {
  color: darkgreen;
}
.ansiyellow {
  color: #c4a000;
}
.ansiblue {
  color: darkblue;
}
.ansipurple {
  color: darkviolet;
}
.ansicyan {
  color: steelblue;
}
.ansigray {
  color: gray;
}
/* and light for background, for the same reason */
.ansibgblack {
  background-color: black;
}
.ansibgred {
  background-color: red;
}
.ansibggreen {
  background-color: green;
}
.ansibgyellow {
  background-color: yellow;
}
.ansibgblue {
  background-color: blue;
}
.ansibgpurple {
  background-color: magenta;
}
.ansibgcyan {
  background-color: cyan;
}
.ansibggray {
  background-color: gray;
}
div.cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  border-radius: 2px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  border-width: 1px;
  border-style: solid;
  border-color: transparent;
  width: 100%;
  padding: 5px;
  /* This acts as a spacer between cells, that is outside the border */
  margin: 0px;
  outline: none;
  border-left-width: 1px;
  padding-left: 5px;
  background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%);
}
div.cell.jupyter-soft-selected {
  border-left-color: #90CAF9;
  border-left-color: #E3F2FD;
  border-left-width: 1px;
  padding-left: 5px;
  border-right-color: #E3F2FD;
  border-right-width: 1px;
  background: #E3F2FD;
}
@media print {
  div.cell.jupyter-soft-selected {
    border-color: transparent;
  }
}
div.cell.selected {
  border-color: #ababab;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%);
}
@media print {
  div.cell.selected {
    border-color: transparent;
  }
}
div.cell.selected.jupyter-soft-selected {
  border-left-width: 0;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%);
}
.edit_mode div.cell.selected {
  border-color: #66BB6A;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%);
}
@media print {
  .edit_mode div.cell.selected {
    border-color: transparent;
  }
}
.prompt {
  /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */
  min-width: 14ex;
  /* This padding is tuned to match the padding on the CodeMirror editor. */
  padding: 0.4em;
  margin: 0px;
  font-family: monospace;
  text-align: right;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
  /* Don't highlight prompt number selection */
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
  /* Use default cursor */
  cursor: default;
}
@media (max-width: 540px) {
  .prompt {
    text-align: left;
  }
}
div.inner_cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
@-moz-document url-prefix() {
  div.inner_cell {
    overflow-x: hidden;
  }
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_area {
  border: 1px solid #cfcfcf;
  border-radius: 2px;
  background: #f7f7f7;
  line-height: 1.21429em;
}
/* This is needed so that empty prompt areas can collapse to zero height when there
   is no content in the output_subarea and the prompt. The main purpose of this is
   to make sure that empty JavaScript output_subareas have no height. */
div.prompt:empty {
  padding-top: 0;
  padding-bottom: 0;
}
div.unrecognized_cell {
  padding: 5px 5px 5px 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.unrecognized_cell .inner_cell {
  border-radius: 2px;
  padding: 5px;
  font-weight: bold;
  color: red;
  border: 1px solid #cfcfcf;
  background: #eaeaea;
}
div.unrecognized_cell .inner_cell a {
  color: inherit;
  text-decoration: none;
}
div.unrecognized_cell .inner_cell a:hover {
  color: inherit;
  text-decoration: none;
}
@media (max-width: 540px) {
  div.unrecognized_cell &gt; div.prompt {
    display: none;
  }
}
div.code_cell {
  /* avoid page breaking on code cells when printing */
}
@media print {
  div.code_cell {
    page-break-inside: avoid;
  }
}
/* any special styling for code cells that are currently running goes here */
div.input {
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.input {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_prompt {
  color: #303F9F;
  border-top: 1px solid transparent;
}
div.input_area &gt; div.highlight {
  margin: 0.4em;
  border: none;
  padding: 0px;
  background-color: transparent;
}
div.input_area &gt; div.highlight &gt; pre {
  margin: 0px;
  border: none;
  padding: 0px;
  background-color: transparent;
}
/* The following gets added to the &lt;head&gt; if it is detected that the user has a
 * monospace font with inconsistent normal/bold/italic height.  See
 * notebookmain.js.  Such fonts will have keywords vertically offset with
 * respect to the rest of the text.  The user should select a better font.
 * See: https://github.com/ipython/ipython/issues/1503
 *
 * .CodeMirror span {
 *      vertical-align: bottom;
 * }
 */
.CodeMirror {
  line-height: 1.21429em;
  /* Changed from 1em to our global default */
  font-size: 14px;
  height: auto;
  /* Changed to auto to autogrow */
  background: none;
  /* Changed from white to allow our bg to show through */
}
.CodeMirror-scroll {
  /*  The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/
  /*  We have found that if it is visible, vertical scrollbars appear with font size changes.*/
  overflow-y: hidden;
  overflow-x: auto;
}
.CodeMirror-lines {
  /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */
  /* we have set a different line-height and want this to scale with that. */
  padding: 0.4em;
}
.CodeMirror-linenumber {
  padding: 0 8px 0 4px;
}
.CodeMirror-gutters {
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.CodeMirror pre {
  /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */
  /* .CodeMirror-lines */
  padding: 0;
  border: 0;
  border-radius: 0;
}
/*

Original style from softwaremaniacs.org (c) Ivan Sagalaev &lt;Maniac@SoftwareManiacs.Org&gt;
Adapted from GitHub theme

*/
.highlight-base {
  color: #000;
}
.highlight-variable {
  color: #000;
}
.highlight-variable-2 {
  color: #1a1a1a;
}
.highlight-variable-3 {
  color: #333333;
}
.highlight-string {
  color: #BA2121;
}
.highlight-comment {
  color: #408080;
  font-style: italic;
}
.highlight-number {
  color: #080;
}
.highlight-atom {
  color: #88F;
}
.highlight-keyword {
  color: #008000;
  font-weight: bold;
}
.highlight-builtin {
  color: #008000;
}
.highlight-error {
  color: #f00;
}
.highlight-operator {
  color: #AA22FF;
  font-weight: bold;
}
.highlight-meta {
  color: #AA22FF;
}
/* previously not defined, copying from default codemirror */
.highlight-def {
  color: #00f;
}
.highlight-string-2 {
  color: #f50;
}
.highlight-qualifier {
  color: #555;
}
.highlight-bracket {
  color: #997;
}
.highlight-tag {
  color: #170;
}
.highlight-attribute {
  color: #00c;
}
.highlight-header {
  color: blue;
}
.highlight-quote {
  color: #090;
}
.highlight-link {
  color: #00c;
}
/* apply the same style to codemirror */
.cm-s-ipython span.cm-keyword {
  color: #008000;
  font-weight: bold;
}
.cm-s-ipython span.cm-atom {
  color: #88F;
}
.cm-s-ipython span.cm-number {
  color: #080;
}
.cm-s-ipython span.cm-def {
  color: #00f;
}
.cm-s-ipython span.cm-variable {
  color: #000;
}
.cm-s-ipython span.cm-operator {
  color: #AA22FF;
  font-weight: bold;
}
.cm-s-ipython span.cm-variable-2 {
  color: #1a1a1a;
}
.cm-s-ipython span.cm-variable-3 {
  color: #333333;
}
.cm-s-ipython span.cm-comment {
  color: #408080;
  font-style: italic;
}
.cm-s-ipython span.cm-string {
  color: #BA2121;
}
.cm-s-ipython span.cm-string-2 {
  color: #f50;
}
.cm-s-ipython span.cm-meta {
  color: #AA22FF;
}
.cm-s-ipython span.cm-qualifier {
  color: #555;
}
.cm-s-ipython span.cm-builtin {
  color: #008000;
}
.cm-s-ipython span.cm-bracket {
  color: #997;
}
.cm-s-ipython span.cm-tag {
  color: #170;
}
.cm-s-ipython span.cm-attribute {
  color: #00c;
}
.cm-s-ipython span.cm-header {
  color: blue;
}
.cm-s-ipython span.cm-quote {
  color: #090;
}
.cm-s-ipython span.cm-link {
  color: #00c;
}
.cm-s-ipython span.cm-error {
  color: #f00;
}
.cm-s-ipython span.cm-tab {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);
  background-position: right;
  background-repeat: no-repeat;
}
div.output_wrapper {
  /* this position must be relative to enable descendents to be absolute within it */
  position: relative;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  z-index: 1;
}
/* class for the output area when it should be height-limited */
div.output_scroll {
  /* ideally, this would be max-height, but FF barfs all over that */
  height: 24em;
  /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */
  width: 100%;
  overflow: auto;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  display: block;
}
/* output div while it is collapsed */
div.output_collapsed {
  margin: 0px;
  padding: 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
div.out_prompt_overlay {
  height: 100%;
  padding: 0px 0.4em;
  position: absolute;
  border-radius: 2px;
}
div.out_prompt_overlay:hover {
  /* use inner shadow to get border that is computed the same on WebKit/FF */
  -webkit-box-shadow: inset 0 0 1px #000;
  box-shadow: inset 0 0 1px #000;
  background: rgba(240, 240, 240, 0.5);
}
div.output_prompt {
  color: #D84315;
}
/* This class is the outer container of all output sections. */
div.output_area {
  padding: 0px;
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.output_area .MathJax_Display {
  text-align: left !important;
}
div.output_area 
div.output_area 
div.output_area img,
div.output_area svg {
  max-width: 100%;
  height: auto;
}
div.output_area img.unconfined,
div.output_area svg.unconfined {
  max-width: none;
}
/* This is needed to protect the pre formating from global settings such
   as that of bootstrap */
.output {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.output_area {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
div.output_area pre {
  margin: 0;
  padding: 0;
  border: 0;
  vertical-align: baseline;
  color: black;
  background-color: transparent;
  border-radius: 0;
}
/* This class is for the output subarea inside the output_area and after
   the prompt div. */
div.output_subarea {
  overflow-x: auto;
  padding: 0.4em;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
  max-width: calc(100% - 14ex);
}
div.output_scroll div.output_subarea {
  overflow-x: visible;
}
/* The rest of the output_* classes are for special styling of the different
   output types */
/* all text output has this class: */
div.output_text {
  text-align: left;
  color: #000;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
}
/* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */
div.output_stderr {
  background: #fdd;
  /* very light red background for stderr */
}
div.output_latex {
  text-align: left;
}
/* Empty output_javascript divs should have no height */
div.output_javascript:empty {
  padding: 0;
}
.js-error {
  color: darkred;
}
/* raw_input styles */
div.raw_input_container {
  line-height: 1.21429em;
  padding-top: 5px;
}
pre.raw_input_prompt {
  /* nothing needed here. */
}
input.raw_input {
  font-family: monospace;
  font-size: inherit;
  color: inherit;
  width: auto;
  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;
  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0em 0.25em;
  margin: 0em 0.25em;
}
input.raw_input:focus {
  box-shadow: none;
}
p.p-space {
  margin-bottom: 10px;
}
div.output_unrecognized {
  padding: 5px;
  font-weight: bold;
  color: red;
}
div.output_unrecognized a {
  color: inherit;
  text-decoration: none;
}
div.output_unrecognized a:hover {
  color: inherit;
  text-decoration: none;
}
.rendered_html {
  color: #000;
  /* any extras will just be numbers: */
}



.rendered_html :link {
  text-decoration: underline;
}
.rendered_html :visited {
  text-decoration: underline;
}






.rendered_html h1:first-child {
  margin-top: 0.538em;
}
.rendered_html h2:first-child {
  margin-top: 0.636em;
}
.rendered_html h3:first-child {
  margin-top: 0.777em;
}
.rendered_html h4:first-child {
  margin-top: 1em;
}
.rendered_html h5:first-child {
  margin-top: 1em;
}
.rendered_html h6:first-child {
  margin-top: 1em;
}








.rendered_html * + ul {
  margin-top: 1em;
}
.rendered_html * + ol {
  margin-top: 1em;
}


.rendered_html pre,



.rendered_html tr,
.rendered_html th,

.rendered_html td,


.rendered_html * + table {
  margin-top: 1em;
}

.rendered_html * + p {
  margin-top: 1em;
}

.rendered_html * + img {
  margin-top: 1em;
}
.rendered_html img,

.rendered_html img.unconfined,

div.text_cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.text_cell &gt; div.prompt {
    display: none;
  }
}
div.text_cell_render {
  /*font-family: "Helvetica Neue", Arial, Helvetica, Geneva, sans-serif;*/
  outline: none;
  resize: none;
  width: inherit;
  border-style: none;
  padding: 0.5em 0.5em 0.5em 0.4em;
  color: #000;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
a.anchor-link:link {
  text-decoration: none;
  padding: 0px 20px;
  visibility: hidden;
}
h1:hover .anchor-link,
h2:hover .anchor-link,
h3:hover .anchor-link,
h4:hover .anchor-link,
h5:hover .anchor-link,
h6:hover .anchor-link {
  visibility: visible;
}
.text_cell.rendered .input_area {
  display: none;
}
.text_cell.rendered 
.text_cell.unrendered .text_cell_render {
  display: none;
}
.cm-header-1,
.cm-header-2,
.cm-header-3,
.cm-header-4,
.cm-header-5,
.cm-header-6 {
  font-weight: bold;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
}
.cm-header-1 {
  font-size: 185.7%;
}
.cm-header-2 {
  font-size: 157.1%;
}
.cm-header-3 {
  font-size: 128.6%;
}
.cm-header-4 {
  font-size: 110%;
}
.cm-header-5 {
  font-size: 100%;
  font-style: italic;
}
.cm-header-6 {
  font-size: 100%;
  font-style: italic;
}
&lt;/style&gt;
&lt;style type="text/css"&gt;.highlight .hll { background-color: #ffffcc }
.highlight  { background: #f8f8f8; }
.highlight .c { color: #408080; font-style: italic } /* Comment */
.highlight .err { border: 1px solid #FF0000 } /* Error */
.highlight .k { color: #008000; font-weight: bold } /* Keyword */
.highlight .o { color: #666666 } /* Operator */
.highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */
.highlight .cp { color: #BC7A00 } /* Comment.Preproc */
.highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */
.highlight .cs { color: #408080; font-style: italic } /* Comment.Special */
.highlight .gd { color: #A00000 } /* Generic.Deleted */
.highlight .ge { font-style: italic } /* Generic.Emph */
.highlight .gr { color: #FF0000 } /* Generic.Error */
.highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.highlight .gi { color: #00A000 } /* Generic.Inserted */
.highlight .go { color: #888888 } /* Generic.Output */
.highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.highlight .gs { font-weight: bold } /* Generic.Strong */
.highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.highlight .gt { color: #0044DD } /* Generic.Traceback */
.highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: #008000 } /* Keyword.Pseudo */
.highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: #B00040 } /* Keyword.Type */
.highlight .m { color: #666666 } /* Literal.Number */
.highlight .s { color: #BA2121 } /* Literal.String */
.highlight .na { color: #7D9029 } /* Name.Attribute */
.highlight .nb { color: #008000 } /* Name.Builtin */
.highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.highlight .no { color: #880000 } /* Name.Constant */
.highlight .nd { color: #AA22FF } /* Name.Decorator */
.highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */
.highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
.highlight .nf { color: #0000FF } /* Name.Function */
.highlight .nl { color: #A0A000 } /* Name.Label */
.highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */
.highlight .nv { color: #19177C } /* Name.Variable */
.highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.highlight .w { color: #bbbbbb } /* Text.Whitespace */
.highlight .mb { color: #666666 } /* Literal.Number.Bin */
.highlight .mf { color: #666666 } /* Literal.Number.Float */
.highlight .mh { color: #666666 } /* Literal.Number.Hex */
.highlight .mi { color: #666666 } /* Literal.Number.Integer */
.highlight .mo { color: #666666 } /* Literal.Number.Oct */
.highlight .sb { color: #BA2121 } /* Literal.String.Backtick */
.highlight .sc { color: #BA2121 } /* Literal.String.Char */
.highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.highlight .s2 { color: #BA2121 } /* Literal.String.Double */
.highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
.highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */
.highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
.highlight .sx { color: #008000 } /* Literal.String.Other */
.highlight .sr { color: #BB6688 } /* Literal.String.Regex */
.highlight .s1 { color: #BA2121 } /* Literal.String.Single */
.highlight .ss { color: #19177C } /* Literal.String.Symbol */
.highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */
.highlight .vc { color: #19177C } /* Name.Variable.Class */
.highlight .vg { color: #19177C } /* Name.Variable.Global */
.highlight .vi { color: #19177C } /* Name.Variable.Instance */
.highlight .il { color: #666666 } /* Literal.Number.Integer.Long */&lt;/style&gt;
&lt;style type="text/css"&gt;
/* Temporary definitions which will become obsolete with Notebook release 5.0 */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-bold { font-weight: bold; }
&lt;/style&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Learning-Gridworld-with-Q-learning"&gt;Learning Gridworld with Q-learning&lt;a class="anchor-link" href="#Learning-Gridworld-with-Q-learning"&gt;¶&lt;/a&gt;&lt;/h3&gt;&lt;h4 id="Introduction"&gt;Introduction&lt;a class="anchor-link" href="#Introduction"&gt;¶&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;We've finally made it. We've made it to what we've all been waiting for, Q-learning with neural networks. Since I'm sure a lot of people didn't follow parts 1 and 2 because they were kind of boring, I will attempt to make this post relatively (but not completely) self-contained. In this post, we will dive into using Q-learning to train an agent (player) how to play Gridworld. Gridworld is a simple text based game in which there is a 4x4 grid of tiles and 4 objects placed therein: a player, pit, goal, and a wall. The player can move up/down/left/right ($a \in A \{up,down,left,right\}$) and the point of the game is to get to the goal where the player will receive a numerical reward. Unfortunately, we have to avoid a pit, because if we land on the pit we are penalized with a negative 'reward'. As if our task wasn't difficult enough, there's also a wall that can block the player's path (but it offers no reward or penalty).&lt;/p&gt;
&lt;p&gt;&lt;img src="images/RL/gridworld.png" /&gt;&lt;/p&gt;
&lt;h4 id="Quick-Review-of-Terms-and-Concepts-(skip-if-you-followed-parts-1-&amp;amp;-2)"&gt;Quick Review of Terms and Concepts (skip if you followed parts 1 &amp; 2)&lt;a class="anchor-link" href="#Quick-Review-of-Terms-and-Concepts-(skip-if-you-followed-parts-1-&amp;amp;-2)"&gt;¶&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;A state is all the information necessary (e.g. pixel data in a game) to make a decision that you expect will take you to a new (higher value) state. The high level function of reinforcement learning is to learn the values of states or state-action pairs (the value of taking action $a$ given we're in state $s$). The value is some notion of how "good" that state or action is. Generally this is a function of rewards received now or in the future as a result of taking some action or being in some state.&lt;/p&gt;
&lt;p&gt;A policy, denoted $\pi$, is the specific strategy we take in order to get into high value states or take high value actions to maximize our rewards over time. For example, a policy in blackjack might be to always hit until we have 19. We denote a function, $\pi(s)$ that accepts a state $s$ and returns the action to be taken. Generally $\pi(s)$ as a function just evaluates the value of all possible actions given the state $s$ and returns the highest value action. This will result in a specific policy $\pi$ that may change over time as we improve our value estimates.&lt;/p&gt;
&lt;p&gt;We call the function that accepts a state $s$ and returns the value of that state $v_{\pi}(s)$. This is the value function. Similarly, there is an action-value function $Q(s, a)$ that accepts a state $s$ and an action $a$ and returns the value of taking that action given that state. Some RL algorithms or implementations will use one or the other. Importantly, if we base our algorithm on learning state-values (as opposed to action-values), we must keep in mind that the value of a state depends completely on our policy $\pi$. Using blackjack as an example, if we're in the state of having a card total of 20, and have two possible actions, hit or stay, the value of this state is only high if our policy says to stay when we have 20. If our policy said to hit when we have 20, we would probably bust and lose the game, thus the value of that state would be low. More formally, the value of a state is equivalent to the value of the highest action taken in that state.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h4 id="What-is-Q-learning?"&gt;What is Q-learning?&lt;a class="anchor-link" href="#What-is-Q-learning?"&gt;¶&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;Q-learning, like virtually all RL methods, is one type of algorithm used to calculate state-action values. It falls under the class of &lt;em&gt;temporal difference&lt;/em&gt; (TD) algorithms, which suggests that time differences between actions taken and rewards received are involved.&lt;/p&gt;
&lt;p&gt;In part 2 where we used a Monte Carlo method to learn to play blackjack, we had to wait until the end of a game (episode) to update our state-action values. With TD algorithms, we make updates after every action taken. In most cases, that makes more sense. We make a prediction (based on previous experience), take an action based on that prediction, receive a reward and then update our prediction.&lt;/p&gt;
&lt;p&gt;(Btw: Don't confuse the "Q" in Q-learning with the $Q$ function we've discussed in the previous parts. The $Q$ function is always the name of the function that accepts states and actions and spits out the value of that state-action pair. RL methods involve a $Q$ function but aren't necessarily Q-learning algorithms.)&lt;/p&gt;
&lt;p&gt;Here's the tabular Q-learning update rule:
$$Q(S_t, A_t) \leftarrow Q(S_t, A_t) + \alpha[R_{t+1} + \gamma maxQ(S_{t+1}, a_{t+1}) - Q(S_t, A_t)]$$&lt;/p&gt;
&lt;p&gt;So, like Monte Carlo, we could have a table that stores the Q-value for every possible state-action pair and iteratively update this table as we play games. Our policy $\pi$ would be based on choosing the action with the highest Q value for that given state.&lt;/p&gt;
&lt;p&gt;But we're done with tables. This is 2015, we have GPUs and stuff. Well, as I alluded to in part 2, our $Q(s,a)$ function doesn't have to just be a lookup table. In fact, in most interesting problems, our state-action space is much too large to store in a table. Imagine a very simplified game of Pacman. If we implement it as a graphics-based game, the state would be the raw pixel data. In a tabular method, if the pixel data changes by just a single pixel, we have to store that as a completely separate entry in the table. Obviously that's silly and wasteful. What we need is some way to generalize and pattern match between states. We need our algorithm to say "the value of these &lt;em&gt;kind&lt;/em&gt; of states is X" rather than "the value of this exact, super specific state is X."&lt;/p&gt;
&lt;p&gt;That's where neural networks come in. Or any other type of function approximator, even a simple linear model. We can use a neural network, instead of a lookup table, as our $Q(s,a)$ function. Just like before, it will accept a state and an action and spit out the value of that state-action.&lt;/p&gt;
&lt;p&gt;Importantly, however, unlike a lookup table, a neural network also has a bunch of parameters associated with it. These are the weights. So our $Q$ function actually looks like this: $Q(s, a, \theta)$ where $\theta$ is a vector of parameters. And instead of iteratively updating values in a table, we will iteratively update the $\theta$ parameters of our neural network so that it learns to provide us with better estimates of state-action values.&lt;/p&gt;
&lt;p&gt;Of course we can use gradient descent (backpropagation) to train our $Q$ neural network just like any other neural network.&lt;/p&gt;
&lt;p&gt;But what's our target &lt;code&gt;y&lt;/code&gt; vector (expected output vector)? Since the net is not a table, we don't use the formula shown above, our target is simply: $r_{t+1} + \gamma * maxQ(s', a')$ for the state-action that just happened. $\gamma$ is a parameter $0\rightarrow1$ that is called the &lt;em&gt;discount factor&lt;/em&gt;. Basically it determines how much each future reward is taken into consideration for updating our Q-value. If $\gamma$ is close to 0, we heavily discount future rewards and thus mostly care about immediate rewards.  $s'$ refers to the new state after having taken action $a$ and $a'$ refers to the next actions possible in this new state. So $maxQ(s', a')$ means we calculate all the Q-values for each state-action pair in the new state, and take the maximium value to use in our new value update. (Note I may use $s' \text{ and } a'$ interchangeably with $s_{t+1} \text{ and } a_{t+1}$.)&lt;/p&gt;
&lt;p&gt;One important note: our reward update for every state-action pair is $r_{t+1} + \gamma*maxQ(s_{t+1}, a)$ &lt;strong&gt;except&lt;/strong&gt; when the state $s'$ is a terminal state. When we've reached a terminal state, the reward update is simply $r_{t+1}$. A terminal state is the last state in an episode. In our case, there are 2 terminal states: the state where the player fell into the pit (and receives -10) and the state where the player has reached the goal (and receives +10). Any other state is non-terminal and the game is still in progress.&lt;/p&gt;
&lt;p&gt;There are two keywords I need to mention as well: &lt;strong&gt;on-policy&lt;/strong&gt; and &lt;strong&gt;off-policy&lt;/strong&gt; methods. In on-policy methods we iteratively learn about state values at the same time that we improve our policy. In other words, the updates to our state values depend on the policy. In contrast, off-policy methods do not depend on the policy to update the value function. Q-learning is an off-policy method. It's advantageous because with off-policy methods, we can follow one policy while learning about another. For example, with Q-learning, we could always take completely random actions and yet we would still learn about another policy function of taking the best actions in every state. If there's ever a $\pi$ referenced in the value update part of the algorithm then it's an on-policy method.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Gridworld-Details"&gt;Gridworld Details&lt;a class="anchor-link" href="#Gridworld-Details"&gt;¶&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Before we get too deep into the neural network Q-learning stuff, let's discuss the Gridworld game implementation that we're using as our toy problem.&lt;/p&gt;
&lt;p&gt;We're going to implement 3 variants of the game in order of increasing difficulty. The first version will initialize a grid in exactly the same way each time. That is, every new game starts with the player (P), goal (+), pit (-), and wall (W) in exactly the same positions. Thus the algorithm just needs to learn how to take the player from a known starting position to a known end position without hitting the pit, which gives out negative rewards.&lt;/p&gt;
&lt;p&gt;The second implementation is slightly more difficult. The goal, pit and wall will always be initialized in the same positions, but the player will be placed randomly on the grid on each new game. The third implementation is the most difficult to learn, and that's where all elements are randomly placed on the grid each game.&lt;/p&gt;
&lt;p&gt;Let's get to coding.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In [1]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;randPair&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;randint&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;randint&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;#finds an array in the "depth" dimension of the grid&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;findLoc&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;obj&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;j&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;obj&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;all&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
                &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;j&lt;/span&gt;

&lt;span class="c1"&gt;#Initialize stationary grid, all items are placed deterministically&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;initGrid&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="n"&gt;state&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="c1"&gt;#place player&lt;/span&gt;
    &lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="c1"&gt;#place wall&lt;/span&gt;
    &lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="c1"&gt;#place pit&lt;/span&gt;
    &lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="c1"&gt;#place goal&lt;/span&gt;
    &lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;state&lt;/span&gt;

&lt;span class="c1"&gt;#Initialize player in random location, but keep wall, goal and pit stationary&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;initGridPlayer&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="n"&gt;state&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="c1"&gt;#place player&lt;/span&gt;
    &lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;randPair&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="c1"&gt;#place wall&lt;/span&gt;
    &lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="c1"&gt;#place pit&lt;/span&gt;
    &lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="c1"&gt;#place goal&lt;/span&gt;
    &lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    
    &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;findLoc&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt; &lt;span class="c1"&gt;#find grid position of player (agent)&lt;/span&gt;
    &lt;span class="n"&gt;w&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;findLoc&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt; &lt;span class="c1"&gt;#find wall&lt;/span&gt;
    &lt;span class="n"&gt;g&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;findLoc&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt; &lt;span class="c1"&gt;#find goal&lt;/span&gt;
    &lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;findLoc&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt; &lt;span class="c1"&gt;#find pit&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="ow"&gt;or&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="n"&gt;w&lt;/span&gt; &lt;span class="ow"&gt;or&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="n"&gt;g&lt;/span&gt; &lt;span class="ow"&gt;or&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="c1"&gt;#print('Invalid grid. Rebuilding..')&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;initGridPlayer&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;state&lt;/span&gt;

&lt;span class="c1"&gt;#Initialize grid so that goal, pit, wall, player are all randomly placed&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;initGridRand&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="n"&gt;state&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="c1"&gt;#place player&lt;/span&gt;
    &lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;randPair&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="c1"&gt;#place wall&lt;/span&gt;
    &lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;randPair&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="c1"&gt;#place pit&lt;/span&gt;
    &lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;randPair&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="c1"&gt;#place goal&lt;/span&gt;
    &lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;randPair&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    
    &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;findLoc&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
    &lt;span class="n"&gt;w&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;findLoc&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
    &lt;span class="n"&gt;g&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;findLoc&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
    &lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;findLoc&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
    &lt;span class="c1"&gt;#If any of the "objects" are superimposed, just call the function again to re-place&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="ow"&gt;or&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="n"&gt;w&lt;/span&gt; &lt;span class="ow"&gt;or&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="n"&gt;g&lt;/span&gt; &lt;span class="ow"&gt;or&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="c1"&gt;#print('Invalid grid. Rebuilding..')&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;initGridRand&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;state&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;The state is a 3-dimensional numpy array (4x4x4). You can think of the first two dimensions as the positions on the board; e.g. row 1, column 2 is the position (1,2) [zero indexed] on the board. The 3rd dimension encodes the object/element at that position. Since there are 4 different possible objects, the 3rd dimension of the state contains vectors of length 4. We're using a one-hot encoding for the elements except that the empty position is just a vector of all zeros. So with a 4 length vector we're encoding 5 possible options at each grid position: empty, player, goal, pit, or wall.&lt;/p&gt;
&lt;p&gt;You can also think of the 3rd dimension as being divided into 4 separate grid planes, where each plane represents the position of each element. So below is an example where the player is at grid position (3,0), the wall is at (0,0), the pit is at (0,1) and the goal is at (1,0). [All other elements are 0s]&lt;/p&gt;
&lt;p&gt;&lt;img src="images/RL/gridpositions.png" width="300px" /&gt;&lt;/p&gt;
&lt;p&gt;In our simple implementation it's possible for the board to be initialized such that some of the objects contain a 1 at the same "x,y" position (but different "z" positions), which indicates they're at the same position on the grid. Obviously we don't want to initialize the board in this way, so for the last 2 variants of the game that involve some element of random initialization, we check if we can find "clean" arrays (only one "1" in the 'Z' dimension of a particular grid position) of the various element types on the grid and if not, we just recursively call the initialize grid function until we get a state where elements are not superimposed.&lt;/p&gt;
&lt;p&gt;When the player successfully plays the game and lands on the goal, the player and goal positions &lt;em&gt;will&lt;/em&gt; be superimposed and that is how we know the player has won (likewise if the player hits the pit and loses). The wall is supposed to block the movement of the player so we prevent the player from taking an action that would place them at the same position as the wall. Additionally, the grid is "enclosed" so that player cannot walk through the edges of the grid.&lt;/p&gt;
&lt;p&gt;Now we will implement the movement function.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In [2]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;makeMove&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;action&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="c1"&gt;#need to locate player in grid&lt;/span&gt;
    &lt;span class="c1"&gt;#need to determine what object (if any) is in the new grid spot the player is moving to&lt;/span&gt;
    &lt;span class="n"&gt;player_loc&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;findLoc&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
    &lt;span class="n"&gt;wall&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;findLoc&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
    &lt;span class="n"&gt;goal&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;findLoc&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
    &lt;span class="n"&gt;pit&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;findLoc&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
    &lt;span class="n"&gt;state&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    
    &lt;span class="c1"&gt;#up (row - 1)&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;action&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;new_loc&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;player_loc&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;player_loc&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;new_loc&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="n"&gt;wall&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;new_loc&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&lt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;all&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;new_loc&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;all&lt;/span&gt;&lt;span class="p"&gt;()):&lt;/span&gt;
                &lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;new_loc&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
    &lt;span class="c1"&gt;#down (row + 1)&lt;/span&gt;
    &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="n"&gt;action&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;new_loc&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;player_loc&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;player_loc&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;new_loc&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="n"&gt;wall&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;new_loc&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&lt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;all&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;new_loc&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;all&lt;/span&gt;&lt;span class="p"&gt;()):&lt;/span&gt;
                &lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;new_loc&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
    &lt;span class="c1"&gt;#left (column - 1)&lt;/span&gt;
    &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="n"&gt;action&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;new_loc&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;player_loc&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;player_loc&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;new_loc&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="n"&gt;wall&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;new_loc&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&lt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;all&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;new_loc&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;all&lt;/span&gt;&lt;span class="p"&gt;()):&lt;/span&gt;
                &lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;new_loc&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
    &lt;span class="c1"&gt;#right (column + 1)&lt;/span&gt;
    &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="n"&gt;action&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;new_loc&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;player_loc&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;player_loc&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;new_loc&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="n"&gt;wall&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;new_loc&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&lt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;all&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;new_loc&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;all&lt;/span&gt;&lt;span class="p"&gt;()):&lt;/span&gt;
                &lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;new_loc&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
                
    &lt;span class="n"&gt;new_player_loc&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;findLoc&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="n"&gt;new_player_loc&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;player_loc&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="c1"&gt;#re-place pit&lt;/span&gt;
    &lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;pit&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
    &lt;span class="c1"&gt;#re-place wall&lt;/span&gt;
    &lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;wall&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
    &lt;span class="c1"&gt;#re-place goal&lt;/span&gt;
    &lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;goal&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
    
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;state&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;The first thing we do is try to find the positions of each element on the grid (state). Then it's just a few simple if-conditions. We need to make sure the player isn't trying to step on the wall and make sure that the player isn't stepping outside the bounds of the grid.&lt;/p&gt;
&lt;p&gt;Now we implement &lt;code&gt;getLoc&lt;/code&gt; which is similar to &lt;code&gt;findLoc&lt;/code&gt; but can identify superimposed elements, whereas &lt;code&gt;findLoc&lt;/code&gt; would miss it (intentionally) if there was superimposition. Additionally, we'll implement our reward function, which will award +10 if the player steps onto the goal, -10 if the player steps into the pit, and -1 for any other move. These rewards are pretty arbitrary, as long as the goal has a significantly higher reward than the pit, the algorithm should do fine.&lt;/p&gt;
&lt;p&gt;Lastly, I've implemented a function that will display our grid as a text array so we can see what's going on.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In [3]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;getLoc&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;level&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;j&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="n"&gt;level&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
                &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;j&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;getReward&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;player_loc&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;getLoc&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;pit&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;getLoc&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;goal&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;getLoc&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;player_loc&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;pit&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;
    &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;player_loc&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;goal&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;
    
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;dispGrid&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;grid&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'&lt;u2&amp;#x27;&amp;lt; span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;player_loc&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;findLoc&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
    &lt;span class="n"&gt;wall&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;findLoc&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
    &lt;span class="n"&gt;goal&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;findLoc&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
    &lt;span class="n"&gt;pit&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;findLoc&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;j&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="n"&gt;grid&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;' '&lt;/span&gt;
            
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;player_loc&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;grid&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;player_loc&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'P'&lt;/span&gt; &lt;span class="c1"&gt;#player&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;wall&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;grid&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;wall&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'W'&lt;/span&gt; &lt;span class="c1"&gt;#wall&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;goal&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;grid&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;goal&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'+'&lt;/span&gt; &lt;span class="c1"&gt;#goal&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;pit&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;grid&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;pit&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'-'&lt;/span&gt; &lt;span class="c1"&gt;#pit&lt;/span&gt;
    
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;grid&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;And that's it. That's the entire gridworld game implementation. Not too bad right? As with my part 2 blackjack implementation, this game is not using OOP-style and implemented in a functional style where we just pass around states.&lt;/p&gt;
&lt;p&gt;Let's demonstrate some gameplay. I'll be using the &lt;code&gt;initGridRand()&lt;/code&gt; variant so that all items are placed randomly.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In [422]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;initGridRand&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;dispGrid&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;&lt;div class="prompt output_prompt"&gt;Out[422]:&lt;/div&gt;
&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;array([['P', '-', ' ', ' '],
       [' ', ' ', ' ', ' '],
       [' ', ' ', 'W', ' '],
       [' ', '+', ' ', ' ']], 
      dtype='&lt;u2&amp;#x27;)&amp;lt; pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;As you can see, I clearly need to move 3 spaces down, and 1 space to the right to land on the goal.
Remember, our action encoding is: 0 = up, 1 = down, 2 = left, 3 = right.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In [423]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;makeMove&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;state&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;makeMove&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;state&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;makeMove&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;state&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;makeMove&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Reward: &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;getReward&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;),))&lt;/span&gt;
&lt;span class="n"&gt;dispGrid&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;&lt;div class="prompt"&gt;&lt;/div&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;Reward: 10
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_area"&gt;&lt;div class="prompt output_prompt"&gt;Out[423]:&lt;/div&gt;
&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;array([[' ', '-', ' ', ' '],
       [' ', ' ', ' ', ' '],
       [' ', ' ', 'W', ' '],
       [' ', ' ', ' ', ' ']], 
      dtype='&lt;u2&amp;#x27;)&amp;lt; pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;We haven't implemented a display for when the player is on the goal or pit so the player and goal just disappear when that happens.&lt;/p&gt;
&lt;h3 id="Neural-Network-as-our-Q-function"&gt;Neural Network as our Q function&lt;a class="anchor-link" href="#Neural-Network-as-our-Q-function"&gt;¶&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Now for the fun part. Let's build our neural network that will serve as our $Q$ function. Since this is a post about Q-learning, I'm not going to code a neural network from scratch. I'm going to use the fairly popular Theano-based library Keras. You can of course use whatever library you want, or roll your own.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Important Note&lt;/strong&gt;:
Up until now, I've been talking about how the neural network can serve the role of $Q(s, a)$, and that's absolutely true. However, I will be implementing our neural network in the same way that Google DeepMind did for its Atari playing algorithm. Instead of a neural network architecture that accepts a state and an action as inputs and outputs the value of that single state-action pair, DeepMind built a network that just accepts a state and outputs separate Q-values for each possible action in its output layer. This is pretty clever because in Q-learning we need to get the $maxQ(s', a')$ [max of the Q values for every possible action in the new state s']. Rather than having to run our network forward for every action, we just need to run it forward once. The result is the same, however, it's just more efficient.&lt;/p&gt;
&lt;p&gt;&lt;img src="images/RL/rl3net.png" /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In [4]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;keras.models&lt;/span&gt; &lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Sequential&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;keras.layers.core&lt;/span&gt; &lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Dense&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Dropout&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Activation&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;keras.optimizers&lt;/span&gt; &lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="n"&gt;RMSprop&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In [20]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Sequential&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Dense&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;164&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;init&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'lecun_uniform'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;input_shape&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;64&lt;/span&gt;&lt;span class="p"&gt;,)))&lt;/span&gt;
&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Activation&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'relu'&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="c1"&gt;#model.add(Dropout(0.2)) I'm not using dropout, but maybe you wanna give it a try?&lt;/span&gt;

&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Dense&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;150&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;init&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'lecun_uniform'&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Activation&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'relu'&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="c1"&gt;#model.add(Dropout(0.2))&lt;/span&gt;

&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Dense&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;init&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'lecun_uniform'&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Activation&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'linear'&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="c1"&gt;#linear output so we can have range of real-valued outputs&lt;/span&gt;

&lt;span class="n"&gt;rms&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;RMSprop&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;compile&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;loss&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'mse'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;optimizer&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;rms&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In [384]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;64&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;#just to show an example output; read outputs left to right: up/down/left/right&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;&lt;div class="prompt output_prompt"&gt;Out[384]:&lt;/div&gt;
&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;array([[-0.02812552, -0.04649779, -0.08819015, -0.00723661]])&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;So that's the network I've designed. An input layer of 64 units (because our state has a total of 64 elements, remember its a 4x4x4 numpy array), 2 hidden layers of 164 and 150 units, and an output layer of 4, one for each of our possible actions (up, down, left, right) [in that order].&lt;/p&gt;
&lt;p&gt;Why did I make the network like this? Honestly, I have no good answer for that. I just messed around with different hidden layer architectures and this one seemed to work fairly well. Feel free to change it up. There's probably a better configuration. (If you discover or know of a much better network architecture for this, let me know).&lt;/p&gt;
&lt;h3 id="Online-Training"&gt;Online Training&lt;a class="anchor-link" href="#Online-Training"&gt;¶&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Below is the implementation for the main loop of the algorithm. In broad strokes:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Setup a for-loop to number of epochs&lt;/li&gt;
&lt;li&gt;In the loop, setup while loop (while game is in progress)&lt;/li&gt;
&lt;li&gt;Run Q network forward.&lt;/li&gt;
&lt;li&gt;We're using an epsilon greedy implementation, so at time &lt;em&gt;t&lt;/em&gt; with probability $\epsilon$ we will choose a random action. With probability $1-\epsilon$ we will choose the action associated with the highest Q value from our neural network.&lt;/li&gt;
&lt;li&gt;Take action $a$ as determined in (4), observe new state $s'$ and reward $r_{t+1}$&lt;/li&gt;
&lt;li&gt;Run the network forward using $s'$. Store the highest Q value (&lt;code&gt;maxQ&lt;/code&gt;).&lt;/li&gt;
&lt;li&gt;Our target value to train the network is &lt;code&gt;reward + (gamma * maxQ)&lt;/code&gt; where &lt;code&gt;gamma&lt;/code&gt; is a parameter ($0 &lt;= \gamma &lt;= 1$).&lt;/li&gt;
&lt;li&gt;Given that we have 4 outputs and we only want to update/train the output associated with the action we just took, our target output vector is the same as the output vector from the first run, except we change the one output associated with our action to: &lt;code&gt;reward + (gamma * maxQ)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Train the model on this 1 sample. Repeat process 2-9&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Just to be clear, when we first run our neural network and get an output of action-values like this&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.02812552&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.04649779&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.08819015&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.00723661&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;our target vector for one iteration may look like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.02812552&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.04649779&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.00723661&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Also note, I initialize epsilon (for the $\epsilon$-greedy action selection) to be 1. It decrements by a small amount on every iteration and will eventually reach 0.1 where it stays. Google DeepMind also used an $\epsilon$-greedy action selection and also initialized epsilon to be 1 and decremented during the game play.
if taking action 2 one step (left) resulted in reaching the goal. So we just keep all other outputs the same as before and just change the one for the action we took.&lt;/p&gt;
&lt;p&gt;Okay, so let's go ahead and train our algorithm to learn the easiest variant of the game, where all elements are placed deterministically at the same positions every time.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In [29]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;IPython.display&lt;/span&gt; &lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="n"&gt;clear_output&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;random&lt;/span&gt;

&lt;span class="n"&gt;epochs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1000&lt;/span&gt;
&lt;span class="n"&gt;gamma&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.9&lt;/span&gt; &lt;span class="c1"&gt;#since it may take several moves to goal, making gamma high&lt;/span&gt;
&lt;span class="n"&gt;epsilon&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;epochs&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    
    &lt;span class="n"&gt;state&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;initGrid&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;status&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
    &lt;span class="c1"&gt;#while game still in progress&lt;/span&gt;
    &lt;span class="k"&gt;while&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;status&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="c1"&gt;#We are in state S&lt;/span&gt;
        &lt;span class="c1"&gt;#Let's run our Q function on S to get Q values for all possible actions&lt;/span&gt;
        &lt;span class="n"&gt;qval&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;64&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;&lt;&lt;/span&gt; &lt;span class="n"&gt;epsilon&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="c1"&gt;#choose random action&lt;/span&gt;
            &lt;span class="n"&gt;action&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;randint&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="c1"&gt;#choose best action from Q(s,a) values&lt;/span&gt;
            &lt;span class="n"&gt;action&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argmax&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;qval&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
        &lt;span class="c1"&gt;#Take action, observe new state S'&lt;/span&gt;
        &lt;span class="n"&gt;new_state&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;makeMove&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;action&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="c1"&gt;#Observe reward&lt;/span&gt;
        &lt;span class="n"&gt;reward&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;getReward&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;new_state&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="c1"&gt;#Get max_Q(S',a)&lt;/span&gt;
        &lt;span class="n"&gt;newQ&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;new_state&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;64&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;maxQ&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;max&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;newQ&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
        &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;[:]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;qval&lt;/span&gt;&lt;span class="p"&gt;[:]&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;reward&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="c1"&gt;#non-terminal state&lt;/span&gt;
            &lt;span class="n"&gt;update&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;reward&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;gamma&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;maxQ&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="c1"&gt;#terminal state&lt;/span&gt;
            &lt;span class="n"&gt;update&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;reward&lt;/span&gt;
        &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="n"&gt;action&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;update&lt;/span&gt; &lt;span class="c1"&gt;#target output&lt;/span&gt;
        &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Game #: &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,))&lt;/span&gt;
        &lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;64&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;nb_epoch&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;verbose&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;state&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;new_state&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;reward&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;status&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
        &lt;span class="n"&gt;clear_output&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;wait&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;epsilon&lt;/span&gt; &lt;span class="o"&gt;&gt;&lt;/span&gt; &lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;epsilon&lt;/span&gt; &lt;span class="o"&gt;-=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;epochs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;&lt;div class="prompt"&gt;&lt;/div&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;Game #: 999
Epoch 1/1
1/1 [==============================] - 0s - loss: 0.0265
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Alright, so I've empirically tested this and it trains on the easy variant with just 1000 epochs (keep in mind every epoch is a full game played to completion). Below I've implemented a function we can use to test our trained algorithm to see if it has properly learned how to play the game. It basically just uses the neural network model to calculate action-values for the current state and selects the action with the highest Q-value. It just repeats this forever until the game is won or lost. I've made it break out of this loop if it is making more than 10 moves because this probably means it hasn't learned how to win and we don't want an infinite loop running.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In [6]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;testAlgo&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;init&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;init&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;state&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;initGrid&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="n"&gt;init&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;state&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;initGridPlayer&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="n"&gt;init&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;state&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;initGridRand&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Initial State:"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dispGrid&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;status&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
    &lt;span class="c1"&gt;#while game still in progress&lt;/span&gt;
    &lt;span class="k"&gt;while&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;status&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;qval&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;64&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;action&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argmax&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;qval&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="c1"&gt;#take action with highest Q-value&lt;/span&gt;
        &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Move #: &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s1"&gt;; Taking action: &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;action&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
        &lt;span class="n"&gt;state&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;makeMove&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;action&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dispGrid&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
        &lt;span class="n"&gt;reward&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;getReward&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;reward&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;status&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
            &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Reward: &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;reward&lt;/span&gt;&lt;span class="p"&gt;,))&lt;/span&gt;
        &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="c1"&gt;#If we're taking more than 10 actions, just stop, we probably can't win this game&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;&gt;&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Game lost; too many moves."&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="k"&gt;break&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In [30]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;testAlgo&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;init&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;&lt;div class="prompt"&gt;&lt;/div&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;Initial State:
[[' ' 'P' ' ' ' ']
 [' ' '-' ' ' ' ']
 [' ' ' ' 'W' ' ']
 [' ' ' ' ' ' '+']]
Move #: 0; Taking action: 3
[[' ' ' ' 'P' ' ']
 [' ' '-' ' ' ' ']
 [' ' ' ' 'W' ' ']
 [' ' ' ' ' ' '+']]
Move #: 1; Taking action: 3
[[' ' ' ' ' ' 'P']
 [' ' '-' ' ' ' ']
 [' ' ' ' 'W' ' ']
 [' ' ' ' ' ' '+']]
Move #: 2; Taking action: 1
[[' ' ' ' ' ' ' ']
 [' ' '-' ' ' 'P']
 [' ' ' ' 'W' ' ']
 [' ' ' ' ' ' '+']]
Move #: 3; Taking action: 1
[[' ' ' ' ' ' ' ']
 [' ' '-' ' ' ' ']
 [' ' ' ' 'W' 'P']
 [' ' ' ' ' ' '+']]
Move #: 4; Taking action: 1
[[' ' ' ' ' ' ' ']
 [' ' '-' ' ' ' ']
 [' ' ' ' 'W' ' ']
 [' ' ' ' ' ' ' ']]
Reward: 10
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Can we get a round of applause for our gridworld player here? Clearly it knows what its doing; it went straight for the prize!&lt;/p&gt;
&lt;h3 id="Playing-the-the-harder-variant,-catastrophic-forgetting,-and-experience-replay"&gt;Playing the the harder variant, catastrophic forgetting, and experience replay&lt;a class="anchor-link" href="#Playing-the-the-harder-variant,-catastrophic-forgetting,-and-experience-replay"&gt;¶&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;We're slowly building up our chops and we want our algorithm to train on the harder variant of the game where every new game the player is randomly placed on the grid. It can't just memorize a sequence of steps to take as before, it needs to be able to take the shortest path to the goal (without stepping into the pit) from wherever it starts on the grid. It needs to develop a slightly more sophisticated representation of its environment.&lt;/p&gt;
&lt;p&gt;Unfortunately, there is a problem we may need to deal with as our problem becomes increasingly more difficult. There is a known problem called &lt;strong&gt;catastrophic forgetting&lt;/strong&gt; that is associated with gradient descent based training methods in online training.&lt;/p&gt;
&lt;p&gt;Imagine that in game #1 that our algorithm is training on (learning Q-values for) the player is placed in between the pit and the goal such that the goal is on the right and the pit is on the left. Using epsilon-greedy strategy, the player takes a random move and by chance takes a step to the right and hits the goal. Great, the algorithm will try to learn that this state-action pair is associated with a high reward by updating its weights in such a way that the output will more closely match the target value (i.e backpropagation). Now, the second game gets initialized and the player is again in between the goal and pit but this time the goal is on the &lt;em&gt;left&lt;/em&gt; and the pit is on the right. Perhaps to our naive algorithm, the state &lt;em&gt;seems&lt;/em&gt; very similar to the last game.  Let's say that again, the player chooses to make one step to the right, but this time it ends up in the pit and gets -10 reward. The player is thinking "what the hell I thought going to the right was the best decision based on my previous experience." So now it may do backpropagation again to update its state-action value but because this state-action is very similar to the last learned state-action it may mess up its previously learned weights.&lt;/p&gt;
&lt;p&gt;This is the essence of catastrophic forgetting. There's a push-pull between very similar state-actions (but with divergent targets) that results in this inability to properly learn anything. We generally don't have this problem in the supervised learning realm because we do randomized batch learning, where we don't update our weights until we've iterated through some random subset of our training data.&lt;/p&gt;
&lt;p&gt;Catastrophic forgetting is probably not something we have to worry about with the first variant of our game because the targets are always stationary; but with the harder variants, it's something we should consider, and that is why I'm implementing something called &lt;strong&gt;experience replay&lt;/strong&gt;. Experience replay basically gives us minibatch updating in an online learning scheme. It's actually not a huge deal to implement; here's how it works.&lt;/p&gt;
&lt;p&gt;Experience replay:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;In state $s$, take action $a$, observe new state $s_{t+1}$ and reward $r_{t+1}$&lt;/li&gt;
&lt;li&gt;Store this as a tuple $(s, a, s_{t+1}, r_{t+1})$ in a list.&lt;/li&gt;
&lt;li&gt;Continue to store each experience in this list until we have filled the list to a specific length (up to you to define)&lt;/li&gt;
&lt;li&gt;Once the experience replay memory is filled, randomly select a subset (e.g. 40)&lt;/li&gt;
&lt;li&gt;Iterate through this subset and calculate value updates for each; store these in a target array (e.g. &lt;code&gt;y_train&lt;/code&gt;) and store the state $s$ of each memory in &lt;code&gt;X_train&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Use &lt;code&gt;X_train&lt;/code&gt; and &lt;code&gt;y_train&lt;/code&gt; as a minibatch for batch training. For subsequent epochs where the array is full, just overwrite old values in our experience replay memory array.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Thus, in addition to learning the action-value for the action we just took, we're also going to use a random sample of our past experiences to train on to prevent catastrophic forgetting.&lt;/p&gt;
&lt;p&gt;So here's the same training algorithm from above except with experience replay added. Remember, this time we're training it on the harder variant of the game where the player is randomly placed on the grid.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In [21]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;compile&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;loss&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'mse'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;optimizer&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;rms&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="c1"&gt;#reset weights of neural network&lt;/span&gt;
&lt;span class="n"&gt;epochs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;3000&lt;/span&gt;
&lt;span class="n"&gt;gamma&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.975&lt;/span&gt;
&lt;span class="n"&gt;epsilon&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
&lt;span class="n"&gt;batchSize&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;40&lt;/span&gt;
&lt;span class="n"&gt;buffer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;80&lt;/span&gt;
&lt;span class="n"&gt;replay&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
&lt;span class="c1"&gt;#stores tuples of (S, A, R, S')&lt;/span&gt;
&lt;span class="n"&gt;h&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;epochs&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    
    &lt;span class="n"&gt;state&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;initGridPlayer&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="c1"&gt;#using the harder state initialization function&lt;/span&gt;
    &lt;span class="n"&gt;status&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
    &lt;span class="c1"&gt;#while game still in progress&lt;/span&gt;
    &lt;span class="k"&gt;while&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;status&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="c1"&gt;#We are in state S&lt;/span&gt;
        &lt;span class="c1"&gt;#Let's run our Q function on S to get Q values for all possible actions&lt;/span&gt;
        &lt;span class="n"&gt;qval&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;64&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;&lt;&lt;/span&gt; &lt;span class="n"&gt;epsilon&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="c1"&gt;#choose random action&lt;/span&gt;
            &lt;span class="n"&gt;action&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;randint&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="c1"&gt;#choose best action from Q(s,a) values&lt;/span&gt;
            &lt;span class="n"&gt;action&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argmax&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;qval&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
        &lt;span class="c1"&gt;#Take action, observe new state S'&lt;/span&gt;
        &lt;span class="n"&gt;new_state&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;makeMove&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;action&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="c1"&gt;#Observe reward&lt;/span&gt;
        &lt;span class="n"&gt;reward&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;getReward&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;new_state&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        
        &lt;span class="c1"&gt;#Experience replay storage&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;replay&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&lt;&lt;/span&gt; &lt;span class="n"&gt;buffer&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="c1"&gt;#if buffer not filled, add to it&lt;/span&gt;
            &lt;span class="n"&gt;replay&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;action&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;reward&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;new_state&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="c1"&gt;#if buffer full, overwrite old values&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;h&lt;/span&gt; &lt;span class="o"&gt;&lt;&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;buffer&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)):&lt;/span&gt;
                &lt;span class="n"&gt;h&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
            &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;h&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
            &lt;span class="n"&gt;replay&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;h&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;action&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;reward&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;new_state&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="c1"&gt;#randomly sample our experience replay memory&lt;/span&gt;
            &lt;span class="n"&gt;minibatch&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sample&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;replay&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;batchSize&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;X_train&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
            &lt;span class="n"&gt;y_train&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
            &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;memory&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;minibatch&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="c1"&gt;#Get max_Q(S',a)&lt;/span&gt;
                &lt;span class="n"&gt;old_state&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;action&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;reward&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;new_state&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;memory&lt;/span&gt;
                &lt;span class="n"&gt;old_qval&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;old_state&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;64&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                &lt;span class="n"&gt;newQ&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;new_state&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;64&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                &lt;span class="n"&gt;maxQ&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;max&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;newQ&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
                &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;[:]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;old_qval&lt;/span&gt;&lt;span class="p"&gt;[:]&lt;/span&gt;
                &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;reward&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="c1"&gt;#non-terminal state&lt;/span&gt;
                    &lt;span class="n"&gt;update&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;reward&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;gamma&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;maxQ&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
                &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="c1"&gt;#terminal state&lt;/span&gt;
                    &lt;span class="n"&gt;update&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;reward&lt;/span&gt;
                &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="n"&gt;action&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;update&lt;/span&gt;
                &lt;span class="n"&gt;X_train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;old_state&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;64&lt;/span&gt;&lt;span class="p"&gt;,))&lt;/span&gt;
                &lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,))&lt;/span&gt;
            
            &lt;span class="n"&gt;X_train&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_train&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;y_train&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Game #: &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,))&lt;/span&gt;
            &lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;batchSize&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;nb_epoch&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;verbose&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;state&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;new_state&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;reward&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="c1"&gt;#if reached terminal state, update game status&lt;/span&gt;
            &lt;span class="n"&gt;status&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
        &lt;span class="n"&gt;clear_output&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;wait&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;epsilon&lt;/span&gt; &lt;span class="o"&gt;&gt;&lt;/span&gt; &lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="c1"&gt;#decrement epsilon over time&lt;/span&gt;
        &lt;span class="n"&gt;epsilon&lt;/span&gt; &lt;span class="o"&gt;-=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;epochs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;&lt;div class="prompt"&gt;&lt;/div&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;Game #: 2999
Epoch 1/1
40/40 [==============================] - 0s - loss: 0.0018
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;I've increased the training epochs to 3000 just based on empiric testing. So let's see how it does, we'll run our &lt;code&gt;testAlgo()&lt;/code&gt; function a couple times to see how it handles randomly initialized player scenarios.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In [22]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;testAlgo&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;#run testAlgo using random player placement =&gt; initGridPlayer()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;&lt;div class="prompt"&gt;&lt;/div&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;Initial State:
[[' ' ' ' ' ' ' ']
 [' ' '-' '+' ' ']
 [' ' ' ' 'W' ' ']
 [' ' ' ' 'P' ' ']]
Move #: 0; Taking action: 3
[[' ' ' ' ' ' ' ']
 [' ' '-' '+' ' ']
 [' ' ' ' 'W' ' ']
 [' ' ' ' ' ' 'P']]
Move #: 1; Taking action: 0
[[' ' ' ' ' ' ' ']
 [' ' '-' '+' ' ']
 [' ' ' ' 'W' 'P']
 [' ' ' ' ' ' ' ']]
Move #: 2; Taking action: 0
[[' ' ' ' ' ' ' ']
 [' ' '-' '+' 'P']
 [' ' ' ' 'W' ' ']
 [' ' ' ' ' ' ' ']]
Move #: 3; Taking action: 2
[[' ' ' ' ' ' ' ']
 [' ' '-' ' ' ' ']
 [' ' ' ' 'W' ' ']
 [' ' ' ' ' ' ' ']]
Reward: 10
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Fantastic. Let's run the &lt;code&gt;testAlgo()&lt;/code&gt; one more time just to prove it has generalized.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In [28]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;testAlgo&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;init&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;#Of course, I ran it many times more than I'm showing here&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;&lt;div class="prompt"&gt;&lt;/div&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;Initial State:
[[' ' ' ' ' ' ' ']
 [' ' '-' '+' ' ']
 [' ' 'P' 'W' ' ']
 [' ' ' ' ' ' ' ']]
Move #: 0; Taking action: 2
[[' ' ' ' ' ' ' ']
 [' ' '-' '+' ' ']
 ['P' ' ' 'W' ' ']
 [' ' ' ' ' ' ' ']]
Move #: 1; Taking action: 0
[[' ' ' ' ' ' ' ']
 ['P' '-' '+' ' ']
 [' ' ' ' 'W' ' ']
 [' ' ' ' ' ' ' ']]
Move #: 2; Taking action: 0
[['P' ' ' ' ' ' ']
 [' ' '-' '+' ' ']
 [' ' ' ' 'W' ' ']
 [' ' ' ' ' ' ' ']]
Move #: 3; Taking action: 3
[[' ' 'P' ' ' ' ']
 [' ' '-' '+' ' ']
 [' ' ' ' 'W' ' ']
 [' ' ' ' ' ' ' ']]
Move #: 4; Taking action: 3
[[' ' ' ' 'P' ' ']
 [' ' '-' '+' ' ']
 [' ' ' ' 'W' ' ']
 [' ' ' ' ' ' ' ']]
Move #: 5; Taking action: 1
[[' ' ' ' ' ' ' ']
 [' ' '-' ' ' ' ']
 [' ' ' ' 'W' ' ']
 [' ' ' ' ' ' ' ']]
Reward: 10
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;I'll be darned. It seems to have learned to play the game from any starting position! Pretty neat.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="The-Hardest-Variant"&gt;The Hardest Variant&lt;a class="anchor-link" href="#The-Hardest-Variant"&gt;¶&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Okay, I lied. I will not be showing you the algorithm learning the hardest variant of the game (where all 4 elements are randomly placed on the grid each game). I'm leaving that up to you to attempt and let me know how it goes via email (outlacedev@gmail.com). The reason is, I'm doing all this on a Macbook Air (read: no CUDA gpu) and thus I cannot train the algorithm to a sufficiently large number of epochs for it to learn the problem. I suspect it may require significantly more epochs, perhaps more than 50,000. So if you have an nVIDIA GPU and can train it that long, let me know if it works. I could have used Lua/Torch7 since there is an OpenCL version but no one would read this if it wasn't in Python =P.&lt;/p&gt;
&lt;h3 id="Conclusion"&gt;Conclusion&lt;a class="anchor-link" href="#Conclusion"&gt;¶&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;There you have it, basic Q-learning using neural networks.&lt;/p&gt;
&lt;p&gt;That was a lot to go through, hopefully I didn't make too many mistakes (as always, email if you spot any so I can post corrections). I'm hoping you have success training Q-learning algorithms on more interesting problems than the gridworld game.&lt;/p&gt;
&lt;p&gt;I'd say this is definitely the climax of the series on reinforcement learning. I plan to release a part 4 that will be about other temporal difference learnings algorithms that use eligibility traces. Since that's a relatively minor new concept, I will likely use it on another toy problem like gridworld. However, I do, at some point, want to release a post about setting up and using the Arcade Learning Environment (ALE) [fmr. Atari Learning Environment] and training an alogorithm to play Atari games, however, that will likely be a long while from now so don't hold your breath.&lt;/p&gt;
&lt;p&gt;Cheers&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Download-this-IPython-Notebook"&gt;Download this IPython Notebook&lt;a class="anchor-link" href="#Download-this-IPython-Notebook"&gt;¶&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;&lt;a href="https://github.com/outlace/outlace.github.io/blob/master/ipython-notebooks/rlpart2.ipynb"&gt;https://github.com/outlace/outlace.github.io/blob/master/ipython-notebooks/rlpart2.ipynb&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="References"&gt;References&lt;a class="anchor-link" href="#References"&gt;¶&lt;/a&gt;&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;&lt;a href="http://www.computervisiontalks.com/deep-learning-lecture-16-reinforcement-learning-and-neuro-dynamic-programming-nando-de-freitas/"&gt;http://www.computervisiontalks.com/deep-learning-lecture-16-reinforcement-learning-and-neuro-dynamic-programming-nando-de-freitas/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=yNeSFbE1jdY"&gt;https://www.youtube.com/watch?v=yNeSFbE1jdY&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.researchgate.net/profile/Marco_Wiering/publication/236645821_Reinforcement_Learning_to_Train_Ms._Pac-Man_Using_Higher-order_Action-relative_Inputs/links/0deec518a22042f5d7000000.pdf?inViewer=true&amp;amp;pdfJsDownload=true&amp;amp;disableCoverPage=true&amp;amp;origin=publication_detail"&gt;http://www.researchgate.net/profile/Marco_Wiering/publication/236645821_Reinforcement_Learning_to_Train_Ms._Pac-Man_Using_Higher-order_Action-relative_Inputs/links/0deec518a22042f5d7000000.pdf?inViewer=true&amp;pdfJsDownload;=true&amp;disableCoverPage;=true&amp;origin;=publication_detail&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;"Reinforcement Learning An Introduction" Sutton &amp; Barto, 1996&lt;/li&gt;
&lt;li&gt;"Human-level control through deep reinforcement learning" Mnih et al, 2015 (Google DeepMind Atari paper)&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: 'center'," +
        "    displayIndent: '0em'," +
        "    showMathMenu: true," +
        "    tex2jax: { " +
        "        inlineMath: [ ['$','$'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        " linebreaks: { automatic: true, width: '95% container' }, " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }" +
        "    } " +
        "}); ";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;
</content><category term="Q-learning"></category><category term="RL"></category></entry><entry><title>Reinforcement Learning - Monte Carlo Methods</title><link href="/rlpart2.html" rel="alternate"></link><published>2015-10-25T00:00:00-07:00</published><updated>2015-10-25T00:00:00-07:00</updated><author><name>outlace</name></author><id>tag:None,2015-10-25:/rlpart2.html</id><summary type="html">&lt;p&gt;Part 2 of the RL series. A slightly deeper dive into reinforcement learning methods by learning how to use Monte Carlo simulations to learn how to play blackjack.&lt;/p&gt;</summary><content type="html">&lt;style type="text/css"&gt;/*!
*
* IPython notebook
*
*/
/* CSS font colors for translated ANSI colors. */
.ansibold {
  font-weight: bold;
}
/* use dark versions for foreground, to improve visibility */
.ansiblack {
  color: black;
}
.ansired {
  color: darkred;
}
.ansigreen {
  color: darkgreen;
}
.ansiyellow {
  color: #c4a000;
}
.ansiblue {
  color: darkblue;
}
.ansipurple {
  color: darkviolet;
}
.ansicyan {
  color: steelblue;
}
.ansigray {
  color: gray;
}
/* and light for background, for the same reason */
.ansibgblack {
  background-color: black;
}
.ansibgred {
  background-color: red;
}
.ansibggreen {
  background-color: green;
}
.ansibgyellow {
  background-color: yellow;
}
.ansibgblue {
  background-color: blue;
}
.ansibgpurple {
  background-color: magenta;
}
.ansibgcyan {
  background-color: cyan;
}
.ansibggray {
  background-color: gray;
}
div.cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  border-radius: 2px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  border-width: 1px;
  border-style: solid;
  border-color: transparent;
  width: 100%;
  padding: 5px;
  /* This acts as a spacer between cells, that is outside the border */
  margin: 0px;
  outline: none;
  border-left-width: 1px;
  padding-left: 5px;
  background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%);
}
div.cell.jupyter-soft-selected {
  border-left-color: #90CAF9;
  border-left-color: #E3F2FD;
  border-left-width: 1px;
  padding-left: 5px;
  border-right-color: #E3F2FD;
  border-right-width: 1px;
  background: #E3F2FD;
}
@media print {
  div.cell.jupyter-soft-selected {
    border-color: transparent;
  }
}
div.cell.selected {
  border-color: #ababab;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%);
}
@media print {
  div.cell.selected {
    border-color: transparent;
  }
}
div.cell.selected.jupyter-soft-selected {
  border-left-width: 0;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%);
}
.edit_mode div.cell.selected {
  border-color: #66BB6A;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%);
}
@media print {
  .edit_mode div.cell.selected {
    border-color: transparent;
  }
}
.prompt {
  /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */
  min-width: 14ex;
  /* This padding is tuned to match the padding on the CodeMirror editor. */
  padding: 0.4em;
  margin: 0px;
  font-family: monospace;
  text-align: right;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
  /* Don't highlight prompt number selection */
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
  /* Use default cursor */
  cursor: default;
}
@media (max-width: 540px) {
  .prompt {
    text-align: left;
  }
}
div.inner_cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
@-moz-document url-prefix() {
  div.inner_cell {
    overflow-x: hidden;
  }
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_area {
  border: 1px solid #cfcfcf;
  border-radius: 2px;
  background: #f7f7f7;
  line-height: 1.21429em;
}
/* This is needed so that empty prompt areas can collapse to zero height when there
   is no content in the output_subarea and the prompt. The main purpose of this is
   to make sure that empty JavaScript output_subareas have no height. */
div.prompt:empty {
  padding-top: 0;
  padding-bottom: 0;
}
div.unrecognized_cell {
  padding: 5px 5px 5px 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.unrecognized_cell .inner_cell {
  border-radius: 2px;
  padding: 5px;
  font-weight: bold;
  color: red;
  border: 1px solid #cfcfcf;
  background: #eaeaea;
}
div.unrecognized_cell .inner_cell a {
  color: inherit;
  text-decoration: none;
}
div.unrecognized_cell .inner_cell a:hover {
  color: inherit;
  text-decoration: none;
}
@media (max-width: 540px) {
  div.unrecognized_cell &gt; div.prompt {
    display: none;
  }
}
div.code_cell {
  /* avoid page breaking on code cells when printing */
}
@media print {
  div.code_cell {
    page-break-inside: avoid;
  }
}
/* any special styling for code cells that are currently running goes here */
div.input {
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.input {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_prompt {
  color: #303F9F;
  border-top: 1px solid transparent;
}
div.input_area &gt; div.highlight {
  margin: 0.4em;
  border: none;
  padding: 0px;
  background-color: transparent;
}
div.input_area &gt; div.highlight &gt; pre {
  margin: 0px;
  border: none;
  padding: 0px;
  background-color: transparent;
}
/* The following gets added to the &lt;head&gt; if it is detected that the user has a
 * monospace font with inconsistent normal/bold/italic height.  See
 * notebookmain.js.  Such fonts will have keywords vertically offset with
 * respect to the rest of the text.  The user should select a better font.
 * See: https://github.com/ipython/ipython/issues/1503
 *
 * .CodeMirror span {
 *      vertical-align: bottom;
 * }
 */
.CodeMirror {
  line-height: 1.21429em;
  /* Changed from 1em to our global default */
  font-size: 14px;
  height: auto;
  /* Changed to auto to autogrow */
  background: none;
  /* Changed from white to allow our bg to show through */
}
.CodeMirror-scroll {
  /*  The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/
  /*  We have found that if it is visible, vertical scrollbars appear with font size changes.*/
  overflow-y: hidden;
  overflow-x: auto;
}
.CodeMirror-lines {
  /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */
  /* we have set a different line-height and want this to scale with that. */
  padding: 0.4em;
}
.CodeMirror-linenumber {
  padding: 0 8px 0 4px;
}
.CodeMirror-gutters {
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.CodeMirror pre {
  /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */
  /* .CodeMirror-lines */
  padding: 0;
  border: 0;
  border-radius: 0;
}
/*

Original style from softwaremaniacs.org (c) Ivan Sagalaev &lt;Maniac@SoftwareManiacs.Org&gt;
Adapted from GitHub theme

*/
.highlight-base {
  color: #000;
}
.highlight-variable {
  color: #000;
}
.highlight-variable-2 {
  color: #1a1a1a;
}
.highlight-variable-3 {
  color: #333333;
}
.highlight-string {
  color: #BA2121;
}
.highlight-comment {
  color: #408080;
  font-style: italic;
}
.highlight-number {
  color: #080;
}
.highlight-atom {
  color: #88F;
}
.highlight-keyword {
  color: #008000;
  font-weight: bold;
}
.highlight-builtin {
  color: #008000;
}
.highlight-error {
  color: #f00;
}
.highlight-operator {
  color: #AA22FF;
  font-weight: bold;
}
.highlight-meta {
  color: #AA22FF;
}
/* previously not defined, copying from default codemirror */
.highlight-def {
  color: #00f;
}
.highlight-string-2 {
  color: #f50;
}
.highlight-qualifier {
  color: #555;
}
.highlight-bracket {
  color: #997;
}
.highlight-tag {
  color: #170;
}
.highlight-attribute {
  color: #00c;
}
.highlight-header {
  color: blue;
}
.highlight-quote {
  color: #090;
}
.highlight-link {
  color: #00c;
}
/* apply the same style to codemirror */
.cm-s-ipython span.cm-keyword {
  color: #008000;
  font-weight: bold;
}
.cm-s-ipython span.cm-atom {
  color: #88F;
}
.cm-s-ipython span.cm-number {
  color: #080;
}
.cm-s-ipython span.cm-def {
  color: #00f;
}
.cm-s-ipython span.cm-variable {
  color: #000;
}
.cm-s-ipython span.cm-operator {
  color: #AA22FF;
  font-weight: bold;
}
.cm-s-ipython span.cm-variable-2 {
  color: #1a1a1a;
}
.cm-s-ipython span.cm-variable-3 {
  color: #333333;
}
.cm-s-ipython span.cm-comment {
  color: #408080;
  font-style: italic;
}
.cm-s-ipython span.cm-string {
  color: #BA2121;
}
.cm-s-ipython span.cm-string-2 {
  color: #f50;
}
.cm-s-ipython span.cm-meta {
  color: #AA22FF;
}
.cm-s-ipython span.cm-qualifier {
  color: #555;
}
.cm-s-ipython span.cm-builtin {
  color: #008000;
}
.cm-s-ipython span.cm-bracket {
  color: #997;
}
.cm-s-ipython span.cm-tag {
  color: #170;
}
.cm-s-ipython span.cm-attribute {
  color: #00c;
}
.cm-s-ipython span.cm-header {
  color: blue;
}
.cm-s-ipython span.cm-quote {
  color: #090;
}
.cm-s-ipython span.cm-link {
  color: #00c;
}
.cm-s-ipython span.cm-error {
  color: #f00;
}
.cm-s-ipython span.cm-tab {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);
  background-position: right;
  background-repeat: no-repeat;
}
div.output_wrapper {
  /* this position must be relative to enable descendents to be absolute within it */
  position: relative;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  z-index: 1;
}
/* class for the output area when it should be height-limited */
div.output_scroll {
  /* ideally, this would be max-height, but FF barfs all over that */
  height: 24em;
  /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */
  width: 100%;
  overflow: auto;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  display: block;
}
/* output div while it is collapsed */
div.output_collapsed {
  margin: 0px;
  padding: 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
div.out_prompt_overlay {
  height: 100%;
  padding: 0px 0.4em;
  position: absolute;
  border-radius: 2px;
}
div.out_prompt_overlay:hover {
  /* use inner shadow to get border that is computed the same on WebKit/FF */
  -webkit-box-shadow: inset 0 0 1px #000;
  box-shadow: inset 0 0 1px #000;
  background: rgba(240, 240, 240, 0.5);
}
div.output_prompt {
  color: #D84315;
}
/* This class is the outer container of all output sections. */
div.output_area {
  padding: 0px;
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.output_area .MathJax_Display {
  text-align: left !important;
}
div.output_area 
div.output_area 
div.output_area img,
div.output_area svg {
  max-width: 100%;
  height: auto;
}
div.output_area img.unconfined,
div.output_area svg.unconfined {
  max-width: none;
}
/* This is needed to protect the pre formating from global settings such
   as that of bootstrap */
.output {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.output_area {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
div.output_area pre {
  margin: 0;
  padding: 0;
  border: 0;
  vertical-align: baseline;
  color: black;
  background-color: transparent;
  border-radius: 0;
}
/* This class is for the output subarea inside the output_area and after
   the prompt div. */
div.output_subarea {
  overflow-x: auto;
  padding: 0.4em;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
  max-width: calc(100% - 14ex);
}
div.output_scroll div.output_subarea {
  overflow-x: visible;
}
/* The rest of the output_* classes are for special styling of the different
   output types */
/* all text output has this class: */
div.output_text {
  text-align: left;
  color: #000;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
}
/* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */
div.output_stderr {
  background: #fdd;
  /* very light red background for stderr */
}
div.output_latex {
  text-align: left;
}
/* Empty output_javascript divs should have no height */
div.output_javascript:empty {
  padding: 0;
}
.js-error {
  color: darkred;
}
/* raw_input styles */
div.raw_input_container {
  line-height: 1.21429em;
  padding-top: 5px;
}
pre.raw_input_prompt {
  /* nothing needed here. */
}
input.raw_input {
  font-family: monospace;
  font-size: inherit;
  color: inherit;
  width: auto;
  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;
  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0em 0.25em;
  margin: 0em 0.25em;
}
input.raw_input:focus {
  box-shadow: none;
}
p.p-space {
  margin-bottom: 10px;
}
div.output_unrecognized {
  padding: 5px;
  font-weight: bold;
  color: red;
}
div.output_unrecognized a {
  color: inherit;
  text-decoration: none;
}
div.output_unrecognized a:hover {
  color: inherit;
  text-decoration: none;
}
.rendered_html {
  color: #000;
  /* any extras will just be numbers: */
}



.rendered_html :link {
  text-decoration: underline;
}
.rendered_html :visited {
  text-decoration: underline;
}






.rendered_html h1:first-child {
  margin-top: 0.538em;
}
.rendered_html h2:first-child {
  margin-top: 0.636em;
}
.rendered_html h3:first-child {
  margin-top: 0.777em;
}
.rendered_html h4:first-child {
  margin-top: 1em;
}
.rendered_html h5:first-child {
  margin-top: 1em;
}
.rendered_html h6:first-child {
  margin-top: 1em;
}








.rendered_html * + ul {
  margin-top: 1em;
}
.rendered_html * + ol {
  margin-top: 1em;
}


.rendered_html pre,



.rendered_html tr,
.rendered_html th,

.rendered_html td,


.rendered_html * + table {
  margin-top: 1em;
}

.rendered_html * + p {
  margin-top: 1em;
}

.rendered_html * + img {
  margin-top: 1em;
}
.rendered_html img,

.rendered_html img.unconfined,

div.text_cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.text_cell &gt; div.prompt {
    display: none;
  }
}
div.text_cell_render {
  /*font-family: "Helvetica Neue", Arial, Helvetica, Geneva, sans-serif;*/
  outline: none;
  resize: none;
  width: inherit;
  border-style: none;
  padding: 0.5em 0.5em 0.5em 0.4em;
  color: #000;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
a.anchor-link:link {
  text-decoration: none;
  padding: 0px 20px;
  visibility: hidden;
}
h1:hover .anchor-link,
h2:hover .anchor-link,
h3:hover .anchor-link,
h4:hover .anchor-link,
h5:hover .anchor-link,
h6:hover .anchor-link {
  visibility: visible;
}
.text_cell.rendered .input_area {
  display: none;
}
.text_cell.rendered 
.text_cell.unrendered .text_cell_render {
  display: none;
}
.cm-header-1,
.cm-header-2,
.cm-header-3,
.cm-header-4,
.cm-header-5,
.cm-header-6 {
  font-weight: bold;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
}
.cm-header-1 {
  font-size: 185.7%;
}
.cm-header-2 {
  font-size: 157.1%;
}
.cm-header-3 {
  font-size: 128.6%;
}
.cm-header-4 {
  font-size: 110%;
}
.cm-header-5 {
  font-size: 100%;
  font-style: italic;
}
.cm-header-6 {
  font-size: 100%;
  font-style: italic;
}
&lt;/style&gt;
&lt;style type="text/css"&gt;.highlight .hll { background-color: #ffffcc }
.highlight  { background: #f8f8f8; }
.highlight .c { color: #408080; font-style: italic } /* Comment */
.highlight .err { border: 1px solid #FF0000 } /* Error */
.highlight .k { color: #008000; font-weight: bold } /* Keyword */
.highlight .o { color: #666666 } /* Operator */
.highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */
.highlight .cp { color: #BC7A00 } /* Comment.Preproc */
.highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */
.highlight .cs { color: #408080; font-style: italic } /* Comment.Special */
.highlight .gd { color: #A00000 } /* Generic.Deleted */
.highlight .ge { font-style: italic } /* Generic.Emph */
.highlight .gr { color: #FF0000 } /* Generic.Error */
.highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.highlight .gi { color: #00A000 } /* Generic.Inserted */
.highlight .go { color: #888888 } /* Generic.Output */
.highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.highlight .gs { font-weight: bold } /* Generic.Strong */
.highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.highlight .gt { color: #0044DD } /* Generic.Traceback */
.highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: #008000 } /* Keyword.Pseudo */
.highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: #B00040 } /* Keyword.Type */
.highlight .m { color: #666666 } /* Literal.Number */
.highlight .s { color: #BA2121 } /* Literal.String */
.highlight .na { color: #7D9029 } /* Name.Attribute */
.highlight .nb { color: #008000 } /* Name.Builtin */
.highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.highlight .no { color: #880000 } /* Name.Constant */
.highlight .nd { color: #AA22FF } /* Name.Decorator */
.highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */
.highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
.highlight .nf { color: #0000FF } /* Name.Function */
.highlight .nl { color: #A0A000 } /* Name.Label */
.highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */
.highlight .nv { color: #19177C } /* Name.Variable */
.highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.highlight .w { color: #bbbbbb } /* Text.Whitespace */
.highlight .mb { color: #666666 } /* Literal.Number.Bin */
.highlight .mf { color: #666666 } /* Literal.Number.Float */
.highlight .mh { color: #666666 } /* Literal.Number.Hex */
.highlight .mi { color: #666666 } /* Literal.Number.Integer */
.highlight .mo { color: #666666 } /* Literal.Number.Oct */
.highlight .sb { color: #BA2121 } /* Literal.String.Backtick */
.highlight .sc { color: #BA2121 } /* Literal.String.Char */
.highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.highlight .s2 { color: #BA2121 } /* Literal.String.Double */
.highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
.highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */
.highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
.highlight .sx { color: #008000 } /* Literal.String.Other */
.highlight .sr { color: #BB6688 } /* Literal.String.Regex */
.highlight .s1 { color: #BA2121 } /* Literal.String.Single */
.highlight .ss { color: #19177C } /* Literal.String.Symbol */
.highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */
.highlight .vc { color: #19177C } /* Name.Variable.Class */
.highlight .vg { color: #19177C } /* Name.Variable.Global */
.highlight .vi { color: #19177C } /* Name.Variable.Instance */
.highlight .il { color: #666666 } /* Literal.Number.Integer.Long */&lt;/style&gt;
&lt;style type="text/css"&gt;
/* Temporary definitions which will become obsolete with Notebook release 5.0 */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-bold { font-weight: bold; }
&lt;/style&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Playing-Blackjack-with-Monte-Carlo-Methods"&gt;Playing Blackjack with Monte Carlo Methods&lt;a class="anchor-link" href="#Playing-Blackjack-with-Monte-Carlo-Methods"&gt;¶&lt;/a&gt;&lt;/h3&gt;&lt;h5 id="Introduction"&gt;Introduction&lt;a class="anchor-link" href="#Introduction"&gt;¶&lt;/a&gt;&lt;/h5&gt;&lt;p&gt;In part 1, we considered a very simple problem, the n-armed bandit problem, and devised an appropriately very simple algorithm to solve it ($\epsilon$-greedy evaluation). In that case, the problem only has a single state: a choice among 10 actions with stationary probability distributions of rewards. Let's up the ante a bit and consider a more interesting problem with multiple (yet finite) states: the card game black jack (aka 21). Hunker down, this is a long one.&lt;/p&gt;
&lt;p&gt;Rules and game-play of blackjack (check out &lt;a href="https://www.youtube.com/watch?v=qd5oc9hLrXg"&gt;https://www.youtube.com/watch?v=qd5oc9hLrXg&lt;/a&gt; if necessary):&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;There is a dealer and 1 or more players that independently play against the dealer.&lt;/li&gt;
&lt;li&gt;Each player is delt 2 cards face-up. The dealer is delt two cards, one face-up, one face-down.&lt;/li&gt;
&lt;li&gt;The goal is to get the sum of your cards value to be as close to 21 as possible without going over.&lt;/li&gt;
&lt;li&gt;After the initial cards are dealt, each player can choose to 'stay' or 'hit' (ask for another card).&lt;/li&gt;
&lt;li&gt;The dealer always follows this policy: hit until cards sum to 17 or more, then stay.&lt;/li&gt;
&lt;li&gt;If the dealer is closer to 21, the dealer wins and the player loses, and vice versa.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;So what's the state space for this problem? It's relatively large, much much larger than the single state in n-armed bandit. In reinforcement learning, a state is all information available to the agent (the decision maker) at a particular time $t$. The reason why the n-armed bandit state space includes just 1 state is because the agent is only aware of the same 10 actions at any time, no new information is available nor do the actions change.&lt;/p&gt;
&lt;p&gt;So what are all the possible combinations of information available to the agent (the player) in blackjack? Well, the player starts with two cards, so there is the combination of all 2 playing cards. Additionally, the player knows one of the two cards that the dealer has. Thus, there are a lot of possible states (around 200). As with any RL problem, our ultimate goal is to find the best &lt;em&gt;policy&lt;/em&gt; to maximize our rewards.&lt;/p&gt;
&lt;p&gt;A policy is roughly equivalent to a strategy. There are reinforcement learning methods that essentially rely on brute force to compute every possible action-state pair (every possible action in a given state) and the rewards received to find an optimal policy, but for most of the problems we care about, the state-action space is much too large for brute force methods to be computationally feasible. Thus we must rely on experience, i.e. playing the game, trying out various actions and learning what seems to result in the greatest reward returns; and we need to devise an algorithm that captures this experiential learning process.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;The most important take-aways from part 1 and 2 are the concepts of state values, state-action values, and policies. Reinforcement learning is in the business of determining the value of states or of actions taken in a state. In our case, we will primarily concern ourselves with action values (value of an action taken in a given state) because it is more intuitive in how we can make an optimal action. I find the value of being in a given state less intuitive because the value of a state depends on your policy. For example, what is the value of being in a state of a blackjack game where your cards total to 20? Most people would say that's a pretty good position to be in, but it's only a good state if your policy is to stay and not hit. If your policy is to hit when you have 20 (of course it's a bad policy), then that state isn't very good. On the other hand, we can ask the question of, what's the value of hitting when I have 20 versus the value of staying when I have 20, and then just choose whichever action has the highest value. Of course staying would produce the highest value in this state (on average).&lt;/p&gt;
&lt;p&gt;Our main computational effort, therefore, is in iteratively improving our estimates for the values of states or state-action pairs. In parts 1 and 2, we keep track of every single state-action pair we encounter, and record the rewards we receive for each and average them over time. Thus, over many iterations, we go from knowing nothing about the value of state-actions to knowing enough to be able to choose the highest value actions. Problems like the n-armed bandit problem and blackjack have a small enough state or state-action space that we can record and average rewards in a lookup table, giving us the exact average rewards for each state-action pair. Most interesting problems, however, have a state space that is continuous or otherwise too large to use a lookup table. That's when we must use function approximation (e.g. neural networks) methods to serve as our $Q$ function in determining the value of states or state-actions.  We will have to wait for part 3 for neural networks.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h4 id="Learning-with-Markov-Decision-Processes"&gt;Learning with Markov Decision Processes&lt;a class="anchor-link" href="#Learning-with-Markov-Decision-Processes"&gt;¶&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;A Markov decision process (MDP) is a decision that can be made knowing only the current state, without knowledge of or reference to previous states or the path taken to the current state. That is, the current state contains enough information to choose optimal actions to maximize future rewards. Most RL algorithms assume that the problems to be learned are (at least approximately) Markov decision processes. Blackjack is clearly an MDP because we can play the game successfully by just knowing our current state (i.e. what cards we have + the dealer's one face-up card). Google DeepMind's deep Q-learning algorithm learned to play Atari games from just raw pixel data and the current score. Does raw pixel data and the score satisfy the Markov property? Not exactly. Say the game is Pacman, if our state is the raw pixel data from our current frame, we have no idea if that enemy a few tiles away is approaching us or moving away from us, and that would strongly influence our choice of actions to take. This is why DeepMind's implementation actually feeds in the last 4 frames of gameplay, effectively changing a non-Markov decision process into an MDP. With the last 4 frames, the agent has access to the direction and speed of each enemy (and itself).&lt;/p&gt;
&lt;h4 id="Terminology-&amp;amp;-Notation-Review"&gt;Terminology &amp; Notation Review&lt;a class="anchor-link" href="#Terminology-&amp;amp;-Notation-Review"&gt;¶&lt;/a&gt;&lt;/h4&gt;&lt;ol&gt;
&lt;li&gt;$Q_k(s, a)$ is the function that accepts an action and state and returns the value of taking that action in that state at time step $k$. This is fundamental to RL. We need to know the relative values of every state or state-action pair.&lt;/li&gt;
&lt;li&gt;$\pi$ is a policy, a stochastic strategy or rule to choose action $a$ given a state $s$. Think of it as a function, $\pi(s)$, that accepts state, $s$ and returns the action to be taken. There is a distinction between the $\pi(s)$ &lt;em&gt;function&lt;/em&gt; and a specific policy $\pi$. Our implementation of $\pi(s)$ as a function is often to just choose the action $a$ in state $s$ that has the highest average return based on historical results, $argmaxQ(s,a)$. As we gather more data and these average returns become more accurate, the actual policy $\pi$ may change. We may start out with a policy of "hit until total is 16 or more then stay" but this policy may change as we gather more data. Our implemented $\pi(s)$ function, however, is programmed by us and does not change.&lt;/li&gt;
&lt;li&gt;$G_t$, return. The expected cumulative reward from starting in a given state until the end of an episode (i.e. game play), for example. In our case we only give a reward at the end of the game, there are no rewards at each time step or move.&lt;/li&gt;
&lt;li&gt;Episode: The full sequence of steps leading to a terminal state and receiving a return. E.g. from the beginning of a blackjack game until the terminal state (someone winning) constitutes an episode of play.&lt;/li&gt;
&lt;li&gt;$v_\pi$, a function that determines the value of a state given a policy $\pi$. We do not really concern our selves with state values here, we focus on action values.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Monte-Carlo-&amp;amp;-Tabular-Methods"&gt;Monte Carlo &amp; Tabular Methods&lt;a class="anchor-link" href="#Monte-Carlo-&amp;amp;-Tabular-Methods"&gt;¶&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Monte Carlo is going to feel very familiar to how we solved the n-armed bandit problem from part 1. We will store the history of our state-action pairs associated with their values in a table, and then refer to this table during learning to calculate our expected rewards, $Q_k$.&lt;/p&gt;
&lt;p&gt;From Wikipedia, Monte Carlo methods "rely on repeated random sampling to obtain numerical results." We'll use random sampling of states and state-action pairs and observe rewards and then iteratively revise our policy, which will hopefully converge on the optimal policy as we explore every possible state-action couple.&lt;/p&gt;
&lt;p&gt;Here are some important points:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;We will asign a reward of +1 to winning a round of blackjack, -1 for losing, and 0 for a draw.&lt;/li&gt;
&lt;li&gt;We will establish a table (python dictionary) where each key corresponds to a particular state-action pair and each value is the value of that pair. i.e. the average reward received for that action in that state.&lt;/li&gt;
&lt;li&gt;The state consists of the player's card total, whether or not the player has a useable ace, and the dealer's one face-up card&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Blackjack-Game-Implementation"&gt;Blackjack Game Implementation&lt;a class="anchor-link" href="#Blackjack-Game-Implementation"&gt;¶&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Below I've implemented a blackjack game. I think I've commented it well enough to be understood but it's not critical that you understand the game implementation since we're just concerned with how to learn to play the game with machine learning.&lt;/p&gt;
&lt;p&gt;This implementation is completely functional and stateless. I mean that this implementation is just a group of functions that accept data, transform that data and return new data. I intentionally avoided using OOP classes because I think it complicates things and I think functional-style programming is useful in machine learning (see my post about computational graphs to learn more). It is particularly useful in our case because it demonstrates how blackjack is an MDP. The game does not store any information, it is stateless. It merely accepts states and returns new states. The player is responsible for saving states if they want.&lt;/p&gt;
&lt;p&gt;The state is just a Python tuple where the first element is the player's card total, the 2nd element is a boolean of whether or not the player has a useable ace. The 3rd element is the card total for the dealer and then another boolean of whether or not its a useable ace. The last element is a single integer that represents the status of the state (whether the game is in progress, the player has won, the dealer has won, or it was a draw).&lt;/p&gt;
&lt;p&gt;We actually could implement this in a more intuitive way where we just store each player's cards and not whether or not they have a useable ace (useable means, can the ace be an 11 without losing the game by going over 21, because aces in blackjack can either be a 1 or an 11). However, as you'll see, storing the player card total and an useable ace boolean is equivalent and yet compresses our state space (without losing any information) so we can have a smaller lookup table.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In [259]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;math&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;random&lt;/span&gt;
&lt;span class="c1"&gt;#each value card has a 1:13 chance of being selected (we don't care about suits for blackjack)&lt;/span&gt;
&lt;span class="c1"&gt;#cards (value): Ace (1), 2, 3, 4, 5, 6, 7, 8, 9, 10, Jack (10), Queen (10), King (10)&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;randomCard&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="n"&gt;card&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;randint&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;13&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;card&lt;/span&gt; &lt;span class="o"&gt;&gt;&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;card&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;card&lt;/span&gt;

&lt;span class="c1"&gt;#A hand is just a tuple e.g. (14, False), a total card value of 14 without a useable ace&lt;/span&gt;
&lt;span class="c1"&gt;#accepts a hand, if the Ace can be an 11 without busting the hand, it's useable&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;useable_ace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;hand&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;val&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ace&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;hand&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;ace&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;val&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&lt;=&lt;/span&gt; &lt;span class="mi"&gt;21&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;totalValue&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;hand&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;val&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ace&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;hand&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;useable_ace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;hand&lt;/span&gt;&lt;span class="p"&gt;)):&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;val&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;val&lt;/span&gt;
    
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;add_card&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;hand&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;card&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;val&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ace&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;hand&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;card&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;ace&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;True&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;val&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;card&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ace&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;#The first is first dealt a single card, this method finishes off his hand&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;eval_dealer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dealer_hand&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;totalValue&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dealer_hand&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&lt;&lt;/span&gt; &lt;span class="mi"&gt;17&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;dealer_hand&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;add_card&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dealer_hand&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;randomCard&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;dealer_hand&lt;/span&gt;

&lt;span class="c1"&gt;#state: (player total, useable_ace), (dealer total, useable ace), game status; e.g. ((15, True), (9, False), 1)&lt;/span&gt;
&lt;span class="c1"&gt;#stay or hit =&gt; dec == 0 or 1&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;play&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dec&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="c1"&gt;#evaluate&lt;/span&gt;
    &lt;span class="n"&gt;player_hand&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="c1"&gt;#val, useable ace&lt;/span&gt;
    &lt;span class="n"&gt;dealer_hand&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;dec&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="c1"&gt;#action = stay&lt;/span&gt;
        &lt;span class="c1"&gt;#evaluate game; dealer plays&lt;/span&gt;
        &lt;span class="n"&gt;dealer_hand&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;eval_dealer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dealer_hand&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        
        &lt;span class="n"&gt;player_tot&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;totalValue&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;player_hand&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;dealer_tot&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;totalValue&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dealer_hand&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;status&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dealer_tot&lt;/span&gt; &lt;span class="o"&gt;&gt;&lt;/span&gt; &lt;span class="mi"&gt;21&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="n"&gt;status&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="c1"&gt;#player wins&lt;/span&gt;
        &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dealer_tot&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;player_tot&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="n"&gt;status&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="c1"&gt;#draw&lt;/span&gt;
        &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dealer_tot&lt;/span&gt; &lt;span class="o"&gt;&lt;&lt;/span&gt; &lt;span class="n"&gt;player_tot&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="n"&gt;status&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="c1"&gt;#player wins&lt;/span&gt;
        &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dealer_tot&lt;/span&gt; &lt;span class="o"&gt;&gt;&lt;/span&gt; &lt;span class="n"&gt;player_tot&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="n"&gt;status&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt; &lt;span class="c1"&gt;#player loses&lt;/span&gt;
            
    &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="n"&gt;dec&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="c1"&gt;#action = hit&lt;/span&gt;
        &lt;span class="c1"&gt;#if hit, add new card to player's hand&lt;/span&gt;
        &lt;span class="n"&gt;player_hand&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;add_card&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;player_hand&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;randomCard&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
        &lt;span class="n"&gt;d_hand&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;eval_dealer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dealer_hand&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;player_tot&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;totalValue&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;player_hand&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;status&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;player_tot&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;21&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; 
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;totalValue&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d_hand&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;21&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
                &lt;span class="n"&gt;status&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="c1"&gt;#draw&lt;/span&gt;
            &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;status&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="c1"&gt;#player wins!&lt;/span&gt;
        &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;player_tot&lt;/span&gt; &lt;span class="o"&gt;&gt;&lt;/span&gt; &lt;span class="mi"&gt;21&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="n"&gt;status&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt; &lt;span class="c1"&gt;#player loses&lt;/span&gt;
        &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;player_tot&lt;/span&gt; &lt;span class="o"&gt;&lt;&lt;/span&gt; &lt;span class="mi"&gt;21&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="c1"&gt;#game still in progress&lt;/span&gt;
            &lt;span class="n"&gt;status&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
    &lt;span class="n"&gt;state&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;player_hand&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dealer_hand&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;status&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;state&lt;/span&gt;

&lt;span class="c1"&gt;#start a game of blackjack, returns a random initial state&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;initGame&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="n"&gt;status&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="c1"&gt;#1=in progress; 2=player won; 3=draw; 4 = dealer won/player loses&lt;/span&gt;
    &lt;span class="n"&gt;player_hand&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;add_card&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kc"&gt;False&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;randomCard&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
    &lt;span class="n"&gt;player_hand&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;add_card&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;player_hand&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;randomCard&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
    &lt;span class="n"&gt;dealer_hand&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;add_card&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kc"&gt;False&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;randomCard&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
    &lt;span class="c1"&gt;#evaluate if player wins from first hand&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;totalValue&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;player_hand&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;21&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;totalValue&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dealer_hand&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="mi"&gt;21&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;status&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="c1"&gt;#player wins after first deal!&lt;/span&gt;
        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;status&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="c1"&gt;#draw&lt;/span&gt;
        
    &lt;span class="n"&gt;state&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;player_hand&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dealer_hand&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;status&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;state&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;There you have it. We've implemented a simplified blackjack game (no double downs or splitting) with just a few functions that basically just consist of some if-else conditions. Here's some sample game-play so you know how to use it.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In [250]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;initGame&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;&lt;div class="prompt"&gt;&lt;/div&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;((7, False), (5, False), 1)
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In [251]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;play&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;#Player has total of 7, let's hit&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;&lt;div class="prompt"&gt;&lt;/div&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;((9, False), (5, False), 1)
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In [252]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;play&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;#player has a total of 9, let's hit&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;&lt;div class="prompt"&gt;&lt;/div&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;((15, False), (5, False), 1)
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In [253]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;play&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;#player has a total of 15, let's stay&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;&lt;div class="prompt"&gt;&lt;/div&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;((15, False), (20, False), 4)
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Damn, I lost. Oh well, that should demonstrate how to use the blackjack game. As a user, we only have to concern ourselves with the &lt;code&gt;initGame()&lt;/code&gt; and &lt;code&gt;play()&lt;/code&gt; functions. &lt;code&gt;initGame()&lt;/code&gt; just creates a random state by dealing the player 2 random cards and the dealer one random card and setting the game status to 1 ('in progress'). &lt;code&gt;play()&lt;/code&gt; accepts a state and an action (either 0 or 1, for 'stay' and 'hit', respectively). Please keep in mind the distinction between a blackjack game state and the state with respect to our Reinforcement Learning (RL) algorithm. We will compress the states a bit by ignoring the useable ace boolean for the dealer's hand because the dealer only shows a single card and if it's an ace the player has no idea if it's useable or not, so it offers no additional information to us.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Time-for-Reinforcement-Learning"&gt;Time for Reinforcement Learning&lt;a class="anchor-link" href="#Time-for-Reinforcement-Learning"&gt;¶&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Let's start the real fun: building our Monte Carlo-based reinforcement learning algorithm. Here's the algorithm words/math (adapted from the Sutton &amp; Barto text):&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Choose a random state $S_0 \in \mathcal{S}$ (some state in the set of all possible states); this is what &lt;code&gt;initGame()&lt;/code&gt; does&lt;/li&gt;
&lt;li&gt;Take action $A_0 \in \mathcal{A(S_0)}$ (take some action in set of all possible actions given we're in state $S_0$)&lt;/li&gt;
&lt;li&gt;Generate a complete episode starting from $S_0\,\ A_0$ following policy $\pi$&lt;/li&gt;
&lt;li&gt;For each pair $s, a$ occuring in the episode:&lt;ol&gt;
&lt;li&gt;$G = \text{returns/rewards following the first occurence of s,a}$&lt;/li&gt;
&lt;li&gt;If this is the first experience of $s, a$ in any episode, simply store $G$ in our $Q(s, a)$ table. If it's not the first time, then recalculate the average returns and store in $Q(s, a)$.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;For each state $s$ in the episode: We use an $\epsilon$-greedy action select process such that $\pi(s) = argmax_a{Q(s, a)}$ most of the time but with probability $\epsilon$, $\pi(s) = random(A_0 \in \mathcal{A(S_0)})$ (basically the same as our n-armed bandit policy function). Recall that we use an epsilon-greedy policy function to ensure we have a good balance of exploration versus exploitation.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In essence, with Monte Carlo we are playing randomly initialized games, sampling the state-action pair space and recording returns. In doing so, we can iteratively update our policy $\pi$.&lt;/p&gt;
&lt;p&gt;Let's get to coding.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In [256]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;

&lt;span class="c1"&gt;#Create a list of all the possible states&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;initStateSpace&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="n"&gt;states&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;card&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;11&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;val&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;11&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;22&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="n"&gt;states&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;val&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kc"&gt;False&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;card&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
            &lt;span class="n"&gt;states&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;val&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;card&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;states&lt;/span&gt;

&lt;span class="c1"&gt;#Create a dictionary (key-value pairs) of all possible state-actions and their values&lt;/span&gt;
&lt;span class="c1"&gt;#This creates our Q-value look up table&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;initStateActions&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;states&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;av&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{}&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;state&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;states&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;av&lt;/span&gt;&lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.0&lt;/span&gt;
        &lt;span class="n"&gt;av&lt;/span&gt;&lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.0&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;av&lt;/span&gt;
&lt;span class="c1"&gt;#Setup a dictionary of state-actions to record how many times we've experienced&lt;/span&gt;
&lt;span class="c1"&gt;#a given state-action pair. We need this to re-calculate reward averages&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;initSAcount&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;stateActions&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;counts&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{}&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;sa&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;stateActions&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;counts&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;sa&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;counts&lt;/span&gt;

&lt;span class="c1"&gt;#This calculates the reward of the game, either +1 for winning, 0 for draw, or -1 for losing&lt;/span&gt;
&lt;span class="c1"&gt;#We can determine this by simply substracting the game status value from 3&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;calcReward&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;outcome&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;outcome&lt;/span&gt;

&lt;span class="c1"&gt;#This recalculates the average rewards for our Q-value look-up table&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;updateQtable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;av_table&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;av_count&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;returns&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;returns&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;av_table&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;av_table&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;1.0&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;av_count&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;returns&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;av_table&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;av_table&lt;/span&gt;
        
&lt;span class="c1"&gt;#returns Q-value/avg rewards for each action given a state&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;qsv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;av_table&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;stay&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;av_table&lt;/span&gt;&lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
    &lt;span class="n"&gt;hit&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;av_table&lt;/span&gt;&lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;stay&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;hit&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

&lt;span class="c1"&gt;#converts a game state of the form ((player total, ace), (dealer total, ace), status) &lt;/span&gt;
&lt;span class="c1"&gt;#to a condensed state we'll use for our RL algorithm (player total, usable ace, dealer card)&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;getRLstate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;player_hand&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dealer_hand&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;status&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;state&lt;/span&gt;
    &lt;span class="n"&gt;player_val&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;player_ace&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;player_hand&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;player_val&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;player_ace&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dealer_hand&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Above we've defined basically all the functions we need to run our Monte Carlo algorithm. We initialize our state and state-action space, define methods to calculate rewards and update our state-action table (Q-value table). Below is where we'll actually run 5,000,000 Monte Carlo simulations of blackjack and fill out our Q-value table.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In [257]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;epochs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;5000000&lt;/span&gt; &lt;span class="c1"&gt;#takes just a minute or two on my Macbook Air&lt;/span&gt;
&lt;span class="n"&gt;epsilon&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.1&lt;/span&gt;

&lt;span class="n"&gt;state_space&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;initStateSpace&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;av_table&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;initStateActions&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;state_space&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;av_count&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;initSAcount&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;av_table&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;epochs&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="c1"&gt;#initialize new game; observe current state&lt;/span&gt;
    &lt;span class="n"&gt;state&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;initGame&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;player_hand&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dealer_hand&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;status&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;state&lt;/span&gt;
    &lt;span class="c1"&gt;#if player's total is less than 11, increase total by adding another card&lt;/span&gt;
    &lt;span class="c1"&gt;#we do this because whenever the player's total is less than 11, you always hit no matter what&lt;/span&gt;
    &lt;span class="c1"&gt;#so we don't want to waste compute cycles on that subset of the state space&lt;/span&gt;
    &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="n"&gt;player_hand&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;&lt;&lt;/span&gt; &lt;span class="mi"&gt;11&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;player_hand&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;add_card&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;player_hand&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;randomCard&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
        &lt;span class="n"&gt;state&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;player_hand&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dealer_hand&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;status&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;rl_state&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;getRLstate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;#convert to compressed version of state&lt;/span&gt;
    
    &lt;span class="c1"&gt;#setup dictionary to temporarily hold the current episode's state-actions&lt;/span&gt;
    &lt;span class="n"&gt;returns&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{}&lt;/span&gt; &lt;span class="c1"&gt;#state, action, return&lt;/span&gt;
    &lt;span class="k"&gt;while&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="c1"&gt;#while in current episode&lt;/span&gt;
        &lt;span class="c1"&gt;#epsilon greedy action selection&lt;/span&gt;
        &lt;span class="n"&gt;act_probs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;qsv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;rl_state&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;av_table&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;&lt;&lt;/span&gt; &lt;span class="n"&gt;epsilon&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="n"&gt;action&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;randint&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;action&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argmax&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;act_probs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="c1"&gt;#select an action&lt;/span&gt;
        &lt;span class="n"&gt;sa&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;rl_state&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;action&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
        &lt;span class="n"&gt;returns&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;sa&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="c1"&gt;#add a-v pair to returns list, default value to 0&lt;/span&gt;
        &lt;span class="n"&gt;av_count&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;sa&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="c1"&gt;#increment counter for avg calc&lt;/span&gt;
        &lt;span class="n"&gt;state&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;play&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;action&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;#make a play, observe new state&lt;/span&gt;
        &lt;span class="n"&gt;rl_state&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;getRLstate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="c1"&gt;#after an episode is complete, assign rewards to all the state-actions that took place in the episode&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;returns&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; 
        &lt;span class="n"&gt;returns&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;calcReward&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="n"&gt;av_table&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;updateQtable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;av_table&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;av_count&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;returns&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Done"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;&lt;div class="prompt"&gt;&lt;/div&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;Done
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Okay, so we just ran a Monte Carlo simulation of blackjack 5,000,000 times and built up an action-value (Q-value) table that we can use to determine what the optimal action is when we're in a particular state.&lt;/p&gt;
&lt;p&gt;How do we know if it worked? Well, below I've written some code that will show us a 3d plot of the dealer's card, player's total and the Q-value for that state (limited to when the player does not have a useable ace). You can compare to a very similar plot shown in the Sutton &amp; Barto text on page 117, compare to this (&lt;a href="http://waxworksmath.com/Authors/N_Z/Sutton/WWW/Chapter_5/op_bj_results.html"&gt;http://waxworksmath.com/Authors/N_Z/Sutton/WWW/Chapter_5/op_bj_results.html&lt;/a&gt;)&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In [258]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;#3d plot of state-value space where no useable Aces are present&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plt&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;mpl_toolkits.mplot3d&lt;/span&gt; &lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Axes3D&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;matplotlib&lt;/span&gt; &lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="n"&gt;cm&lt;/span&gt;
&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="k"&gt;matplotlib&lt;/span&gt; inline
&lt;span class="n"&gt;fig&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;figsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;ax&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;fig&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_subplot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;111&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;projection&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'3d'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_xlabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Dealer card'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_ylabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Player sum'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_zlabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'State-Value'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;z&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[],[],[]&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;state_space&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;&gt;&lt;/span&gt; &lt;span class="mi"&gt;11&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;&lt;&lt;/span&gt; &lt;span class="mi"&gt;21&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
        &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
        &lt;span class="n"&gt;state_value&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;max&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;av_table&lt;/span&gt;&lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)],&lt;/span&gt; &lt;span class="n"&gt;av_table&lt;/span&gt;&lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)]])&lt;/span&gt;
        &lt;span class="n"&gt;z&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;state_value&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;azim&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;230&lt;/span&gt;
&lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot_trisurf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;z&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;linewidth&lt;/span&gt;&lt;span class="o"&gt;=.&lt;/span&gt;&lt;span class="mi"&gt;02&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cmap&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;cm&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;jet&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;&lt;div class="prompt output_prompt"&gt;Out[258]:&lt;/div&gt;
&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;&lt;mpl_toolkits.mplot3d.art3d.poly3dcollection at 0x1105d2358&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_area"&gt;&lt;div class="prompt"&gt;&lt;/div&gt;
&lt;div class="output_png output_subarea "&gt;
&lt;img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAcwAAAFdCAYAAACO4V1gAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz
AAALEgAACxIB0t1+/AAAIABJREFUeJzsvXm4JGV59/+pvbfTZ5l9ZVaYYR+YAQSDIIbFBTcS+ell
3ENUYvRFQ0zM4uvvNS4xJkqiXOovvtGokGhEjaKMgoLILggzwwDDzHCYmTPrOaf3quqq+v3Rp3qq
+1R3Vy9nm3k+18XFnO7qp57qrqq77vu57+8teZ6HQCAQCASC5sgzPQGBQCAQCOYCwmAKBAKBQBAB
YTAFAoFAIIiAMJgCgUAgEERAGEyBQCAQCCIgDKZAIBAIBBFQW7wvak4EAoFAcLIhhb0oPEyBQCAQ
CCIgDKZAIBAIBBEQBlMgEAgEgggIgykQCAQCQQSEwRQIBAKBIALCYAoEAoFAEAFhMAUCgUAgiIAw
mAKBQCAQREAYTIFAIBAIIiAMpkAgEAgEERAGUyAQCASCCAiDKRAIBAJBBITBFAgEAoEgAsJgCgQC
gUAQAWEwBQKBQCCIgDCYAoFAIBBEQBhMgUAgEAgiIAymQCAQCAQREAZTIDgJcBwHy7LwPG+mpyIQ
zFnUmZ6AQCDoPZ7n4TgO5XIZ27Ypl8t4nkcikUBRFFRVRZKkmZ6mQDCnEAZTIDgB8DwP13Upl8vV
/0zTrBpHWZZxHAcA27bJZDKkUikURUFRFGE8BYIICIMpEMxRXNfFcRxs28a27Wq4VZIkJEnCdV0M
w0CWZVzXrb4ny3I1POt7n0HDKYynQBCOMJgCwRyhPszqe4wAsiwjy3Lo9v62vtHUdR04blg9z6t6
pbIsC69TIGiA1CIJQGQICAQzRFiY1fM8PM9DluVJ3qD/XrlcxnEcHMepGkBZlvE8D0VRME0T13WJ
x+NVD9T/fPD/wbVOYTwFJxmhJ7wwmALBLKJVmLXecAW9Tt/j9A1dqVQikUhUQ7KO45BMJnFdl7Gx
MXRdx7ZtVFXFMAw0TauO7xtff9++11nvxQoEJyihBlOEZAWCGSRo8IrFIkDVaDUKs/pepx9m9Y2Z
rus1RrWRV+i/nkql8DwP0zQpFovk83kMw8AwjJqQrAjZCgQVhMEUCKaRZmFWy7LQNA1VVWu2bxRm
1XW9a8MlSRKxWIxYLEa5XMayLDKZDIqiYBhGjRH252LbNpZlIcvyJCMtEJzICIMpEEwx9WFW13Vr
Qqy+F2nbdtUwNQqzxmKxKTNOqqqiqirxeBzbtjFNk0KhgK7rNV6nJEmUy2XGxsbo7+9HkiRUVRVe
p+CERxhMgaDHtMpmrTcsvtfpui6maVaTcxRFQdO0aoJPt3OKiiRJ6LqOruvVOeVyuerrhmFMWlP1
HwaCa53CeApONITBFAi6pFU2a5jx8L1O34v0vUxVVathztmALMvE4/FqyNY0TcbHx1EUZVJCkv+g
4DiOSBQSnJAIgykQdEAwzOobvbAwq0/QmJTLZeB4mNUv7SgWi9MS1uxET1aSJDRNQ9M0PM+jVCpV
w7IiUUhwsiAMpkAQgbAwq2ma1SSdRmFW/zPBbNZYLDbjIctuE4U0TcOyLJLJZOREIb+ERSgKCeYq
wmAKBCFECbMCNYbPN5C+kexlNutspZ1EoaDXKRKFBHMRYTAFggn8G3q7YVbfCAA1NZEn09pdlEQh
/+HCDwlblkWpVCKZTFYF4oXxFMxmhMEUnLR0ms3qe5G+gfXLPcQNv0KjRKF6RSFZljFNk3g8jmVZ
IlFIMOsRBlNw0tBNNqtvWP1QoqZp1W4giqLM0BHNboKJQq7rYllWjaKQLwIf1LIViUKC2YwwmIIT
Gv8mbFkWpmnWhFhbZbP60nP+Wlt9mNWyrOk+nFlDu5m2sizXKAqZpkk2mwXANE2RKCSYEwiDKTih
aBRm9T2cRCLRNMzq10QGyz3ETTqcTr8XP1EoFosxPj6OZVmRE4WCHVQEgulGGEzBnCZqmDUoSF5v
IIFqmHUqpecEtfi/S19f36REIT9kW58oFAzZikQhwXQjDKZgztFpNqvneRQKhWpNpK+q02mCSfBG
LuiOsEShYrE4KVHI/879iIFIFBJMJ8JgCmY93WazBqXnTuQwq+s45J/bgfTkY3g7nyJ3bATj77+C
rBvA8RCq53mz9vhbJQqFKQplMplqiFckCgmmEmEwBbOOYNJHJ9mswQ4ffpjV87yq9NxsppXHmn/h
ebzHH8J7+im8Xc/ivLAXd+Qw3tFxnKyF4hzvfKtIUDolQ/JP/7vqYffKI+7FOK0Md1iiUJiiEBz3
9kWikGAqEQZTMCuoD7OWSqXqGlWjRsr12aytwqyzPXwqSRKFkX0oTz0BO5/AeWYn3gt7cQ4ewj0y
hjteQimHt4KXmHwxKx5Id/+C3Jm3IF/4TiRJYmxsrKoH24v5Thd+olAikZikKOQ4zqSQrUgUEkwF
wmAKZoRWYVbf+/A9wmaNlOd6mPXQQ/ex8x//D7t++ySXHcjQF7KNPPFfu9j7YfHtf834xitRFqzF
MAxKpRKe5zE+Pl4Nc86V7y5MUchxHIrFIp7n1SQKgajtFPQWYTAF00LQ4PleZLMwazDE1ijMOpdv
emY2w3P//H/Y/p3beOGFY1WvcfsAbBnrzDiGYT0P3mku8X95NaW/fqoq/m5ZFvF4vJpco2kahmFM
qyfW7Vqqnyjkh2DL5XLTRKFgmD9oOOfyeSSYXoTBFEwZjbJZgYZhVr9ExDeSQW3WE+Hm9uLPfsTO
L3yanQ88QWlC9yB4RE+PwcoBWDLWm/0pJmTzMO/Fg9j/8Xb4k+9W9hniqeXz+UklHXOFKIlCwKSQ
rfA6Be0gDKagZ3SSzdoozCrLcvUmONcpHDzA0//4cXZ87weMHMyFrkEGediEqwwwzN7sv3gI6IO+
e/+H3KZ/R9v8lpr3G5V0zITX2S1RE4XCFIWASSFdgSCIMJiCjqm/4QQzMRtlswaNajDM6pcF+NuX
SqVpP55e4roue//z39l56y0889tnKE88O0S5DY8WYed8ON3szQVqPg/2KtAUiH/lfRTXXArawKTt
wko6CoUCnudVPbWg7utsMSqNEpiaJQrVKwq5rsvY2Bj9/f3Vh7a59KAgmB6EwRS0RX2Y1b+xyrIc
GsarD7MGGylPZ5h1KmoQw4QLxnftZOc//G+2//hnHB01IxnIMB4/AiuWwOCB7uepZCFrwlAC9EKZ
8udfQeGmB5t+xvfUDMOoNssOdhyZjrKSdmg2TjD87DgOlmVNUhTyP68oigjZChoiDKagKa3CrL4X
GdZI2TeSJ3ojZddx2P3/fZEdX/sKz+0Yxp2wJd0cpQc8MA5XDYF8rPs5lo4AKyv/Tux5kcJ/fwDe
/R8tP+d3Z/E9NT9c67oukiRV15nnCoqiNFQUguNGXIjAC8IQBlNQQ7vZrD5hogFBAfMTkWNPPsau
f/p7dt79azK5cs/HP1SAZ/tgvQay3d1YxT3gLgf/pxi857vkz38jxqY3RB5DkqTq+mCxWKyuD9Zn
pU43nXiq9eFn0zSxbZvx8fGakK2/rfA6BSAMpoDwMKt/E2qWzep7kb634d+AepE0MZt1WosjL7L3
A2/l6BPbyGZLjOV6VwZSz0OHYPVyUIe724d8BDIWDMQqfysuxL70dqzPXozWv7j98SbEz5PJJJZl
USqVQrNSmzFb1kH95QTTNEmlUm0lCgV1bGfDsQimFmEwT0KihlmDNAuz+k/dfkPgExXXcdj/mb/g
xX/+CuWCy2BcZkCBQQ2yMXgqOwX79OCeUXjNMjD3dT6OBJRGgSXHX9NzFuXPXwF/t63t8YKhS99I
+mudjeTr5gLtJAoF1aaECPzJgTCYJwHBMGupVMJ13errrbJZfSMJjcOsvkd6InPs7h/xwgffR253
pUDSBaSSiwEUNEhk4SIVCvGK4XR7uO8DOdjZB6vT4GU6H6c4TI3BBIjv3EX2tvdjvOlfupojVM6P
RCJRFROoNzb+OmGv6YWnWj9GlEShMEUh27ZxXbcqBD+XHhYErREG8wQluObiX8Se52FZVmh9Y1iY
1X9ijsViJ0TIyfcK2jmO4sH9vHjjmxn52WNIwWeClEw8VzGL8yUYBihDLAtbFLAT8GQWulx6rPLr
g7B2BZg5UDu0xt6LkD0X+gKBAEmCxA+/RuGMV2Gc+cqezLXe2NT3uZxLUnzQOFFI0zR0Xa9RFCqX
y+TzeRRFEYlCJyDCYJ4gRA2z2rY9KZvV/9xsymad6TVM13HY95mb2f+Fr2Ln3UkZr9KAAhMGExOW
pWDfxFqm54CahfNkcJLwVA5KXR5K2YW7RuH1K2F8T2djyEAhA33za19XXTD+5c2U/2E3anKwu4nW
EeZ1FovFnoZqe+VhtqJR67GgFx1UsqoXgQ8aT8HcRBjMOUon2azBhAXTNPE8r3oRd9tI2Q/zznVc
1+XoL37Ei//rRvJ7GuvTKX21WbFyDhb0wdHAOqbngpyFsyUgDU/moNjF1zScgR0pOGUx2COdjVHa
B8yf/LoxXqqsZ37ssc4n2IQwKT5fnKJUKs0KKb52DFkjRSHfUNaXpwAiUegEQBjMOUSjMGuUbNb6
ko8TJczaLcG12vz+YQ59+J0c3vp4bfg1BDUx+TUjBzEDSvWSdh6QgbMkkPpgWxE6rUL55UF45wqw
40Cx/c+Xd0PhdEiEKA4mtm0n+70/x3jDZ1qO043370vxSZKEZVlV0fSZlOLr5niCiULFYpFSqcTY
2JhIFDoBEQZzFuMbvKD0nE87jZRVVa12+LAsq6Zt1slGmMA7nsexL36cA18MD7+GoRqTX5M8mOfB
izQQLfDAy8JGQO6DZ0ow2uYip+XAT8fgjUvhwK72L2DFhXwOEiGRV0mCxH9/gcKZr8Q49bKWY/XC
qCmKQjKZbCnF1wjf0PViLr0ohdI0jXK5XC23iZIoJGo75w7CYM4igmFWy7IwTbN6w4iSzRq1kXKv
mYr1xl6Gef3vyPO8ahjQbxNWevBu9n7wveSeH21zfg3esGBpYD0z9LNUDOdaQLpAYtdhj2O7o+/7
+THYkYTVqyC7p41JT1AaARosVaoOGF94A+XP7kWNh3XmnBrqpfhKpVKNFN9MiSK0S7CPa9REIaEo
NHcQBnOGaRRmBbAsi1QqNWn7ei/SLyKf642Ue0WjjF9/HU1VVcwjB9n9/jdz8KePVEKmbSI3seVy
Dhb2wZEWdZkywEMea4G150vsyXocfqb1viXgFwfh3ctAHgK3Tek863kwTwOjgUU3jhUof+EquPn+
9gbuAX5yTCqVwvO8qqGpr4XsNVMlohAlUaiRopBt28TjcSECP4sQBnOaiRpmDXpsjdYhO2mkPNPZ
p1NFlIzfQqEAnsf+z36UFz//Zex85x6s1CKUqmUhHoNihKYrEsCjHquAVafEOXCoyAvF5so+xTL8
NAPXDcHeDKhtrIkqJuTyYDRxIOOPP0b2fz5O7FV/G33gHhOU4gsm1gS9ztmiFuTTbD7tth7L5/PV
xtj+Q7F4IJ5ZhMGcYsKyWf1QY6swK0ChUJiRMGs7zIQRbtQFpdl3lLnvZ4z8+Z+1HX4NQ25RJyID
gw4UJSJ7sBLA3iJLgJUJ2CfB7nxjw7lzFLYlYO0pcHhXe9J5fo/MhvOXIHnb31M842r0VRdOen+6
u5UEE2uCUny6rs+6zilRqD+eepGH4FIMUPVORaLQzCIM5hTQKpu1XvGkUSNloOc1kXOlBCTMCDeS
52sVis4/ei9HPvd37P2fh5F7ZNelCDJ4kg3LkjDcxOiFfg4oF2ARsCwOhxR4JmRNVAK2HoLVSyFx
DpSeiL4PK9AjsxFqGfR/fDXOZ4dRjNjkec6Ap1MvxVcsVlKFM5nMrJDia9fw1h9PMFHIH08kCs0e
xCNKD/A9wlKpRDabZXx8nFwuV6119I1k8MT2F/lLpRKFQqHaMknTNJLJJIlEpW7hZL4Y/JuDaZrk
83mKxSKO41RFvxOJRE3afj2ZO77Owcs3cvTlr0L50cMsGerh3KKuG+ZhcRe5M+UiDOXgpTE4LTVZ
ci9vw09sg/kFYGn0ceUs5OrLX0IwjmRx/7U3CkC9xk+s8UO3pmkyNjZGPp+vyjlGpVceZjfj+MfT
399PLFZ5QPHvJbZt1zx0+w+U/j2kPv9BMDUID7MD6sOsfualH2JtJ5u1WSPlTqTcZoJehWTDknUs
y0JV1ch1o45tk/3yxyl89d9wdmeROP5UaIyCpoNtdTdPVwW9DaF1JQupOOQ6qJv0KZegH7jEgIxe
kd3zj+vp/SZPnwXrk7DvcPRWYMUjMLiy9Xbxh+4nv/WzGK/4SKfTD6VX53aYFF82m62uGc6019ku
fuKTLMuk0+macptWiUJ+yFYkCk0NwmBGpFmY1XEcNE2rCbU2CrNGCSFOJbMt6Sco6RdMaPJvCL6n
3Qrz8AEKn7uZ/Hd+BMcq3kX9tyu7sDgBe60uW2UNgna4je2BfhsKMnQbDXdMSJpwsQ65GDyVqRzn
z16EVUMwtAnGHoo2VmFPbY/MRigSxL/5NxQ2/D6x5ed2dwA9pt7othKAbxSNmA0eZtg47SQK+Z8T
IdupQxjMBoRlswblrpp5kfU3f99DaveknW3GrRc0E3kPXvzBjOBmFLY/SuFTf07xzoeRImSkKmMw
bwBGG6vetR5jQILDbf4uZViSgL2F3lx0rgUJCy7SIL8Ctr8AWxfDaw9DfgPYT7ceQ6nrkdkMzfIY
efZ7rFhyFoqizPrIR5gUX5iIwFyiVaKQ71X69w3XdavH3iySJYiOMJgB/KzLdrRZgyel53ktw6wz
zVSJDDQbcypE3jN3/RfFz30C64HdSG4DZZ0GpAtwTKKl/F0j5GhO72QKsCwNB7to0VWPa0P8edic
AMuGnQlY68DwAMgtHgrCemQ23dfy7VXvBuja4EyXaLovxRcmIuAbGv8675ZejtPou2mWKBSmKFQs
FqvXqPA6u+OkNpidaLPWe5H+iSnLcs/bFs1VD3Oq1IdcxyH79c9S+PKXKO8cRaI9Q+kjWbB8CPa1
WfDvI0fwyBqhZCC+NE5xfxcLmsG5pGSWrnIZGoC0DPnFID0Fi9fC/kdbX+BhPTLDcIDyyt9hyMdQ
vRXVxJpg78dOmE5JuzARgXw+X31vqg3dVIzTTFEo2IO0PlHIF4EPeqWC1pxUBrPXYVZ/LdI0zTl1
0k2VEbYsa0rWa+3MKNl//Avy3/wu0qFKxk6337R6DFIpyOU6+KzaRnFlHRIwkDEpLQLvYHufdSVY
MAQLB6A/DjEFYrgVmb6J45DOhfwWSH0JBs6H3KPNxwzrkRlGOTVEPO1SLG5lnnxDTZu4sDW12U5Q
is/vYVksFimXy3NKis8n7GHATxQCaq5B33DWi8CLRKHWnPAGMxhmLZVKNYaxWZg1bI1N07TQz0yV
JzhV4dNeELzg/BR+13U7Xq+tR5IkSnuepvTPf0P+B/ci5b2ujWTN+FSE0seBdn0juUNjWf18zmXh
KbD/ECgNhnKpGPRFQzCUgpQGOqC2+BLkNMgbwHwVDP4PFFeD00SntlGPzEnzGZgPFChIdzGPGyqf
nTA6foKNXyLlhwunQ+C/W4/ONzT++iBQla6LKgDfy/n0Ypz6RKFcLkexWMS2bZEo1CUntMG86aab
uOmmm6q1WkHjF6RRQfxsaKQ8WwjTsPW/y1gsRrFY7ElI2nUcCj/7FuNfvwXnrh3I5e69yUZIeVg2
D0aOtvnB1rlILVG3waKLJY7cP9FtIw3zz4L5iyUGd6vEHRu9kwPvA7kI+jvA3AuLd8NwvPJaIxr1
yAziDPUBBVztcUrFfcBA9b2wso4oXudsShzy1/d0Xa8Jb86UAHyvvhu/PCWRSFS1eZslCvkh23K5
XGM4Z8vvNNOc0AZzeHiYXC5HX1+lcjyYyFPvHdWHWdthqtRzZiJBJ0h9WQx0rmHbDNd1MX/538T+
80uov36M+cfKpFaBez4ceA68dg1aG+ijoBtgRSji94mSjRsF7TmPNW+H5QcgdhCUPLDLA+yOnxK8
/kqZiFsG7cPgfgQWnAWHH2pcStOsR2Z1m6E4ALICBfkudO+60N8/WNYRzOScTq+zFzSS4mt1HLPp
IcDHn5NvJJslCsHk2k7hdR7nhDaYAwMD5HK5ajKPv2ZpWVaNdyQEjStELfkIoxORhdKvf4Rx2y2o
9z5M/LBN8KPaPpBWwvpVUFgP+/eCe6DLAwxBdmFRDPaa0Wsz5UL3DzHSmXDaORMiA6Pth4XDcD2Q
+0HXoXAUEkug+BGI/01z6bxmPTJ97MHjt4qishWd65rOpT6TM8zr7AVTHQKtP45SqdTUe+7VA26v
DW99rWqrRKEwr9Nft260NHUycMIazOHhYUZGRvjYxz7GY489xm9+8xsSiUQ1vj8XslmnMkvWvyCn
ouSjGYUHfoLxnX9Bu/dB+g+ax41k3W4Uu6LIY8SgrwynLoXCKhjZD6W9vdV0VMZhwSAcjajJLo13
tz/jClgzANrE/sYvkDDu6/53tg2IJyv/lirJn8TXQf49MO/LsG8xMBL+2WY9MgHsecf/XVYfxnKO
oGnR6lEaeZ1+sslcwW923awOEnqTJ9BLg9nsYaBRolAjRaHx8XGSyWRV6vNkE4GfkSO988472bBh
A+vXr+fTn/70pPePHDnC1VdfzbnnnsuZZ57J17/+9Ujjuq7Lhz70ITZu3MimTZvYs2cPmzZt4u67
72b+/Pk1TVt7yVws//AvjkKhUF2PTCQSVX3WTjLmGn0HpUd/gXPT65C3LGTwujeR/O6v0A+ZtBpe
eRGKE0NKEiRtWLsA1rwEEusn66p2QzIPbqr1dh5AhyFiF+h7E6yLgRZYU0zt9cgu72zMGgL1oXJg
nTV5OVi/D4sWg9Xgijd3SzRznO2h43qCsuJgqve0PT3fW0un06TTaYCqx2ZZVkfX0Ewk2dQfhyRJ
ZLNZMpnMrGxsEOXYfEeiv7+/2os0k8mQyWSqNeb+fc43or53appmdbnrRGfaDabjONx4443ceeed
bN++nW9/+9vs2LGjZptbbrmFTZs28fjjj3PPPfdw0003RRJTlmWZDRs28M1vfpNDhw7xrne9i40b
N7J8eS/uRtNPrwxxsHGtX3cGYBgGyWSSWCxWDbN0M9cgpd/dR/nm65AvWkT/a19H8vZfoI+UWhrJ
ILIHbkjZR9yGU/phzUWQ3gjtyWw32JcFS85qffxeChId7LAMLL0iwarM5MxYxQF5afeyeV7A4Osx
yB85/nf8neCthAXnh39WLXkMGwPhbwLWUL7mb1u/u5upVr0T/wGtVCoxNjZWfYCbK/jHMDAwQCwW
w/M8stlsRwLwQabDw2yE39xgYGAAwzBqRO3DyvBOJhH4aQ/JPvTQQ6xbt45Vq1YBcP3113PHHXew
cePG6jZLlizhd7/7HVCp8Zo3b96klliNuOGGG6r/TqfTZLPHVbLnYui0E5olNcViMQqFQtcGMozS
9gcxvvMF9Lt/SfqFPHKDcGs7aAcgl4RUyFTj5Ur7rPkXwhFb5+hTFloXwuqx37gYp4O5vfE2yiDV
mseoeDqc+hJIGYWG2yRfhPELoP+R9sauIeBhShLIGarZr7IM2k2g3Ay508DZOfnj+WMKhHjZngfm
/HGCeg1u7CHsbAaDBV1M+HiGbdgaof8gNx1rZb0oT/HXM/v6+rBtuyspvl56zp0Stg4Nta3UGiUK
SZI0qUPTicC0G8x9+/axYsWK6t/Lly/nwQcfrNnmPe95Dy9/+ctZunQp2WyW22+/vaN99ff3c/jw
cZXs2WbYWhF1vq1KPqZygf7QU/eR/s8vk9j6C/QXcsdDFj3anSQBo+AONhYJNxxYJlsM/Z7EwQGN
7M8s1Da6iVT3BcwvwgtyJREmDCXdnmiBOgBrNkMsQo5LLAOlJMTyrbcNw6trIybVdS3R+qH0EVjw
/8L+9IRBDWD8Not1Ceh137OV6Cc2WOstKapNSf4lqRbJP03nGyKcHlwjjJKZOhuzUuul+EqlUmhS
zXTS7f78RKFSqUQikWiZKATUKAr5a52z7bdql2kPyUb5wj75yU9y7rnnsn//fh5//HHe//7313iK
Uenv7yeT6aFwZwNmwhAHwyCFQoFSqYTnedV+mvF4vGHiTrfztUYP4vzrh1Bfs5pF73k96gs/ACU3
ZSeTcYym62s+8XGPVXstTt0EAy/rwzXa35e2Gxa+pPGRKPHoYyWXw6kXRjOWAEYOrE1d3FDqvENV
g1Ld6R9bC+7bYcFpk0PZycMW+/V51OMOhhdpltS7Op9rE+rXCP31tGw22/FaZyumYi3UT6rp6+uj
v78fRVHI5/OMj49X+99O53x6NZamaaRSKfr7+1FVlUKhUD0mXzkoGLL1y1hM06yGbOcq0+5hLlu2
jOHh4erfw8PDk9YY77//fv7qr/4KgLVr17J69Wp27tzJ5s2b29rXdIVkfaYiFdyfr+9F+nWR9SUf
U52pVi4V8X5wC8Yd36D/d3tQJ7yX8XV9xDUbeblLeRk4j4LRG5nUGpSDYC8GLcJhGgVYQpYFZ0HW
hv27QG4jjJp8xGVsBTjDk9+Tm9QqBhncAEtXgdLmz5La7ZFZpJM+2H5sud7DVFWwRoF07euJl8H+
g0OUFsikfnyk5j0ntwxitVlNzlA/cGjS/hzj15StAqrSqRp9a1p5nbMpYtRsLmEC8OPj4w29ztls
MH1OxtZj0+5hbt68mWeffZY9e/ZgWRa33XYb1157bc02GzZsYOvWrQAcPHiQnTt3smbNmrb3FWYw
p4KpGtevgfJvEv4agq7rNV7kVBlL13Up3XM7vO9SkpcsZuhvPkHy0ePGEqDcLxNzXKwExBWIXQjm
Gd0nsNSj5sFuc0wVGNRgw2mwdFOlj2UUZBMWDkqhWbitvmoXWLYFlq9u31hCJdFJHYRyJ99f3+SX
5AaCDIuvO0Z8mcv42bUfcreNTvrtnKFwgyirJfLePR1MtEI7xi7odfb19VW9TsuyepJk0kvD0myc
Vh6a7331sp6zVzT7jpolCvl5FPWJQn6S11xKFJp2D1NVVW655RauuuoqHMepZrLeeuutQCVp5y//
8i95xzsFxUYoAAAgAElEQVTewTnnnIPrunzmM59haGio7X2FhWSn6kfppHC/nrAuH0DPvchWnnZp
+4MY3/o0xj33kj7cvPzDTVjgVnROLa/y/9R8KL4crCcnOStdIe8DcwUYbX4NigT9CqTWQN6DA8Pg
tmgAbfzOI705Tu6RWndZbnL6uCqsvxiSEcpTmpHIWBTSoLabXJSe/JqiQNkEtS48Lcuw9O3H2Dc+
RGm3TCxbOdfUvcOMXbCSIeeF6rblwcZudUG+i35e2d5EA3RyvQRVeHK5HOVymbGxsRlXE2r3+g8K
wPtJNb4UXy/vU9OZbRuWKNQo+clPDvK9Tn8JaTYzI8IF11xzDddcc03Na8Hs1vnz5/PDH/6w6/2k
0+kagxkMDcyWMEAwzFrf5QMqdWqaFjEO2AWlkT1o3/oUxl0/Zmj32HHlmVZfU8yDAugeFBKgT9iX
uAfOmVAsgvIwqD24/hULbBvoYG0SKoYzLUHfSsivhH2eSvmxcsMwy8BzFtn+WqEC2Q7fVu6D0y4A
o8O51aOnoJSvfL1R8FV+6tE0KBwBddnk9+JJGHxnnhF3CPe/jiBT+blzxcUM6ccNpjWv8SRM9R7K
dglV6aLnWYf4Hosvnu6HBNvVfp1pz8bPKA1K8eXzeXK5XNcPATNZnhIUrAhTFPL1e+dSMuYJq/QD
EI/HKRanYEEthHYyWpuVfNSvY0xlGUy5mMf7r88R+9F3GHzqRdQOyt+kQFGh7kDJg9jEIShAKg72
y6C0B2J7up+78iIU10C8i3uAJFXyY06TymReL3FoHMxfeJMMpzrmsOQimZEHAjHK4uTfQz09xvrl
JbQeXk2qDPYgELFnp61DvIFnKzWuZmHeYpPctTGsoxuQ7366MtauMThe5YU91OApAVC0LHnz1/Qr
V0Sb6BRRb3A66TjSrWHphXHyPbFCoUAqlcKyrK7ap82kwfRppCgEVJs2zJW1zBPaYDaSg5pOD7MX
JR+9nK/rOJS3fpPY97+K8ej2qkfYKcGVPlUCKwnU3aA1D5SVUFoB3sOgdyFeLrtQzhG6XtcJ6WGP
NJB7NRx2JHJ3ejXesPGAS+xMKD1V+VuqS9ZOvl5ilVVq2KarG2IG5A1IRhGGTzZ7U8F1nYbrr6ec
Pc7oladzbM9ylN0vIu14huyZC+hzKnHr4kCuqdZtUdlKP+0bzKm4DoMhwZnuONItjaT42vE6Z4PB
DOKHoXVdZ2xsrLoWrSgKg4ODs15m74Q2mGFMh3hBWJcPVVXb7vLRUyP5q++Q+9V/sujOe+kfbewx
tItSl4ljlKEgQaLuK5YlSEhQvgiKh0F/snUCTSO0A3BsucbQeO+OIzUCKTwKV8KRmMTYnR6aOdE3
MwsvqKCUQZrQf3WBBe+QWDritaVe1A6SVKmdLI9UPM5meE0MZtxwOGDGWRJv/HTUf9VvKB+7nPHP
H0AtO+TdtfRxGM8De2Fzg1lSfoHjlFHk6b+dtEpEieJ1zvaM1LB1waheZ6+Tfno5lizL1QcC27Zn
vbGEk8BgTpdKiF8X6WftTWfJRxjW6EHkn3wJ494fYWx7Dj3voq5P4Q7YEFFkvBWeB4pZG8dVJCDO
JC/TR/UqzYpLL4dSh0lBkgSe6eG6nRvdRiSOwko8FlyscnjQYewuD20vLLpE4uADHloGygk45S0S
8/Z5U9escwJdhcIAqK3KiZt6mFB0k0BjgynLMPD6X2Meeynlr/2S4t4CrAQ7lkIfLNIsoV7Rj5LP
PUhavqTFJGeGVl5nrxJNpkOdJ7guaNt2QwH4IL0udesF9Q8E7YaaZ4qTwmC6rjtJwqlb6rt8wPFs
1l7G49sJIZd2PoTx4y+jPvBL+ncfnrQmqcgm6nooP18Jn3aLmYCkw6R7qVGGvArJJlKaMQ+0M8Es
AI9UwrbtkH6yzNGXqSzY3wsl2cnEs2VWZmHxJji6SML6tYd2OqjjsPYKidS+6UtSMBITCUBN1pi9
Fpm58bzV0qhqCYvB63YysutsuG87hZUp5MEFyI0ynQLkvDvp8y5u+7yf7nXDoNfpJ6H42ejB+8Rs
oFV5SrBpd31/S7+Z+2wLyTYbSxjMWUAqlSKfz1ebSHdqMMNKPnytRF3Xq73iomre9gLXcSjf8x8Y
W/8D7be/JXmodFy/NQRZstGBwiZQH+9+/+VBhZg8+S6uSBMF/i1smQIkEmC+XKf0jEUsRCigGdoe
F0uvlLJMFXoBluz2mL8a2ASL+8B4Ynoz+hQZ7IFKKUzD+3mLNd0FhQxjpsqA0fxHSS4ZYfB98zm8
vY+sspbUoAO0qMEBTO3njI5+qHqzjnIdzGRmpCRJ1aJ739h0u9Y5U6HdYH9L3+v0s1GBnj0E+GHU
Xo0VPMa5YCzhJDCYvniBbzCj4odZ60s+/AtqunQR6w28dewA8o8nQq3bd6EHNeNaTWeiOkVfSMXQ
dCFUDlDuV4BwtyfmQE6DVIRlRqNsoa0Gczm4j4EeJckFSO51GXu5xoLh3q1lhlFKQ+ldEmuGoKyB
u8Ejo0i4I6A85tE3NqW7ByoJQNnl0Lc//H23xemtyjDq9jMQoTfZ0KlPUfzfF1P4pknsomhagGrs
EGpyF5JzBtlstuOszpnAL+VKp9NVY9Nuhm0v6SYb1fc6XdfFNE1KpUqGnSzLXS8PzVZvdTo54Q2m
L16wdOlSoLmH6XuRvpGExiUf9UxlLVFpx/0kfvo19Ad/SXz3UdQOVXS8iV9bBUqbgfu7m5fT1+z7
qNykXTPaOqMsQVyH8kugMALG9mifiz9eprgE4l0a/zBcF8ZeLZE812PA8chqEvGFHgxD2vVgHjhX
QC4G0oMgjYA+DuoU1V7HNLBU0MOcxBbhVgC16FbWlyOw5IL72bXvYvL90QtLS+pdLDS2VNfXfJ3j
qRQU6LVCT73Um+91xmKxlqLps8kI+FJ8vrZruVzuWgB+Kg3mbPneWnHCG8ww8YJ6fdawkg+//dVM
/ZCFu75OYut/kH78cWIt1Hai4HkQTHXUUlAagFgX3pEbl5qGXWMe5GOQbMOYqR6kF0FxAVhPQaxF
gpJxzGPsbJ34vt5azNwycN8iMYiHNOFEe2qlxnRso4yxY0KFSYaUBWyqbGPloHgAvAPgHYJkD5+h
NBuKq4DnJr/nhYgW1LMgN04hBYkIMWxZhpWveoTfHXwJERUFKcpb8byPTlpfayQoMFsMTNg86tc6
C4UCnuc19TpnY7YtUP3egzWQrY5lquc1W377djnhDWa9PJ5vJEulUlclH/X4yUW9YPyFexj8vx8g
6ffV7sF5ZakQDwgGKYB1LnBPF4MatFyn1GQoe+0nGcVlcM6GYhaU3zZXCkr9xiK7Efo6bIsVpOzB
+PVJ0qvzaHURA0+WAI9k3K08CITUk+opYH3lP8eBQhzKBQlpp0dsG2hd/pZ6oZI1mwg86HgeSBEM
ZgyXvc4ApxDtKcmIWbxw6kXopXGSsSMtt5djL5DPbSelnVF9LZjVWV/a0Qumeh3U9zrD5OuieJ2d
MFWGqZkUX5R1W2EwZ0B8fbpJJpPs3LmTj3/844yMjFSFfv2F8mQy2ZMedb0Mycae/1eUy6HcwwiW
FJ8c4jQ0KCwP3z7SmM2EVSfQPSi10RIriAKk+kB+mcTo+Y2/DNWEktd9x4zsGVD8qMS8VfnwrN0J
dQJNBmdD63NFUSBhQVr16DsDnOsh+2aJscsgF6L7GgUFkOfVitubhkQy4hK9Z7V3Uh1LG3wp90lc
J9qzdVH+aejrfvZmf38/qVSq+nCZy+Wwbbura2c6Mm39hL5kMkl/fz+apk0STZ+NRqBRNmpQLF3T
NIrFIuPj4xQKhaojEWWsXs1rtn1vjZhRg3nnnXeyYcMG1q9fz6c//enQbe655x42bdrEmWeeyWWX
XRZp3OHhYb761a/yB3/wB3zsYx/j61//OpZVCdn5IQg/5DobiY/eT2w+2Of0bkw3JAwnSyBv6Lyz
iORF+6DhQTcBU8PzmJ9yyL5ZozgQvk36iQKFDnN/bA3GbpBJvBr6mt24A9d0n+IxNrl1ZFNiLvTZ
HgMLIH4lFN4CmddJZDeA3Ya9iBUnQrMT5BZEfyIZyOXb+r33J2WOxuLcOfrhSNsX5a0tt/FDnf6/
fcNTKpXmRK9E31NLp9OkUikcx2F8fBzLsnAcZ1Z1Tmk1lu9B+w8yvvKO3wkmeCzCw5zBkKzjONx4
441s3bqVZcuWsWXLFq699lo2bjwuYjk2Nsb73/9+fvrTn7J8+XKOHGkdFgL40z/9U+LxOK9+9at5
5StfycjICDfeeCNAtWay1/TKwywc+TELpUoIWbkM7G2gRcwabUqDCFhMhsJZkNjW/pByxH5bGpXQ
ZDcyfDIwtM/GvERizFFI/7hc4zHLQPkYuAvaEzMYuxj0y2DAiXAsAY9akkA7RcI57HXUxkuRKt4n
mgdnQekcKMoSHPBQHoFki04lugemAYYJ5pBOQ6WIOgacEpniGtLJ51tuW3ZkDhsap7qjfCt9KaeN
Pcnagf9p/iFjJ/ncMyT1UyPNp75HpJ+YEovFItUz9+LG201WqqqqVY/Z75wyPj7eVYbtTBmTemWk
qew9OlcN5oy5WA899BDr1q1j1apVaJrG9ddfzx133FGzzbe+9S3e+MY3VhtMz58f3vm9nu9///t8
+9vf5m1vexurVq2a1ibS3aK8+MVqgo+eAru9ntkN8ZosGWnLoNzmmRCm8tMMX5i9W4ycx4JimeJb
VLKray84PQPFiK5sKQ3jH5RIvxQSHYjOAyRlj+za3lz0MRfSZY/0AohdDYVXxyiugUIyvDem5sCR
syoubjnd5o9nL4y0WVmajxzT8OT9HFLhq8p7KJbOaPoZSZIoKq29zPrPBHtEKopCLpcjk8lQKpVm
9fXqE+wylEwmq15nL0LO3dCJYfLD5+l0mnS6snbg54HUe529mtdcMZ4zZjD37dvHihUrqn8vX76c
ffv21Wzz7LPPcuzYMS6//HI2b97MN77xjbb3E9ZEeqq1ZDvFcR0SLz5W85p+CVhd9lcEkJp0CNMA
a0t745kJSLURPVOl5nqn7TKwv0x6rcfYdRp24FqTjoDdxAC6Lhx7pYR0I/QbXlOhh3rCNo0PepR6
XC2hSJCIl4ifD4lXgvM6KL0CihuhFAitL9l/lOF1fTj97V3GaqG1EAGApVQeULNGnlML4zyWMvjX
wp9Rtpob3KJ8V1vzCeKXQ/T391fLU+obEfeaXno7/nJPqwbR0zWfbsfyk7b6+ytZZb36Peaqhzlj
IdkoX5Zt2zz22GP8/Oc/p1Ao8JKXvISLLrqI9evXR95PWBPp2Yp1+NsMOLVxSzUGhYtB/1l3Y7st
WmrqaTBTYERsWlweClf5abqPMuRlSPZomUq1YcFhm8JVBqXfmsQOglYEywQtJAcovwSct9aWikTF
dcMF0A0ZxjdIxLZNnQdhGFRC6oPgbIRR+hhzDIwdRfRRl0KivS80bu8iW5hPX6L5EkdJrTRtlySJ
s6VRnpMGebBvOd/Mvpc/6v8kshK+aOxqT1Io7CWhn9Jw7Chra/WlKWGCCLPpxls/l2BWarCus1Ut
5GwymEEkSaKvry+0MbQvxdfpvGbLb9iKGfMwly1bxvDwcS204eHhaujVZ8WKFVx55ZXE43HmzZvH
pZdeyhNPPNHWfuaSh6mPfDX09dhmKA11NXTLRyNVAve86MOVB9p3qxQJpCnoM5womiRPA+t8MDVQ
DkEpYEMcD0bfLKG/DdJSZ91FbBkSDXJrUjGPrDQ9z56KAoNKltX6EZaek4crYdd57Z0ckgSuvarl
dgX1eAVmTBkBIKPJPGls4e6xtzY832UFivLP25pTM3wvZ2BggFgshmmajI2NVesJu2WqjW59yFlV
VfL5fMNEp17dn6ZqzTHodYZFAaL2BZ4rRjLIjBnMzZs38+yzz7Jnzx4sy+K2227j2muvrdnmta99
Lffddx+O41AoFHjwwQc5/fTT29pPvcH0mao1hU7HtW2T2P7whwFZhfKlE+IDndLCwwTQDRg/JVp9
nJPq7GSPlSE/BUo4sgTJFBgXgrUcCnol/pvdCIW/lBhc4bUt8B6kmYeuSOCumkpF23Cyms7vLj2N
Iy9bz0MD69r6rFJqnUmWVY/XvozpoyzKVyI125Iq90hXsDf32oafLSpdhkRC8L1Of23Nv9ZyuVzP
1ta6IYoR8L3O/v5+kslkNUmofq1ztnUYaVSeous6fX199Pf3I8tyzdpzs/CzMJhtoqoqt9xyC1dd
dRWnn346b3rTm9i4cSO33nort956KwAbNmzg6quv5uyzz+bCCy/kPe95T9sGMxaLVfUUYepc/27H
dQ5/hZjVOE6YOBPMpZ2N7XrRMkcVCcqXeJHKDrx4Z8crSyDrnZeytEJTIL0SyueW2PtWSFwLfW4P
utO0UBxIDxXIT34umzJGY3Huv+IsWJ5gvp7l8xvexa549BMkVtxJsdjc3R9XA4vOssQW6bjgwVN9
A3zZu5pcITws4WiPUbJHGo7di7W1ZLIyP13Xq3WEUdcJezmXTmjkdWYyGWy7N9rI0xnaDa49JxKJ
hg8C/lj1zBXjOaNKP9dccw3XXHNNzWs33HBDzd8f/vCH+fCHo9WARWWq1j46GddXHtIO/N+m28ky
OJeB+y3aSlSBSp1hLKIDNHTY4shlOgt+1SLdVAc6vK5jDuQ1SHWYndoIzwNTB/OCJP0X5CkuUVCe
7M1OvBYeuiSBug7Kw6BOsbN5KJHit684HXmosiNNhXXyAJ/bfDOfeeCfSdmtS0ZU2aLobgJ+23Cb
g3V9YPqlg8BKAIqaQt5eyaf4Q/7OOoiq1ybsyYpLQfo5Md7S3sG1gX/jNQxjkv5rN5qp3cynk33V
r3Xm83mKxSKO43R1DDOxFuo/CGia1lCKz99urhjJILOzcn+KmenSEr/ZtC9OncscJHHgmZafS64H
c00HO2xDaUeSILbYxW4VNpW6UWYBVe2dl2l7UFwIhddD7CPQ/7I8qgGxZTC2sEc3jAjafsYKaKPS
piP29w3y2yvPrhpLn9ON/TjqOj513nsx5WiKCrLV/ClgNF4rHzSmHyZdPK4/+GxCRXPW81X7XTjl
ySdZQe59WDYM/8YbVOJpRxBhOho/R8E3Nn4tpKIoVa+zE1GHmU4eCgo81Jfa+GPONU4KgzldTzKN
DLHfBcV/2vIXx/0whpH5GroT7eTxXg5Ou4fTpmxn31iZ0de0ys7pztrFgFIXcqKOBGMbVLJbFKQP
QfzdkAxE620Z4nEF8xy1J4bZjXil6GdBaYriNof7N/DUVWchD0yezJCyjf3SELvmD3DrWR+g7LXO
rlJzz9Es+ndQrTWongLn28dqXnskEecFTmFr8d3UCz+VtQexyi3U86eA+ht1MDw4VaUpPr0yvO2E
OJuN0yu6lS70w88DAwOoqorneTVSfHPF2zwpDKYsyzX6iNPhYdZ7kX4Btq7rJJNJ4vF4tT+dPnJ7
5HETy8Da2Hq7GjowTH2eSaGBDB2AElHlpxmqDO0OUxiSOfoKncKfwMAbyvT9voMaUkLie4TxlMTR
U3uQZdRM/T2ANgBmBJ3Zdjky7wIevXoBUoPiVyl2kDiH6Css4MGVy/mvU2/EcZvPw/COYZY3hL7n
uHDImOyBLlFrS1FsReaIspgfxtbzbOEPat5T1DJ5wrNle6XQ04xGggjj4+OYplnTtWg2dRkJjhN2
DO14nbMteSjoRftSfLlcbs54myeFwZyO0hJ/PNu2Q73IRiLvZvEAiUN729qXdDmU2/BivA7W1OJF
j/wrw70UzwOl1H3sUQfsCGUmjgKjZ2sc/X9UtHe5zLvAoq9Fz6ma7+dUuabMpCPauFekdI9se/3K
mzKy+FIevlJDiTc+ZyVJ4jJvF6PyYgB+uGEjdy95W8vMarkc/kXa3hBeYvKTVk4/hGrWtml5IaYw
WFzOP8V/j7HCS2re60bEIApRb+L1ggiWZVVLIebMzbqJ1xlWzjHTIdlWYwVD6MLDnEX09fWFlpZ0
S70X6XcsCPMiG3LgH9DavJnH5oF1dhsfiFBSEsbgaImxNZPnbiYlUj26x2iA1WCs3EKZI1frFN8L
g6+2mbe6jBbxWNzAmqNhSIxv6fBL8GnjSlFk8NZ2v0breTC84gqeuLKMarS+oaySd7AjLhGfsNZf
23wJ2+e9vuln5NyB0NdtdUHo62XV4aLy+KTXH03GGMgm+XvlDViBhXZbuw+rPI3pwy0IlkKk02kk
Sapew0GvsxOmy1ONKiU42w2mz1wxlnCSGMz+/v6eeJit1iJ98eJ2str0Az9oex4AyuVQGIzY+LVD
W6E64Fw8+cP2kNKWwHkzNAnKAS/T1mB0s8boHykk3uky/zyLVAetsNy6JB1tKeQ6bDMGILWZ5JRW
IbOs8/15HuxefxXbLy9GFvBW9GfotwoU5IrkpCzL/P2Wq9jf93sNP2NYe8gWJpejWGrjxKGV0mSF
IFeR2RdbTBGDW8pvw7ErRltWTfLePZO2nw2CA34Bvn/NBgURGrW4mg7aOa56r3OqpASFwaxw0hjM
oDxeOwaznbXIdg1xKfs0iSMH2z4eACMJ2auixVq9LpJQhg6aHLqgNjTXrnZpK1Rg3xo4+hoN+70w
eKXN4HKnK6NcLzSgqhK587v0MtvEWNJe2y4fx5XYefo17Hppvq1uF7Lq8Ap7N9tiEka+srDr6Rp/
s+V6xozw+mVJAsldOen1gtp4AdtUD+CFZAsdjCmk7VXsSs7nB8V34zqVuef46ayvvdM0rUYQIZPJ
kM1m2xJEmMlifN/rDIoIWJZVvXfNpZZjs5mTwmCm0+nIerKNvMheN5wGkA9+rqtC2MHVJbJLW4/Q
jcGUJDDWuASTeDtV+QlieZBfDYVrwP4Lhfz7Usw7yybRA6F5CC8DMebB0Q4lBjs54rgMxXUXtPUZ
x1PZcf41DF/YWRjzLGknriLjcNwIFpMxPrHl3RTVcGEDpThZQDij9DfcR1G3OKdwNPS9h5Ma88fT
bE2v48lCpQazrN/LkaMjM+65NSMo++Y3Vm5HEGE2tb6qZt9P3Kd64XUKg1nhpDGYzUKyUbzIKA2n
2/Uw9X3d1anpGhSvbJ4BWqaiftMN/cdsjr7quJfpdqjyU4xLFM8F8w9A+ggk3wqJLZDUHbz5Gofi
vav4d0MeEhRZwj5Pa3tt0XajCz/Uk+jfTlFvkaHk70eK8cSFV3LgnM6bBaTVbbiuy+9iKmr+uEc9
MtjP58/9U2xpcjaSXthBsVT7ekZt3lpmPeEGU5Ikno3PQy9JfDl5AYfzl6PqedS+39V4blE1R5sx
lfWTvqi431g5aruu2ZRtC5Xa1HrpOr82tZ3vX4RkK5wUBnNgYGCShxlUoZhKL7IRxbGHSYx2X6M2
b5nJ2PrGd3M3VjGs3ZIybEx/DTCi8XBdyM+HwqVQegfo/8sjfi0YG2u7iTguEJMZW5PumZiB16AM
JNEncWRde6e9oxI52ageVc5RjtBdx1bSPH7J5Rw9vbvOOpIxxoWFFykrEpJT2y1k25KF/PuZH8Kp
CzkokoPrnlbz2tGwWp3gftSDDT2uY7qMVq6so35Kfw2l0gZMbWvVc9M0DdM0cRyno4L8qaDZde6X
QNRL2AXnPlvED+rH8ufUbds04WFWOCkMZjqdZnR0lNtuu429e/dimmZoRmsUL7IZ7XiYysjnUHpw
zigKmJc3FmZv1ji6HRJ5l/FrK9k5ktz4GE0FshsMSq+C8p9B8n2QuAxiKypzDcPyJOJxhVhKZt9Q
b5pmNkt0kjYobZWZtGqN1oqE8TC5/sbi6Ka2gEcvu5ixdb3JJr2EXQBsixvIZu2X/otVp/DjNe+d
dL7IZu3JeFhrniGVTxQ5tTA5W9bniaTK4tx8SprB5723kvcep+xYSJJELBYjHo+jKEq1NKKTcOF0
33iDwunBso6p6NU53YLprbxO4WFWmHGDeeedd7JhwwbWr1/Ppz/96YbbPfzww6iqyve+971I47qu
y6OPPsonPvEJPvrRj/LZz36W22+/nUwmg2EYyLLccy+yHYNp7PtlT/YJsGChxeimBpaxRwYTYCBb
IrtUQqqTdMkMwaHXGhy9yYC/kOj7Q5PY+RAxEkk50GiydEqCJhr0kbDL0Ox+bxgS420kAHlKh6r3
Eyiyh7w6PBRc1Jfz4CvOJbsiYiPSCCxTtgNQ0mRi1qpJ73/nzHN5dEmtxqua24llHb8ODmnNTxxJ
kjhHOtb0/ScT/SSKGi/GB/gv73qOWQ/WvC/LctVzC3a66La8o13aNQb1ZR2yLFfrOWdLaUoUZqJZ
NwgPs2Mcx+HGG2/kzjvvZPv27Xz7299mx44dodvdfPPNXH311ZFPxj/+4z/mLW95C8eOHePGG2/k
zW9+M9/97nc566yzuvIie0HhyJ0ks/nWG0ZElsF7qRMqVteJaEEj9DKYL9fBKnPsVIXDb40x9hc6
yffBwnNM5iVNDKX9m0VZPe4FGTGJ/SsbJ5xEoRJCbb5wqy2HXMTenJK6uKv5ACTUHWSXn1/zWj6x
lgeuOhVzUbHBpzpD0p9nYaHSWWS7EcML6eT1ufMvY8+8V1b/1rwMtnMGUAmlH4gQg9bl5hneOVXG
9pbiOi6/Ti7n9sCp0ShcWN/vcrYmCfn4c0+lUtXMVN/ozPTc2xFMb+R1+g8AIiRbYUYtx0MPPcS6
detYtWoVmqZx/fXXc8cdd0za7otf/CLXXXcdCxaEF1OHccstt/D000/z+c9/niuvvJJi8fhNaaqk
8aKOq43cQq/Pl3lDZY68JMQC9NDDzA4qOGdA7n0yQ9c7LFhdYkC3ULo8i4IeJoCzSCffUV5qhVat
uKBSZpI9L5ocj6f0Rhw2tnAf5sQCcKbvdH5z9UrK81p0hekAWfF4hVMJy2Z0mURxxeRtZJm/O/81
HE1tqb4mTdRO2l4/bqr1iTOuH6v2yGzE0wmVJYXKA8dd6Rw7y+HJQhDe79JPEgpLtJlNknZ+942g
IFI6gz0AACAASURBVEImkyGTycxYaUqngulhikh+9cBUzGsuGc8ZNZj79u1jxYrjF/Py5cvZt2/f
pG3uuOMO3vve9wLRv9xY7LjxmA5pvKg4rkNs3wNTMnZsszNJmL1T0QIfW4EjZ8c4/CaNxA0Oiy42
6Zvf2w7QTp3F1TSJA2sixnNDKEfoLAIQm28yNrS69YbdPhFMYKgjmOvPY2zwPH5z9Xy8dG/6HoZx
Gk9X//1cLI1nT77Z2YbOX2/5I/JGZX1Vyb6A64KtRHwwVWS20Dpx7ZF4kr68gafIfFV9OtK1Fyzv
0DQtcueRmSJoBHxBhIGBAQzDoFQqRfaYZ9pg+tQrIgHk8/lJOrzTPa+ZZkYNZpQv7YMf/CCf+tSn
qkaukx+qUR1mr41mFENsHrqdRKn3XgVAetCeLMzegXPkeTC2JM6hawys98P815RYsM6uJu0MShaH
u82ECeCok09DZUjhqNqZZxe17lRRwD63r2Vmrqf05gZtleGJhWv58QXnIien9qafMrYj2ZXz7GhM
JlWaLE4AMJ5K8Mnz/gRLno/h7CNvnoKpRi9WTUuHWm5jqTIZeTHYDjuNHD93X4g8vp8kVN95pJch
z6m6gfulKel0mr6+vkiCCLOlw0gQ33sO0+HtZK1zLhvMGW0gvWzZMoaHh6t/Dw8Ps3z58pptHn30
Ua6//noAjhw5wk9+8hM0TePaa6+NvB9d12u6mM/kj6UfvHVKx5cuh/IzoE6cx+14mMWERO5sA2Wj
zdDSxutqkgRqDNwSPZHIK6vypACsokgcXTfAvKcny7C1wlUlovrARv/TjK45j3l7Hmu8kdz9jXkf
Z3D/ussoqXDQOgstLzOQfLr1BztE0ou8dPwF7p3Izt2rDjDkDCOHeMt75g9yy9kf4AOPfxLJXkyx
icpPPeMTPTIz8ebZzc/HVS7KLuewdoB/155jU2mQmBQ9UlHfmNg0TUqligi8aZrout7Rdd0ro9LK
CPjye4lEAtM0KRaLFAqFalPlYF7FbOsw4h+b73Xquo7jOJimSTabRVEUDMOI9BvMdsWnVsyoh7l5
82aeffZZ9uzZg2VZ3HbbbZMM4fPPP8/u3bvZvXs31113HV/60pfaMpaNmIqwbKsxbdsktv+Jnu6z
nknC7C3uSQ5wbJ3BodcZSH/iseCKEkNLWxuIQdnmqNKbjKL6kKyPkZbYn4qYmRPAlda2tb234Shm
sycLOSRrJiJmWebXg2/npxs2kU2NInsGh5NHeNg5j0yhk27g0blQOt6UfH9cpr/YONv30RXL+M/T
/gwvP84Y0Ut7PBUucMYibftwIsZANs6YVua76u7I+6jHX2fzS1OCSUKdhmun66Yd9JjDBBFc150V
IdlW4wTDzrFYLHKyU9D4zkVm1MNUVZVbbrmFq666CsdxeNe73sXGjRu59daKF3bDDTf0bF/T+QM1
OlHtQ19lqNuaiQiol4G9DbAhpKUhALlBhcK5GsZpJkPzOjMIuupiF0Hr8iyqF0r3kSSJ3Oo+yk+U
CInaNkZtL8tWjx8ge/YWjCfvD99A6iyL9QXpbB5Y93vkUsfX+STPwFE8Fkgq96oX87KCRSrxYkfj
t2KRuh04ngm7X5lH0t3fMEv8R6eeyqLiy/DK7a2tLpQPA62V5h1FZkRfTMLaxU+SB3jZ6CJOa8M4
h+GvdZbLZUzTZHx8HFVVicViUyo8Uk8npSm+IILvMfulKbIs98TYTUdSVJjXmclkGnqdczkcCzNs
MAGuueYarrnmmprXGhnKf/u3f+vZfqfKw2yGMfLvPd1fI/QUFLaA+lhtvoqtwPgZMbwzHIZOsUkp
3RnvfqXMQd1gkdu5BwbgNEnSiSUk9i3u45RD0Yv6Xa3UeqM65FXbye0cImWF1BZK7QkKmGWFB+f/
Ec8ttkCtS4qZqPM5mjiEVxrgXvVyLi1uJRkPb7PVDXJ8H6tyh9iTWgjA7rjMxfmF5JKNw9xfOWsz
Zw47QHTFoZw2gmqWKButowH7DJkt+VM4pg/zjdjzfMJb1JMbaH3IM5/PV9cQDcNouI/ZkGnre8yx
WIxisVj1mHVdr9aKdzKfXhH12Hyv06/pNE2TQqGAruvEYjEURWkopjBXmHHhgunCFyH2me7SEtvK
khiZujWrevRLIL/YqCTwLNM4dHUggWeN3VB1p11SWrkroQHLASPZ/DS0lyUoOtFPVU9vXzFHVQsU
zz9t0uueB1KETFCfPdK5fH/dDTy33IQQeT534hnVVTyWeToZw+ZerqBQ6FAVvgmSJPEKrzb0eUxa
1PQzsixzKL2MviPhSUJhlDWXC+xoYVmAh+Mag+NJnkhm+I2zP/LnouCHPMPaXc10XWQrfDEHXder
9ZDZbLYrMYeZkOurz7CtL7Hp9fymk5PGYNaXlkwnnudh7fsn9PL0lbLIGuy8bh7736kz8Habheeb
JKOVHbZFUnIYi+BZNMKW5ZZCErrucXTlZZHH9LTONHrVBY8xPli7/ml7ceLx1iFKs6zyq6F38/MN
Z5JPNTYeZe/4sR6OHySZg/F4mfvlV1EodifYEMZapVYIJNhguhFjfUf41wd/n/7Mwsj7OUVqXF85
CVliT2wBuglf157FdHvfQaO+3VWjusjZ4GGGjeN7nfVrhFHFHHod+ux0rPq1Ttu2cRxnTohShNET
g2lZ1qysjQrS19c3LbWYwfKXcrlc7YBiHLy95/tqRMGU+OnZL+WON76O5zatYacxr2ei5mH0yRbF
DksKgyo/zbAXP0dWal0faDkGRqozFSVF8bA2pWq+K1frb5kJvFc5n++f+sc8t7SA1KIEJeiNewos
nRAyOBqzecC9lmKpR/3NJtD0pzHMWtGOvNR8vbGsurxk2SG+dP/rSBWjde8uNeiR2YgjhoJuLWdE
N/m+91zkz3WCLMuhdZGtWnbNBsLqIaMIIsyWek4f/zhisRjahIpUJpMhl+udJOR00LbBvO+++9i2
bVv171/96lf87d/+LTfffDOPPPJITyfXS+o7lkyFwfQF3f01FNu2kWUZmXFSh/f2dF9hlMuwM7GY
b7z5Dxk+fQUj6kqelM/BXDGPx5eu5lgPayeDxGWXbKIzL9OV5kXaTlFLHFtzVuvxlKGupA+N/h2M
rt5U/dvTGntjJUfjF4PvYuupG8gnooUk6zOCj8QPkspVbkaHkzYPOa/HtJoLn7eDrFpcYdaee9vi
CrFc832sXbqPo24/t9//euJm69/WNCzOKTTWlg3jiT6DBZkBvqvv5WC5/RtnJ4k2wbpI13XJZrPV
9n6zoRi/2TiNBBHCDP9sM5jBsYIPMPF478716aDtO8tHPvKRahza8zze9ra34XkefX19/PVf/3Xk
Rs3TzVSEZH0v0jeQvvyen7kXj8crWWIHP482xQ+yo7bO9y+9gl+94feR4zolTwVV5dfxl5MrKagp
jT1rTmFH3yLKUzCXfsmk0EFkTVKil1Z4g9s4YkxeZwziNml8HHk/G0cxncpao6eGX9DPKxfw3+vf
zZ7/n703D5OrrPO+P2ervarXJJ10J+nsK9lXlhhUQKIiqAw4MurzggKP4syrgxvqNeNzOYPX6+j4
CAoOMjKjKKgoy2hkFZB00iH70lnJ0kt67659Odv7R+VUV3fXXtVJUL9/JXVO3X2fU+fcv/u3fb+N
UYQi+HPHUlaYEkw1R7zsbrfKm9rNJNTKkQCvFI+N+r8piWjCzCxnJxHzdYFhcDI+mVfe/ACKlr/w
ZJFUXChcEAQOu2oxVZGfiEeL+m65kGUZt9uN15vcEKVLdpViOC9UPydkNvx+v38UheClbDCtsaxK
4bcTijaYmqbR0JDkhtyxYwd1dXV89atf5etf/zoDAwMMDBSRy7iAGMv2U6qHaRgGqqoSjUYJh8Mk
EiOSRS6XC0mSEEVx1ANmPzeeH7dSCCkSLQ0LefLjNzM0e6TP7oCxGBETUZTZqSc9JlkWUadUsa9p
Dueo7M7OLpqESvAytSKqj0TJJDi7Pmd42cij41gIbM4ugivWAWCO6TWN6g5err+TV+bPI+rKLm+V
DdEMFPn9rj584ZFXscOVYHfiVlS1MpVZtedFpdOx3yGjRLNHHCIOlTW1SVKRnf4ZHNz7nrz8DWYO
jcxsCMgCgjGdPyk97NPyswZNBCRJqkiR0MUoYLEM/1gKwWL4a/Phr9JeIyjaYHo8Hk6dSlbe/frX
v2bt2rUpeiRVVS9ZD7Oqqqokg2mRDlsl0lay2iphd7lc2Gw2JEnK+OPHgsdx9XdX9FoAdBOOzJzK
L6+/kYPvXjsqDGmqCbYpmxDPL87bnVcTio0svopLontWEweqG4lXUMWnmhjBIsfTi9xgSr7j9Nas
zXrclCsTdhZnthG21UDaDvi4dDm/mfdxTjcEi/Iq0xHJYDBNCRrGMEyccSfYF/8Iqlr+giI4+lga
Hl2NqkkCipmb4GHV9BFe5+d7F9Fz5Gowsl930B7KqZGZDYfcMlMiU3hEPoJmFG6kKrmQpxcJlUKe
frGLh8ZSCOq6jq7rKUKESyHcXOmxLgaKNphXX301P/7xj3nsscfYsWMHf/M3f5M6dvvtt6dCHJca
qqqqCg7JWjmNWCxGOBwmHk/2GdrtdtxudypxnSlXNtYQC93/X8WbXQc8Dp7dfBWvX/VuNN94jyqk
Oc6HEpPzEEWR7fqaUedIkoBZ7+bgrLmclSvzm9lE0OSlRX1Hk4q32JGZKgk9s/dlFMVwkB2yEiay
aiGmaBJWnbxQ/ylend9MzFV6WN80TUJC5sKYXkcP3tDouZ/0aByMfxRdL99T2GScHPfZPpuMGM/+
dCq1o4UQfnFmDYmTa7IuvoKQWyMzF/a6vPTrGr83Tpf0/VKRj8XGyhX6/f4LUiRUrkGxDL/dbkdR
FCRJqki4+a8GM4miV5evf/3rLF26lO9973ssXrwYXdf56le/yqc//emUoOqliFyKJZYXmUgkiEQi
KVJh68VxuVzY7fasXmQu2M/9oWLXkBAFWhfN5ZdbbqRvenPW8/ayHAAhzZvZ6dxEMDbeyCh2kYHp
Deytn0EoixEqBj7bEULq1ILPV5XiSQ9kZxf9jVdlPGZk6H0sFfLkPRz2TOXphR+jvSGEWO7tURVE
dxYPWBKYnGEtPubROBz527IX6mZ5fI4wKgu41Oas3xl0BZipjA6TPnx0M7bOhVm/k08jMxuiskhM
mMbj0gn8emHEExOtOJSeK7QYedJp7NL//qVmCKziGkuqa2y4uRjS9L+GZEdQtMF88cUXeeGFF/B4
PBw9epRvf/vbPPXUU7S0tEyoSne5GBuShWQ+0mr7sHZfNpstVbCTzYvMhXRDHBnaiWuwtJ7AdJgm
nKmv5pfXvYd9qzci2bKHHc1EnJ32KwAQGXmhRVFkm74u43ckSUCsdnC0eR4nneU10EuiBo78NGkW
NKW0FpDY1HbC+viWB1MpXzJL02S6Q5v4Q/Tj7Jq7goi9+DBjJshG7rzxgLufqsD45+2w16Qt9JGy
jKbiOE51dHy65JDdgZBFPEcQBK6a1T76Q1HkO3u34O5tyvidQjQys+GYU8adaOC/hcILgC4UfZyV
K6yqqqqI11bufAoZx0KmntRiCBEuxeu7WCjaYD711FNcfvnlvPbaa7z00kts3bqVj3zkI9x5553c
cccd1NZWnrGkErA8zAcffJDW1tbUg27twiwvshL8k9YDJvV8F6nMZyNkl3lx3Uq2XvteInX1ec8f
1r0IYtKgCox+0Hc7ryQQyxGCsxuEptWxp2EWQ0bpgWSntItADs/FgmGAUaIxkm1BBmaP3wDocmm8
rwCx2BSOh27iZ/rtPFW1lNNVToZ9Q0iBwllvckEy8xRFSQL1WZ6Xgz6B48GbSycXl3TepY1vbfIr
Ah41uyZo7aQMTDyizHdab6IqkIE1qECNzGzY6XayQx3imHppFg+OFVi2vDZN0ypiWCqdlx2L9JYO
h8Mxirg+V5HTX0OySRRtMBctWsSMGckFxLrwa6+9liVLlpQ8ia1bt7Jw4ULmzZvHt771rXHHf/az
n7F8+XKWLVvGFVdcwf79+wsaN5FI8NJLL/G5z32Om266iSeffJIDBw5gs9lwOp2pZtqxVa3lIH0c
R9cfSx5HN+HwrEaeeO8HOL1gacGe7k5jddZjoijyhr4h54stCAKSR+H0rIWccmwuqQVFEk0kZ/7Q
vGpU4XCV7jUZkw4xJI1ujyiWFs80TfyRlbSEPsYjtpt4oWoqYddI7FUQBMI2R0XyiKJpz3vOgHuA
mlDm33qPT+at4AdL/vuLzbaMnx+TXZBBYBpgyN2Ph/H3NCE6+MG2G/FFx0uBVYmlV7tqkkivPIWH
tf151UcuJkF5JkKBSCRScJHQRCPfdVnz9/l8owgRMml1/jUkO4KiDeY999zDVVddxeOPP86uXbtQ
VZV169Yxf/58oPgboOs6n/nMZ9i6dSuHDx/m5z//OW1to1/s2bNn89prr7F//36+9rWv8alPfaqg
sb/97W9z3333UVNTwyOPPMLll1/OQw89xIoVK1KKAJWGFZKNDryAO1Aai0Wf18XT73wHb1zxTgxX
4W0SZiLOAeeI15Xpp9jr3Eggnr/HT1ISBJu6aJt6LYNG8TJULmkfQS1fz2R50QhR0vHPaU793zTB
KJAWT9PcdIav4zfhO/iZdyN7qjyISubXIeQKYAvNLWuuSRTQWylCXQ66tzd9dk7531fSX6+yHcbM
4EX02UV88eaM39Flk3dOb894bNDw8fi2G3HFR4eaLY3MUtHhUhgU6/mj0Z4Si76U0z1WK5nH48Fu
txONRksuEroY1bbpRU42m23c/P9a9DOCog3mq6++yi233MIDDzzAl7/8ZV5++WVeeeUVvv3tbwMU
3bvU2trK3LlzaW5uRlEUbr31Vp5+enTf4saNG1PFROvXr6ejozA5pC9/+cts376dr33ta1x11VUZ
aZgmaicon/u/GQ1WLsQlge1LF/CrLR9goLH4MGC/XpPXExVFkde1jQVft+k9TfscJye9W0hoxQj+
guQQc/ZM6lL51blC9WF6Xckip4TpxuXNkpA7j0h0JgeCN/MTbuNp3xy6q/J7fQBDdh29PFEWzALV
vPucfdQGMt9rQRBo9bo567+u6L8vOgJsjHVmPHZKqcLQM/9YM6dm/g7AqfgkXth5A4o2cm2GBOuM
8vK+b7rt/E4cQvE4R5GQV9p7q2SvoiiK2O12qqqqxmldFhqyvZjtKVaRkzV/q8jJImiZiJDz2814
Fm0wu7u7mTdvHtu2beN//+//nQqnHjuWZBMp9qZ2dnYyffr01P+bmpro7Mz+gv74xz9my5YtWY+n
I/3HkGV5lDGfqB9KEAR0XcPetb3g75gmnJpSyxPv2cKBFeuQSxCYNE2TFmN9Qece8mwkFslPM2dB
kFTCU05wZMZV9ArL8n/hPFxyGyEz+98xpNJJ21NzEwTCsxU0A3SxJuM5ui4yGNnIS6FP8Kjrel6v
nkTCXlzJa8wRQYnl9pjzQc+n5n0egihQk6vPUxRo8dbQ4b+66DlcQWbe1k67gC+Subo54jsHWvaN
yO7ADPbvfQ+SPvJONYh9Rc8tHYYkcthVw5Pa8RQJeaYWj0q8xxOxFlhal1aRUCgUKqjIZiKKfkpB
epETkPI6Y7FYyXn0ix2mrgSKNpgzZswgFovR19dHKBTiwIEDbN++nbq6JCdoKbuaQvHKK6/w6KOP
ZsxzloKJImDXh57GFSnMHQk6FP6wYS0vXvNe4jWlhyjNeJyT7hWjP8xRlflHY13x1+7qoqs5ztGa
9xPVChP+VRwRtCxBB02qDP2b5D5Lz6QrMKXRVbOJRA2nI+/nSfUOfuFdydEqV1k8s/3OMEasdGIE
3SzcSPe7+qkP5jhfhG2eyZzzZ26vyYYG8XDWY11CbcbFMGrTuGJK7qjOi70LOXf4aqxOpoDSjRIv
zyXvsUu8Jkl0aIFxLR5WY340Gi0rXDvRbDhji4RyqY5caH3eYsaxCBE0TSvaa7Zg3aO3m1eZjqJX
j8bGRtrb29mwYQPPPPMMvb29tLa28vnPfz45YJELkjWehfb2dpqaxpes79+/n09+8pM888wz1NRk
9iTy4UL8UIIg4Bp4JG84VgMOzJ7OL7Z8gPZ52fvaCkWPOV6KyUH26sf93kmEQ4V7ixZEySRed5Sj
zZfRIW3Me75TOklEWJXxmF4hkgGAxPQBorIX0zQJRhfxZuij/Fi6hd95pzPkrgx1hGZLICXmlfx9
leKIwqvzsAmZksCfPI30BfP/DqlxbaeYHM6c5z3llvCEMpPhX9aUPepj4Yn21cRPrE2G8GSdDVr5
7TitHoXHYmdHfWZ5b6IoFuW9ZcOF8OiyqY5kKrK5FOXGrNaUTF5zoa01meb0djOeRa8ktbW1fOEL
X6CxsRFJkmhqamLatGmpHsdib8CaNWs4fvw4p0+fZtq0aTzxxBP8/Oc/H3XO2bNn+eAHP8hPf/pT
5s6tRPEFqblWXrFEw3luX85zerxuXlu3nuGphfcr5oJpmLyhjw9Tmxlo2NLxirGW95n7S3poRccg
A80mAf/7mN7TglfK3gZgs/WixgSUMaQCegVJBuJEOOR+B0OhVbT7iu+fLRS9rkHqQm7EEiTEEhR3
vX3OfuoC9Qz4sv+OhgSvOpvZHExQ792Vd0xRMrlGP8nPWDPumCAI+OVpKBnaQoSa/AYT4EfH38Hn
XGHUpsM0Cb1A4ZqamSAIAlu9NjYFz3KVZ8a4Y3a7PdWUb/VUOxwO7HZ7Qc/ARLdxZIJVZGN5nNFo
lEgkgs1WOcL9icyFWl6zpW8Zj8eJRqMp+S4pCz/02z1/CSUYTI/Hw0033URnZyd+v5+33nqLl19+
mSeffJJrr72W1atXs3Fj4TteWZZ54IEHuO6669B1ndtvv51Fixbx8MMPA3DnnXfyjW98g6GhIe6+
+24AFEWhtbW12Kljs9mIx+PY7clCj4kwmGrvo9QkMscgNQ12zV/G3vVLEKXKEeYpsem0e8bnn0wz
t8E8XDWJq0Mr8HhyG/hsEAQBrfoYJ13NVPcsZ0b05YzakQ65g4C8DoXRv5kq5y7QKQTdwfm08R7a
7DZsk6dzzrDTHDoNvrN5v1sKTNlAMJuBQ/lOHYdYkQZTEARqZMjXkajLJq86F3B1SKXWk7/laoFw
BDIYTIDDToGNYR8R92jygWFnmDn2Lk7Gp2X8Xtqk+c7e6/iyPZJUPFEXgFIev++gTeRRJco6XcUu
jR/L8t5sNltKPcjv96MoCg6HI68iRqX6rouFZfBtNlsqvAwQCoUKmne+OU20p5p+3y2+7UAggCRJ
qetK/+7bvUIWSjCYmqbx9a9/nd///vcAqZ1SS0sLjY2NLF68uOhJXH/99Vx//fWjPrvzzjtT/37k
kUd45JFHih53LHw+H6FQKGUwJwL2np+M+8w0ocd088J7ribWUFMZ1e40dOnzMx8Q8r/IL+lruMHc
W9aDLNqCBKYHORy4jqnn2qiTxhsrh3KaRFTBJo8w8ahyuCSe3YQqcjK6hYPSUtpdUQRJBHTMhA2k
Gv7kNlgSmkm1uAfZVXmB2l5XH5MDdQi+4prrMxGv50Ofs5/Jwcn0enPn6TTZ4FXHUq4OJaj2HMl5
rtvehqTG0ZXx74EgCESF6YzdEAiCwBUz2zl5LI/BBBBl/m3H+/nCpl+yUvSzR8lPuJEPO7wi/z3Y
wR2ekTRDpgVYlmVkWcbpdBKPxwmFQili8rELeKVR6tiCIKTEHCyDU+68K5mbLQTpXnO6t2+321O0
on+RBlMURR5//HHa2tpGiX8uXbqUH/7whxWdXKXh8/nw+/2jCpQq6WGqiSDurtE9pGGnyLaFazm9
JItRKxOmLvC8mLkFxSzAozlSVc+7wqvxuHeXPRfDd4qzTh9D/e9hhv8P2NJCrjapl4CyHpu5I/WZ
pgSLegCHItM4rL+fQ0o1YV8CiCOkbT+iSBx36NRFRQ57TBzaSpYFwsjO3VRIxAQAQQJdmoyc1/cb
jQg6xZYNCIKAV9IphAogIRu8Zl/DO8IaVe7M1bAAgi3KpmA7ryiZ0xsH7LAm4iTmGs2aVD35HBzL
+JXxcxEdPLjtRm67bAd7POOPm4aBTdNxmCKyIaAYAoouIBsCki4iaQKiJiCqAkJCgITAC354Z12Y
2bPyF5yNDRumL+AOhyMVrr2Y5AeZxskU7hxreArFhQ41W+eme52xWIxAIIAsy+NC5G9H41mSwVy3
bl1qB6eqKh6Ph9tvv51EIlHROHylMVaxpNIG0+h5ALuWHE8HTsybwmsrNoG9/PaJbJBjM+lzZy6C
Mgr0aF4w1nCjsRuhAq6vpCSITH2LI1WbmXquj0nmwdQxh3SEWNSFQ4mgagqyO0w+A2IYBqfDmzkk
buCkQyVZaJo5lBtGJCGL1EZq6GSQmAytPjcNsc3MiZ1E8mZuwC8FA65+GvzTMKsyUMdlug4VEnYd
sYT4Qr9zgMnBKfR68/PkRhWN180NvCOcwOvOHpZeJ57gFTIbTEMS0c1mYPTmb9A9SI3oZ8goTGBh
yPDy+q5VOP8jQSRmIxoUiYUFIhGReFgCqTjtUoecwOlI8JP/TP6/kHc30wJuhWvtdvsl2+qQy/BY
SiS5DM7FlhuDpNfpdrtxuVypXK1hGESj0YJzzJcaSgqSP/nkk+zZs4eWlhb6+/uZPn06f//3f3/J
34CxiiWVhq37CQAGamz8cfXlDDZMz/ON8nFaz161aRQQkgU45q0hFF6D1/1mpaYFrk46m0X6+7cw
c/BlXEoMm+wnYF+Pw9iBLtYhy9kNeiju40j8Jg7KUxnyxoH8xiJw3uIfcelMDQmEPMnr73bodNtm
siTYTJW0C9kVKfvyBEEgorix6SZSAYTBkuFEtJfm5gqCgEdS6TaMgt6xsE3jdd7BpuhLeJyZDXq9
eAB4T9Yx9ttFlkUVVOfIfTckeOf0s/z6TOE9vIrqxHlK4eDQGJKKEpRfalwmv3jcxSfviHDFgd4g
+gAAIABJREFUFef5kotYzK0F3Cq2CYfDGOfvaTnh2ok2TumGxyqwSfc6xz4TlxpZupWrNQwDXddT
hAhWu83bCSVZuNdff52Pf/zjHDt2jB/+8Ic899xz3HfffQwOlqaFd6FQqoh0IYhFupH6T7NjxVx+
df3NF8RYoou8pMzMerhQgwnwB2M1hl7ZEIkoGahTTnBs1iq6pCRln0s6QFStQRfHc5ACdIVW8EL4
8/yn9Ele99Uy5Cq8l2/wfNuGLot4zTFetyhwyAt7lNVEh1eglS9qQtDlRw5mb91Jh5yPeD0PBpyD
TAsXnnsP2lT+JLyTcKwh43HR0cWcYHYpLlUWkTJQIjY2FFYta0GOmBzc56BKKZ0U34LPbgIi994r
o2dhJSoEoijicDhS7RGaphVEQJ4NF8qbs3Ka6SLR6T2RY8e52B5mprEs419VVTWhtSQThZIM5j//
8z/z/e9/n3//939n2bJl/PKXv6StrY2TJ5MitZdqmMPn81XUYBqGgaqqDIaGeXX41/zyuhvZv3Tj
BfO0xfhchpzZ6eUKDckCnPRWE4qtrcS0xkF09NPXPMTh2vcSw45mn48hj4Tj4qrCgeCH+UX0y/zC
vZmDbgMth/eZCYJqEk7z4I66dDwZgglRBXZWezmlbUYPZJaoKgZ+O2hq/gVFLNNgCoKAS1aLYlnx
OzRahGuJxMb3VgqCwLvE8eol6ThoVxDio13BoLcHySh8E6P5VYJhhUX28ncoFif+7j0O/vMnekXE
lgVBwOVy4fP5ME0z1Rs5Vu/yUkK2nki/319yL2o2TBSPrCiKZVUBXyyUtLLbbLZRP8pLL72ELMvE
y2T2mGiMzWEWC0to2krEnw1281vxTf61bivPzffR58zc9D1ROK7PyXm8GA8TYKu5quJepgVBENBq
j3Ni1hz63R78mof+yBxeC9/Df5r/wIve6Zxzxkp+Oe2GAzHtBTQkETfZmZPOOXXe8DQzELoSLVJc
Li0dMWcEWzh/QZdglp/bH3QO0ViElwkwYE+w3Xwv0dj40NccKbN6iYWILOAeI/0Vt+lcOTm3oU2H
GEr+Jrv2uJnqLK9i2ZZWxPaNb9gZHi5PVDsdludTXV2Noigp5ZFCmvIvZr5wLJOQ1dphrVUXY04X
YqyLhZIM5uTJkzl37hwAzc3NPPjgg6xYsYJZs5Iv16V6U0oJyVrEw1aVXTwe55Tew8/dO/ju1Jd5
vfotYopGQ9xHTWTDRF9CCoIm86ItN0F7MR4mwClPFcHoxF6DoPjpn+Tid75389/297PLLRO1la9E
oRjjDckxl44vgyBzCqLAIY/AHmU1scBKNLW0nXm/K4IRz7NbroDBhGThS7Fcnn3OBK3mjcQTo8tV
JbkNZzx3PveQ3YE4xjlc1Fh4WDZ+PkujahJTy1y/RWPk9+ntVfjOd3ILcheCTM30VtjTIkQYHh4m
HA5XxAAVM5dikC7X5XK5EAShIt7yX6W9RqMkn/jee+8lEkm+aB/84Ac5evQoH/3oR6mrq7ukdxFW
H2Y6Mj1IhmGgaVqKr1KSJARJ5Ijczav2Y5xyDiDpAvPik1msNbJYm0aDUoMpmmyNnMLvKnwHXirM
+Hwi7tyeUbEGE+D3wkr+Rt+BKFVu9w5gGhCLrWS7cRn7XD6kRoH6mEHMXX4BDoCcwSCZkohdqiFf
639UgVbFw7To1cyKHkfyFZen02xx5MACDHt2MgOjtFdtHIacwzQFJ9NVQMVsOrqdcXZGP8TaxC+w
25KRIFFO8O7oGZ61L8r6Pb8i4A7PIqicSn1mVHcl1b8LSD1E0jjYd+9zMX9dkGPBElVqYqPf1Z88
VsVdd8VYurTyoT0r7Kkoyqim/ExVqpfammdRBnq93lQ0zDTNVE9nMSmjv3qYo1HSk2aJRbe0tDBj
xgyuuy4pNXSpxvwtjK2STX/gLeNoJc8lSUJRFExFoEU6yWv2o8RRWaxOY7N/AQtpxCXZQQCUkfEu
S7yf153fn/AHo83MHY4F0DChCP5SgDNuL0OB9dT5Wkqc2WgYukQ4tp5XzIWc9iQ9HBEwAZtZTYzK
GMxsIc/jTp3ZIRuDnvysQl1OnS5bM4v9zdQou5FchReq9LoGqYu4EVyZKfM0UyLZbFQ+bHL8vL0q
LkDU6YyjRG9lpfpTbEpyLiulEzxLdoMJSYHpqaoOSjKJGHTFWOLp4lAkfw54eFSRrojil4DCjO1Y
qGNuraZJfPFLIs89W/pCXMgint6Un16lalHwVQqVViqxvGW73Z5iQLIo7Ox2e0E5xInMh74djWdJ
IVnLqDz99NM89thjAKlY/6V8E6qqqvD7k4TQlpE0DINwOEwikUg9YC6Xi7CS4BlxFz+SXiEsxPi7
yEb+T+zD/J15Fauk2UljmQFN0iJqw5Xju80EIWHnJXvuKlzDMNBL8DABtoqrMPTyCpcMzUF/6J08
Gf9f/Kd7TcpYpqPT6ccdLD1/mA7dzPLyiwKCUIRHI4kcrhLZo6wlXkSY1pB1BKM563GtyI1LNugR
L3u1q+jtfie9Pe9C7V+IHiq8R+O0M87u2EdQ1eTvWyUdyBvi7bOLeOMj1diCILB2RgE9rabJ4Bhn
/dBRF8vrSstlxjNwub/0kpPf/nZiQ6UWxlapWtW1sVisIuNPFK/t2CKhdH3RCyU3VumxLhZK8jCt
i543bx59fcmYi8ORrAI8e/YsgUCApUuXVmiKlYFpmnR0dDA0NMQ111zDli1buOuuu4AkvZ+1W2+P
9dIpDKFJBpvMhdTL54slirhTiyNb+JPr+xUhAsgEPbEA1ZN7ZyvE45g2oaRlusPjYTh0BbWe14uf
m+rjXOwKXrDNIJhnjkgiouCBCniZWQ0mcMKlMzegMOArPIwZUUx2KB6mRTafD9PmJyjocfYxJVQL
nvHtVeXWiGpxmcHEJl51TiUmS9idOo4+O2eUaQixVcwLxZgjDVMrd2DajyO5si+CZ7waSuhvWSH+
FMnez8rgOfZ5cwsBnJarqdHPIkrJh9pdnz9s7UUlGB/PyhM4awOPCkJxfalZRFb4yn0K112n4XIV
39xZqtCyFa41DINQKISqqgQCARwOR15SgUrOpdhxcjEgZWMS+qvBHEFJS7p1Uz/4wQ9yxx13ALB9
+3a+853vcO+997Jz586ix7SEqOfNm5dV7/Kzn/0s8+bNY/ny5ezZs6egcQ8fPsw999zD7Nmz+chH
PkJvby//+I//yF133ZUy8paxDMbD1MtVbLAv4Ep50YixLBIN8hwmh4vn1C0UewsIx0qanlrcSsFz
wjIMvfAFSI9P4UToRv7D/Fue8s4jWGCoqtMdxBPIwJ1WJGJCdoMpCAKqUJh+51h0uQze8MxmKHQl
Rjx3a4gggS5k7nsstX7cUHWC/rU8L/wNf/A2EZOTv0lclqiqjqNoKqYocczm5vdSIz8z1/Nk6FZ2
dX2AgXNXoA3MRM/gAJ3waOwPfwRdN9kknMw7j06HQFWawPSw288UOYsFO4/qLBGOUx0OVlUXX60+
nKVt9NQpG//+vYuTDrJID6wwpyW0bLHaFIsLVW2bXiSUq6Xmr0U/o1FWtlzXddra2ti2bRttbW0k
Egk2bNjApk2bih7nM5/5DC+++CKNjY2sXbuWG264gUWLRnIrv/vd7zhx4gTHjx9nx44d3H333Wzf
vj3v2OFwmKamJp577jkWL17Mpk2bxuVcrR/Say9tUc2ERZHr6HW1IeTRNCwWUsLNq478smC2Mh/G
c24PQ6ErqfO8mvM8NTaTI9oG/mivxfQUz2QjCAJIHqC8loNIHuqYMx6YP2yjr7oEhRRR4IAHXIl1
XBYIILv3ZGX36Xf1MTXQiDGmcChapFKJYRgkggvZaV/J6arMm4+zTokNUT+vM5rcXJNlDss+DuMD
ZmMLaiwajjBLGcQrn8Fwnka0iRzzmUj+W5gv7gbyv7Pd8iScxjlEUcSUBN4x4yxPvpVdm9Zj5PBy
j7ixN8WJ64VtrAR0BnuyL1ff/radj/5tnJkzi1vSKsUlK4riKOURi4Kv2HzhxWhPGcsklF4kZBhG
xfOqb2eUZDBVVeWll17i97//PSdOnKChoYHbbruNd7/73SVNorW1lblz59Lc3AzArbfeytNPPz3K
YD7zzDN8/OMfB2D9+vUMDw/T09PDlClTco69du1a1q7N3JA/UT+eIAjUCI00xVbR6c6vUVgMYvEF
4M1vmOQKJOufFZbyMX0bojQ6oGiaJonYYnYbq9jhrEF0lBd77nIFmRb0EfIG8p+cBWEz9xwEQSAu
uzGMWMnEEhGbyQ6bl8bIZmYZJxA948OSgiAQkd3YxtDYRYoo+NFCU2kTNrLH5877jO6vkVjZM8we
W2bmJICEJLNP8rEPH+jNuIYuZ4kQYYbUz2H5NGZco0ocxu/OPgbACQdcHqoj7E16lg1TOuGt5VnP
d+a45IFhOxsXhWgZLsxgVrs0hszs50YiMl/9WoL//q+ChpswWMojHo8HwzCIx+MEg0EkScobrq10
0U+xyFQkBKQKnC4FubGLjZLuwMGDB9myZQubN2/mK1/5Cps3by7rZnZ2djJ9+kgRS1NTEzt27Mh7
TkdHR16DORZjfzSrF3MifsyliS10OvaCVLmihFazMCo2WwWKTHrcHgZCVzLJ8wqQbA2JxlazzVjK
YU8yXF2JNK0gCOiCE8MYLtmY+QtIGJ/1wPxhJ73V5RFsdLoMOvVmloVm4ZV3IjlGjxdwDTM1MBfd
9xaQXCxCgoaU53XTIx7OapvY5q7FkMSCfkFBEBis1Zk0FKVPKawvMaIo7KSKnVSBPocqQ2XjnhMM
X5Gfmm1YbkwJTPu9vShaBFXOXLhlj+ZeuPfvdVA7P8pgIv+8q51kkLUejV8+6eSTd4TZtKmwSEcl
JbAy3bf0fGEikRiXL5xIRrByGZAURUGWZRKJRKpIKJvOZSHIdI/ejga0pF9s0aJF/OQnP6Gmpoav
fOUr3H333XzjG9/g4YcfZteu4j2qQm/c2Ae8nFLy9DEq3Q5jjVkjNzAzur5i44pRL9s9hdG5VUrN
6llxCXrCzXDoSp6O3s4jritSxrKS6HGHqQ5lZ+bJBdM08y6mFkKKq6Tc0jhIIvs9AnuEdcQCy9D1
0c+Q38YIX61qQ3JnN5Z6XKI/+E5+o3yAP/nqMYrMPfttEs3uMBilbcyGJZnj2+Yy50/evO/CYQc4
z/dRqrLB1U3Zq2WFzB02KYSjMvNthf0WHrmAd1QQuPdeGU0rklaxAiHZfBsNu92Oz+fD4/Hk5YAt
F5Uex+VyUV1djd1uJx6Pp3h3i3mP/hzyl1CiwXQ4HHzsYx/j17/+Na2trVx33XV0dXXx+uuv88AD
D3D33XcXNV5jYyPt7SMvXnt7O01NTTnP6ejooLExfy4v09wvJIXfUu09CFplGquDiQUF70rlImnx
sqHX6eLBk9/ip8IVnHVXLsc7FoIgkJDtJRkzURWIuQrjau1yw9Rg5a4jYodWXxWn45vRgyNFMRFH
CEd0AQCykXluhmYQCq7lBeEWfu9tIqqUIOFxHsc9Mu8QSwtpT1I12obrOPl4I3Nbcm+GBEEgLIy8
d/OmdWQ9Vw/kfwZ37nYw3Z3HsgJ2sbDned9+Bz98KFYQK8/FCBNa4dp0DlirvaOS+cJKj5Nu9L3e
5MbK7/cXzCT05xKSLTkmEIlE2LVrF9u3b+fDH/4wDz30EN/85jf52Mc+Nir3WAjWrFnD8ePHOX36
NIlEgieeeIIbbrhh1Dk33HAD//VfyQTF9u3bqa6uLjocCxOrWJJpTK9Ux+zoVRUZdxvj1SOyoRI5
TICasJtnB9azQ16H6V+CqU5cz1ufK0J1qHg+XodeXHhrWLZjqOXT8aWj02Xwhms2w6ErMOLJXFuf
I4oRl5AyGMx4YD4t6q38xruIPltlNlQHq0wWq8VXnzacr6KVm2We/tw85rTk7ls95JSwhZLXlKg+
l2T9yQB1MP8zqOsSkxL5F1KliH3U/fe7OX16+IKRqJfLAWtt4q2cZ7kRkIn2VGVZTimOKIpCOBzO
y7v7F28w/+3f/o2bb76Zu+66iwcffJD+/n7uv/9+rr76aj772c8WNZYsyzzwwANcd911LF68mFtu
uYVFixbx8MMP8/DDDwOwZcsWZs+ezdy5c7nzzjv5wQ9+UNK8K61Ykgljx1ysXYOklccIIkfr2O+d
mv9E6/wiqzKzITIwk17Dx7QhJy9VNXBSuxopOKkiY2f8e5KEXuSCIecoBsmEHrdAUzR3gUtJkET2
e0T2COtJBJcTk6IoiQWIafNTQw0cCN7IE971vOWsrLC4Lolo1Qk8anERFFcwuZDtG3Ywc1aEp//f
+czZnt1ompJIQk/WE4QdCVZVZw7LRvsLWyB373OysCpPlXQRPL8DAzb+7/erRy3mmRr0L4VFPL29
QxCElFbk2HBtMahkbjYX0mXS8vHu/rmEZEve2v7oRz9KhUiXLVvGpz/9abZt20YgEMDn8xU93vXX
X8/1118/6rM777xz1P8feOCBUqebgtfrnVAR6Uxwy1XMjV7NUe/WkscY0gsPx0KZ/UIWdIM/diRZ
i3admER1fTunnQpnjMvYGArhVHYj2CvrqQ2540wPTGbY11/wdxSK34z02WyYqo5QRhg0G8I2k+02
H02RzYjmCRoiDnTJQ3v8St7w1Bdc0FMKeu0SKxxBXlOVgp8X3TJsgkjDcoEzZ0Se/of5fOB7Rzm5
PrMhO+xWWBaR0VwaK6adYXdgvC5rsLvAjY8gIPRLIGWnzDOKlNN85BE7/8//Mlm2rGpcg77D4aho
wU0lDa/7fNojHo8TCoVSlavFFtpcyNDuWCKHWCxGIBAYVRl8KWxOKoGSn5olS5aMqmR98803U1yL
lzKqq6sn3MO0kD7uIv2dyInSaOBM0+TVIsKxAFIFPMzacA2n9aQ32Wf4mNuf9IhMUWCbx8se8Sqk
4NzKFNGkIWgTMIoI/RpG8SVOfQ6Tplj2HsJKoMNl8IY0m+dPXcn23i286qwtuqCnFByskrncKLQM
CgLnRjYNe0N2aqqjIIo8/fcLmLsjM6mEJkvI5wk0HPXnMp4zlD29OQ5tJ5ysrMuey0wEinvGdF3i
C19MXtfYBv10D+5itnFkQybJrmIKbSaKYq8QiKI4qkgoFosxPDxMIjG6//ntajxLfnuvvPJKPvnJ
T/LVr341FVL90Ic+lGLPuVSRiYB9IkKyMFo/04gLzAoUR+hgQYlO5binuDCoVIFrGuhrHvX/N49P
wqaNGLJBReQP3pn0Rq9CCFWukGbYEaM+mpkxJxOMEmuCzykSTFRONmYinV5Cy9n3ctpxOXRPQTg6
jXknvDR3C5CorGc+FqdqYWYsfxGQaZp0vDWyDMQNmUWXn1+URZHf/v0C5u7MHJ61BKaH3UGalL5R
x2x6gvBQcc/EwCkbQhYSwUjh9j+FV1918Otfj/y+VoO+VXATiUTQdZ1EIlH2GjARHl0mNh7L2OfK
zV4K1baZioQsr/lSFufOh5INptPp5MYbb8Tj8fCZz3yGv/u7v+Pee+/F6y1RuucCYWwOs9Kw9DOB
lH4mgN1uZ6n0buyJ4lsyevQFRX+n3ECjqMMLHaMp+PpMH3P6xm+IDrodvOpYi+a/DLNETcmxGLKZ
BRcY6WZpVzvogKZIZb1MM2Fga1/ErtPv47nEAgYlO6pmsF31MTsW541EDa2D01GPNTHnmJdZ5wTE
eLlMs+MRlyV856nzcqFO1fBHRnuRRzQbinI+UiSK/Pae+czdOd7TTAlMSyKbZo7OY9YIetGKJGfP
2VlXmzlCFcit0JYVX7nPRiQy2iuzPDi3240oiilWnlLp7CrFFpQL6cZeluULkput1DiyLCPLMk6n
MzV3Sx7y7YaSU12f+9znUFUVXddTcjd79uwhGo0SCARYt24dtbWl9dVNJKqrqzl9+nTq/1aivRwY
hpGSBrP0M4Fx7BgSThbFr2Ov7cmCxzYNeFlsLnpOimhSjg9TE6inXxhfGPPmiUnUTGonIY82UglZ
4o9Vk5kW2cSS8DHM6izEnwUi4IgzMziVQaU377mxMjK27Q4JKa5h2MvL+poJHUfvQlpD8+gSHaO2
oiEVEAR2JLysYZg33dUMiTZaNBsM1eDpT7DYHkVyBTlTG0NzVUZsut2lsDER5DUj+3s4NQ7dYz4b
TCisvzLEjlfO54ZFkd/es4AbHzjKiTWjc5qH7A5mJqB+ciecWJX6vAoo5Qk4fsiOsylONJ0yzzQZ
zBz1zYuzZxX+7TsqX/vq+GOCICCKIj6fLyUSXyydXaWRz0BZhTZ2ux1VVVNUdrnI00tFpXlkLfrA
i3VvK4GSZ/2Tn/yElpYWnE5nysW2QgjDw8M0NjZekgazEiFZ0zRHGUnDMFK7KIfDkaRHi0QyPmxz
jcs5mniJqK2wLbMSn06Hu/j7WGDbWlZ09DRn/Lzf9LGm10HbtMyeS5fLRqdzCesDzfjk3eAq3Xsa
UDQE1QAlt6eSj0c2F/x2WOqvpcNeWtTB0Ayc3XPYE1rAGdGVMWYzpJL8XBDZE/eyXPCzzzUSaQhJ
Nlo1GwSqcA6pLLFHsbtDnK2JEC/TeO6rEljV62e3kjmyYVXIjkWPSwZTTzLKQ9JofmYBNz54hBOr
R3KNfkXAG2pmyHMGtxEmLCbDsO4SI92DwwobF4VHUeY5FJVY2FWstGsK3/mOjds+GmfWrNHLXfp7
XyqdnTXORJMfjIW11qZz11oC1xPNYFTuWIIgvG1zmCUbzFmzZmGaJlOmTMHpdOJyufB4PGiaRjQa
ZcaMGZWcZ8Uw1mAWCisfaXmRkHzJbDYbkiRlpdwbC1lUWBy7nl22nxb0dzvU+VAY49kolFP0I6si
W8/NyRrX3XliEnWTO4jLmQ2ZIAi0+jz4Elew3t+J7jlaknJKyKEyMzCVQSW3rxIqk6DvtFPEEdfR
7IUbXsMwcPfMYt/wAk5KnqzJDUnX6NVscN7u6aLEkbiHxUKQw87x6YuopPCmpoDfh31QY4kcxuWJ
0FEdJuIt3ngKgsBAjcakwQh9tvFFZ+ZA5oXrdNjBsjUh9u9KC8WKIr/99ELe//02Tq0dCakdVdxM
MzWunn6a5zqT4vK2eOnP3949duoXRumPJx/8WrdJVxlaedGozH33qTz++PhjY9/bsXR2Y8WiJ2qh
L8c4jSVPV1WVYDCY8ubKYUSrVDXxX3yV7ObNm/nEJz7BkiVLqKurQ9d1jh49SlVVFRs3bqSqqvL0
aZVAMcQFpmmiqirRaDQlMm29UC6XKxVaKPZBmMN6PLH8RS2mLvCiPL5cvxCIZTD9+PxTiErZCzYG
8DG7L38rR8Am8ULVDDrjmxBDpfU99jtUSOS+Fn+ZBjNkE2hI1Oc/kaShdJybytlj1/JUcHXSWObA
JEMF2+h7FRckzsaczInm7j2MSzK7zSr+FJxKx5lZTG2rZcFZG15/cYoruajzAl3Z753ZlOGYKPLs
PYuYs2vE+PbbRXzxmTRPHSGjF8tIUUVjMrPTqPC89vI9pqeecvDyK4UnKdKLVtLFogvpMbxYsLxO
IG9fZCH4q7TXeJTsYQ4MDPDQQw/xxhtvoCgKDoeDcDiMJEnMmjVrVC7vUkIu4gLTNFNFO1aoVZKk
UaHWQpHLEIuCyJLYFnY4Hs05hhyfRZ+rtI1HOSHZI535owM7T0ymblJ7Vi8zHUdddk7oK7kiMIxs
34tYxAIYtqlMH57CsC1zLtM0TQbF8l++k3YDT0xHdWR/Zh09kzk5vJT9QnXBW80awRyXIwQICTK2
mI0mwnQ481eTaqLEPtMDIQ9CQGdxZ5Q6d5hzvgD+mvybl+NehU0JP68xEt43TZPOt7J/58Cwk9mz
grx1aownLIo8/elF3PTDIxxfmQzPnpKrafS2gZYA2QZFtoGMxZu77TSvDnE65MFVbn4BQBD44hdl
tr1hoJwP8ReqG2n1GFoV71bo06pRuBgh2VzjiKKYdc52u71ggeuJNJhvV5RsMH/xi1/w8ssv8+ij
j+JyuZBlOeV9AZeksYSkh5kekrWMZDweT1W35gq1VgrN4iraoi8ScJ7Nes5pY17J44slhmQdcYlX
BufmLbMdML2s7bPTNrWwHKUuibzmq2VKbBMrAifRfYU36fU5E9jikInQR0qI6O4SYtZjELWJzA3W
0+4Y37/g6Kvh7NBydpk1UOTzkKvzdlCwYY+b1IsR+u2F9+iaosQhPBD2QGgSC89FmeQK0+8LMlCb
vcXmYDUs7PVzxJ7chNWoGr3BmuzGXxCoXybx1qkMx0SR39y9kJseOsLxFWE6HQLNwXo2Tu6gZXA2
ieGCLycjDEOiOpKcmK0SrFVmgp6eAD9+NMJddxbespQOSZJwuVyp3sj0Ss9yDcJEGZSxcy4mxFzJ
1o+/eA9z0qRJrFy5kpkzx4cML+XdhNvtRlVVfv7zn1NTU8OVV14JjGjBiaJYkbnnKyYSBIHL4u/j
T44HM/89TeJ5afr4zwuEmEXtPh8cw43oUmHMOcV4mRZ6HDJb7fNZHZpBvbgbwxXL+52YXWdKcCqD
9vGlkg6jPMrBdBx3mvgiYPFL2Aeq6B5cznajLmkoS3gsFD3373AOO82xGHEhTtBWwrUIIkdwcyTi
hvAkZndFmOoI4a8K0F03mu3HkETMWg33UIywzcGUuEFvnhzVnqCd+roo/QMZNiWiyG/uGjGa3fIk
Lpt23mBmyY0Wg70HnSza4EcsVLzA1Jk0aYjJk0N4vEFEIUwiEWJoKEJXV4TeHoF//LzJjOlr2LJl
esnrVLpupKqqhEIh/H5/WZWqE12okz5nqyI4Go1is9lwOBxZ51wpr/dStgnFoGSDedlll/HUU09x
3333sXTpUoaGhujp6WHWrFl84hOfwBgjoFssBgcHueWWWzhz5gzNzc08+eSTVFePzoO1t7fzsY99
jN7eXgRB4FOf+lRWHtsTJ07w7LPP8swzz7B9+3YkSeKOO+7A6XQSjUYLDlMUg3wvQZPtz1bgAAAg
AElEQVS4mPrYPAacJ8YdE+KzCbhL72kt9Ur2dBWmtwlJL3Ndr53DWSpms0EQBHZ7nLi0jWwM9GA6
DyDmoajrtkdwxEUM+2gDVCyPbC7EZIE5sVr6huIMDKxkq16PKYil30zA0PMvhKdNBwviUc4QJ1aK
0bQgCLwluHkr4YbeyczojjLTHSHoCdJRn2yh6LFLLLMHeEO34S6gMFg1JOatN+j/XZYTzhvND/7o
CEcvCzHNngzRFkyLl+d6tB6ZRFUCOB+2Ng3q6gaZNDmA1xNCUaLE4yH8/jCdnRH6+gT6+jIOBoCm
CXz0o7t45hmFtWvL4xO2wrWQTPVYlaqKopRU33AheiezhZgzVQRX2sj9RRvMSCTC7t27CYfDHDly
BJ/Ph67rqVaScm/O/fffzzXXXMMXvvAFvvWtb3H//fdz//33jzpHURS++93vsmLFCkKhEKtXr+aa
a64Zp5by6quvcuutt/K+972Pz33uc/zrv/4rv/rVr8qaXz4U0q5ieZmvOL477n4dN+aX9/dL8DA9
UTst/llFlYLtODmZ+snFeZkWIrLIS76pzI7WMy92GN2bnT82bjNoCDYwaO8a9blYIYNpGAbVPVW0
9cygHydHXd6yDKWFWIF1Jkd1J0tjIdoEEV2pgJqpIHBWcnE25oJYPdN6osx2Roh6gxyqlbjSH0Ad
LmxDdlizY3fEicey3GtR5KlPLeSmH7XRP9dkjqOHwXOl0UAmpx5lqi9KjUfFbSZwB8+xbu0Q/f1R
urtjDAwIDGTsyirsB4tG4eabW3n66dVcdll5xBWWURlbqRoOh4vigb0YZAPp4dr0imDLU77UCBAu
BQh5FvWC4gQ9PT3IskxdXVKaqRIFPwsXLuTVV19lypQpdHd3s3nzZo4cOZLzOzfeeCP33HMP73rX
u0Z9rut6qkkZYNOmTfzP//xP6ng4HMbpdFaUkNkidSiEKvAV6Qf0uA6l/i9oCj/QbydmLz03967h
DgarM261s8LdNY//OFG8FNl75p7M2pdZKETdYEM4iNO+Nyuhu6KJuLUgumNkM1AVnMbz3tJD10JM
p/pcE6cGmmjT3CAI1KDicqp0Okpf9C3MHgzxlpG7kjYdKwQ/e91umMDG7klalEVaLz1vRDl6bmFB
31kvhtjxcp7rMAxu+lEbgh7lqVsuy5x0BiDGFE+YuioNj5JAMlT0uErIrzLQr9HXa2IYI+uHIBhs
2NCLafrp6NDo6KjMe9rQIPPcc2tZurR4mUALlrpITc1ow2tV2MdisdQ6YLdnl6GzznOXqTkbj8dJ
JBIlMa5ZrXOxWCzVW+/1elNedKnQdZ1gMDgqQmi3Vy4yNEHIaOHLeitPnjzJd7/7Xc6ePUtnZycf
/vCHue6661i1alX+L+dBT09PSu9yypQp9PTk7sU7ffo0e/bsYf369eOOZTLeYxtpLya34WXq++gx
DqU8OyM2n5invEIWSS5uw2KaJts7Cg/HpqP15GQmTW4nVoKXacGQRLb5qqhLXMka/xlU78lxi4sq
G1RFGxh0jHiZulHaI2z3S9jOzWbX8CQGhPMv7/lXZAgFV9SgRogyVMamBaAvDsVQ3e41q1gX9dPq
9hZNLZcThkFTOECTLjEUUXgtMg13o45kD6J3mRD1QI5e2S6HAmjkXDJEkd/cuYAtn9rDZE+Yes8w
bnsC+bxBDAdUBvs1entNenQpCxPQ+DmYpkhLyxTWr4eOjhMsX16NpokcOmRQDglkd7fGzTfv5sUX
r6KxsfBNzei5Zc8ZWsQCmqYRj8fx+/2pjoKJZLoph/81ncBheHiYUChUMIFDNvy5FPxAmSHZr3/9
6zQ3N/NP//RP3HbbbSxcuJB/+Zd/4Ve/+lVBbvg111xDd/f4ovtvfvObo/6fjxkiFArx4Q9/mO99
73t4PPkffLfbTSQSKXs3lwvFGOF6cQaNsVV0unYDcMgoTpkk498vsrKwJuLhQKyppL81aHpZ1+ug
bVpx/YGZMGCT+INtNkuDU5kq7MP0jFaw6HCEqIpIqK5kX5kuFm6NDMOgqttHoGcGf4rVo4lS1ihe
J3bmR6NEhdLzii41QVAq3ktt1atYGxpip69MnlvDYF44RJ0qcC4sc0arouP8ezRVDHFO9kCDAxqA
oRicM2FYAXH8stAesbNiXZC9rXk8F0Hm5P8sYXHVCWIxlYN7TEKhdMKFUjcBAjt2TGHDBont248B
MH26ncZGL/v2qUSjpRnOU6fi3HRTC1u3XkVtbfHCEYWsc+lcqhYBuUVxZxmhSy38aY1RVTVeHi2X
pzyRc7oUULLBFASBffv28bOf/QxVVampqeGmm27ii1/8Yup4PrzwwgtZj1mh2IaGBs6dO8fkyZMz
nqeqKh/60Ie47bbbuPHGGwuau8X2YxnMi+1hAixNbKHDvgdJt/OKozTDlQ6hSOKC6EBpBAkWWk9O
KtvLTMdBr5Pj2lo2DPUheQ4gnu+d0xUTT6yBIZJN8vECPIyRsGsjOzRPsuK1gGkeM50si4U5IIiY
JYSlJgkGZ0r0Enfq1awP+9nhLq4PV1BVFkUjeFWJ02GF44aP46mDI+dNkXXOpe9vahxQA4RV6IjA
gAziaGahWIGCOVV2jT/+0cvGjWFUdZB160zCYYFDh2TK4EoBBLZvr2fjRoGWlqO0t8dpb4/j8Uhs
2FBDe7tGZ2fx4+/fH+ZDH9rGs89eicdTGR7fTEhnERprhMotkrRQacObzv+azrdbjKf85+RhlqVW
YpomoVAIRVHo7u7m0UcfZfny5RUxPjfccAOPPfYYAI899lhGY2iaJrfffjuLFy/mH/7hHwoe+0JJ
fBUzZo00lZnRdajqQjRb+RJpRXmYusEr7XPyn5cDg6aXWb2VlXaLyxKv1jRwTH0HYmAkz9ThDGCP
JBe2cI49n31Ywts2l2N7r+J3vQtp071F91Hu192sicagBIJ+n1mGdJiQJGtfFcqva2WLxVkZDLK2
P4Kvy+TwYBU7gh56crTcOLKF7N0KLHDBKgEmR4GRtp8jIQ9z5vrzzkdWVUCgpcXNqlV1tLbGOHQo
TlNThMsvV6mvL0czV6ClpY5160aK4kIhne3b++nsHGL5cp2lSwWguHvf0hLgttu2kyhSdq0UA5Uu
2+XxeFLVqolEItULXiom0lO1wrWWPFooFMqqmDIRc7oUUNaWZvXq1bz1VpIqZNWqVTz//PN88Ytf
rMjN+dKXvsQLL7zA/Pnzefnll/nSl74EQFdXF+9973sBeOONN/jpT3/KK6+8wsqVK1m5ciVbt27N
O7bP58Pvz//il4tiDKZpmiyKXcubanmGa2S8whf46lB1Sii6HLSemIRDq6yYNECHy8bzniUEQ+sh
pmDI4DKS8w2OiakahoG3y4OwbxlvHLmC5wPT6RfKKzDYqXtZH85NY5cJznI3YYLIvoSP5ZHx/R/e
aIQ1/gAre8KI5yT2DHjZGXLhNwvzkIJanlffocBsJ6yWoTGa5LoTBGoW5/e0437LICaN5saNdYBB
R4fJtm0xBgdjXHZZmFWrVESxlGIxgdbWejZsWASjqsEF9u3zc/DgADNmxFm/XsLhKNxwbt06yCc/
ubPigui5YBkhm82GKIoEg0ECgUDJGp0Xgng9XeDa4XCkBK6zyaP9ORnMsqtkVVVFURTOnj3L9OnT
3xY35hvf+AYrVqzg6quvBpKVZek8jJWAYRhEo9GceVKLhs8idRdFkQccA/y6qpwdeBLXh8/Q7R4s
6Fz9+FKeOLeu7L8J8J55p2ibWv78s6EqobMu2oHpOk59XOOgOY9BrwshblDd1cipgUbarLBrJWGa
rLMFaPUUHiJdHwmwI+Ir+0/bTY2ZtjCDpshsLcm1ejhqQxdKLHhRVTyYhIQinnfDgF4VOuPU7zbp
H8h+H2YF3uLUodEGed26GK2tPYzNAtXWmixY4KCry+TMmWI3NiYbNwZoadlPtr2/xyOxdGkNZ8+q
dHUVdr/uuquR7353TUFrWSKRIB6Pl60DbEXqbDYbiUSCWCyGaZpFk75b9KSFVOfngqZphMPhgjnB
rcKmRCIxLlwbjUYxTROXK5nPt+hGL3FUvkoWSJUcX6rqJJlwMUOyhmGkjKTVfmNR8YmiyCd0kf/R
zpadCzQLDMmKOjzfOa/MWMMIWo/XM6n+LLE8RASlwm+TeME2k0XhBmrDbYRNBW/HXHb7J494khOx
ZxME3ox7WCYG2O8qzAhqBZAWFIJp8RjOfpF5isBBTSEo28u6xulSnPYiWl2AZMVugx2m2BhojsG2
MBxwjqvkFdDpOJEARi/Yra0O1qyZyu7d3aNaRgYHBVpa4oDJokUGXq/MgQMm0WghxlygpaWKjRuX
09Kyj0wPsRWuFQSTFStq0DSRgwd1clXXPvRQJ3V1dr72tWV5ZzARzf12u31UdW0hjDyVnk+x42Qq
bLL6UCuVn70U8OdxFUVirGLJRMLqbbK4JyORCIZhoCgKbrcbp9OJooxQmE2WHHwwWlqJ+2gUFlaq
DtTTL5ZZjZmGQbzM7J64wgkLHWGJlp0b0F9chv9UNY6wWlKesRgYosSxqIv5eVRGLET18l6vSfEI
awaDnD7nYl/YS8uwBzMisdEM4dVK9+In28ow5IKAWeeE97vhU1FY1gfCyFwaahKo8czezZtv2li+
vAFZzhQmFWhr02htjSEIMdati7NokUohz3FLi4+NG1fmPNc0BfbuHebgwUFmzoyzbl3ucO03v3mS
H/wgd993JZGpMEZRFDweDz6fD0EQCAQCBIPBVI9kIeNUaj6FIj1caxlPS3LsQoa6Jwp/sQZzIj1M
y0hCsv0mFksWTtjtdtxudypcke2BvE2rw1lmLrBQDzObUHQ5aH1rKg61jIKXHHAN6cx8uY7jzy2k
2z+Zts5ajrdLdJz00HAkzrquEKv8QbzR6IT8/Zgo0xexMS0aznvucIldNq5EnI3BEMFuG28GvEl6
vvMIGTIt/vOGk3BJhlMpZ7dvGDAQhN4YuGywZRJ8RoBrw+CLMMmTu2hlzx4bCxZMweHIfl4kItDa
mqCtLcbMmVGuuEKjri73zWxp8bBhwyoKMbBnzsRobe1DloOsXw/TpmU24J///GEef/xkzrEuhIGy
GHmqq6tRFIVIJEIgEEiFbS/0fApBemGTFYX0+/2EQqGSpMYuFVzygeSJwESEZDPlI4GSCN3rZDs3
R738lzf/opx1PgUsHLIq8occQtGlYljwsL7XyZHG8vsyLdhCOo176tl5so6282QFHjHOibiNxQmN
QUmlGyfdfUAfCKbOfE+E2ioTv8PgqM2GUSF2kSHRhjNmJokNHFmIDQydXlWGIv6koKqsS8Q4Puig
Rc8dZQgZMi3DMl5RY6MvNBKqLQCBfAU/mdAVhqAItSJMGpOvc9tglQ2W6RzuikGnCG9oZNuPHzpk
Z+HCqbS39xAO557LmTMGZ85EkSSDVasMTFNizx7IxAaxfbub9etXs2PHrqx/Ox2hkMGOHYOpcK2q
Shw6pKe+a5oin/rUfqqrbWzZUjqbVKWQjUC9HNL3bKh0qNlyEkotZrpU8BdpMCsVkjUMI2UgM+Uj
LT7JUh68j+p1PKWFCMklqqUXsCb6Ag05haLLQevJyUyZfJaoUl4QQ4qoNO2tZf+JyRzXRi+S9vNe
9OEhFxumBthujhw3BYljYRec33O4BJX51RFsHp1OxaTT7SmLSafr/2fvzcPkOus738/Zaq/qfdHe
Wq193wwGC08UT0jGOITYZMgASfAzd5JJCONEbMNzb0iY2EkessBzby6By5jlGUISEmy2jIFgDKjV
klqSZe271FKr9+7azn7e+0f1KVVXV3XX0i0km+/ztOWqOnXqrTrveb/vb/v+CLLG0MlKJmYJIm5x
bUYqVQnyPLaZGUbGNA5Z1SWPpDyVg+OxHHE2ZHjVVmcmTtvmCmpFMdBOkWZ5RGLAVri8IAILZ3mT
quAsjcKBKAzp8P0k/FMKzOnLzNmzAVavXsDg4G0mJmYfjOvK9PbagE1bGyxf7nDrlkJf31T3/6FD
EXbv3kVPTw+V7gR9dy1AV1eI9vY4J05YmKaC40j8+q/nxNofemh6W7CfhkVXLKBeKPo+V27P+eiF
WSjWcL/idemSrdXC9F2tlmXl45Gu65aNR9ZjuTYqAZ7Ua8+88yqwMM/3d9V8/tkwRoyuOuoyJdNh
+ZEYma+t4YdnFzHulLjJCjw73bdibJHLN2HMCo3jYxF6bsS5eTlBxxmLXTfTbB9PkdCzZd83E86L
MGt0C8meXhrRVGEN5hozxYYRk2MDca5btf9eKU/l4FgU8jHO0m3Tlio6ulR+wWpyM+wNpVgX0LlN
hIN6lMtOqPqs47YwPNkBzy2DP2yAJdPn44ULKo2NnTQ3V3ePDA1BT49DX5/Bhg06u3bZBIN3vBk9
PSF27dpDtbWYAFev5ty1wWCavXthwQKXbBbe8Y4ejh+frs18N8o4ZoIv+t7Y2IiqqnieRzabnbU2
cr7GM9/n+mnjZxbmLPBJ0rck4e40mAZ4p9vCP1hJkoHq9zWzxTDDpsr3hpbPuTu2EIcud9DRfq0q
K9OzHFacjnH5VAc/MGe20OzC8J0kc3kwyoKWNP3S7ElTA06IgWFgGCTPZWU0Q3PcJhWVuRAM4lbo
vj0p4uzSUxxWlCkWa2wWpaUFZppFGYkjE1GQ5m7fmpqMccZkh73xNK86KmntDhG3BSSuF3FpzNVZ
H3XRPZlTZohuY3JSzMXUDmvwUBPsTcBlHZ4fh5ct/L36tWsqixZ10N4+wOBgtR8oceqUAzjEYoJt
2yTGxgTnzqkcPhxkx469HDvWg+dV/0WSSZfu7kJ3rcTb3naQF17Yxfr1bVPKIu4FMvDdtX5zaD/J
cDbR93IQQsxZZutriTBftxZmIWEWW4J+PNIwDDKZDJZl5SdkJBKpuNddvbHRhKLxH83qpNF8eLMQ
ZnCi8kbRtWJMRFk+VJlb0vM8lp4KEPzacl7q7eLGLGQJkC5a+FOORkRX0LzqEmGErHBJj3J4sJGz
VxIEzilsuZZl90iapZn0rNm3h904u9NTN2BamaStuKGzN5lmuD/MkeTckmUh0p5K90QMsgp7vGQ+
OUibjHMFHJMdoQzbQzqWpNFjxDhpRfBqre2cDaoCa2LwB4vhswvgP4ZhsivNzZsasryAhQtrP306
LdHdbXDunMmKFQYPPuhw6RJs2bIbRanH0sq5a0+dGiEczvDf//sRXnnlcl5cwPO8eyLJphB+sk08
Hs93U0mn01WpCM2nhXk/k+fr0sL0m0b78InNtu2y8cifFp5wm/l7K8lYoLpJNptL9tjN2jqTVIuD
F9vpbJvZylx8XmH0xGJeTlVXTjNaorrjUjLMrlCSw55Wc4xSFyonxlWY9PC2ayZdTS5uxOOiJjMR
mS6o3uM0sDuTpCeaq9FUiswzxbHZZRqcHgnR7dXXAaUapIXGoVGJNpFiY3QcMZHkoYZG+qUA/YaC
J1wacXEdgSfJeELgIeGJnEPTFbk/TwBqcG7ajrWF4ckwPNYMvRn4XyPcvqHQ2tpJV9cQV6/Wl0V5
+bLL5cs6miaQ5QBvetMmfvjDY4RCErGYSjisEArJKIogFFJRVQlZ9vWXBZ4ncF0Px3ExTRfTdNB1
h9HRCb73PYdbt27R0hLhoYcW8sY3drJ9+6KqxAVKYS4IqnhzXonoe6XnqmdMryUL83VJmD5BvvLK
K2SzWTZvzhUoO46TV6mYK8X/eideVNF4l9HApwPVJSnNZGFG9QAHJ7ruin9hnCh7hyKcWTg9ptZx
Tcbs7eTHo9VrvKrCYTirlXQpHx6Is2txksNubdZ5MQbtIIODkw88l1WxLG0NHsmIxFlNzblvJYkj
RpQtUooTkTiWv+a7LtuMNLfHgnQ79anB4DhEhUlCFcQUCMqCACAjkCVAyHhIuJ6M4UpkHEjZEhO2
RFtY0D8WJh2Ks8r2SHoSQ0o053aVmH0uCAGei+xYKBLIEliWQDhSrpJDiJwumJBy/3rk/qNJufM7
3mT7MAkQdzTEVsnwwRa4PMpwt4FxupnVq8e4cKFya0hVDdrbJRobIRIRaJoAHEzTIZWyuXbNpKGh
la6uIKGQxfDwGOfODVNLPKK9PcCrr44CY7z0Uq4BQEtLgIceWsi+fcv4+Z9fxcqV1clMzodoSiFm
En2fyV0714IMrwXMSQPp+cLo6ChPPvkk165do6uri69+9atTmpAWwnVddu7cyeLFi3nhhRdKHuM4
Dj/60Y/4+te/zhe+8AUikQi/93u/x/ve9z4MwyAajc7phTUMA0VR6s4Ky7o2vxq5ynAVVuYbjFfQ
yxRmR26s4LNX9tU1pmrQKGVZsPcq2Ukrs6UP5OOdHBlI1OyS7FR0bl8rb6kFJYeF7VmuSPVL082E
EDYPNNqEEoKBANwOBVgaMcAEJQ3ehMo5o2ictkUMi7gKMRXCsoQm3eEWhITtgeNJGK5E1oGkLZFy
5KramQGs1FKEVYVXk2E61AwD4ZwVrwmXLQmdIQmuyXMhlFEFbAcmcgLtNGo5d21Sz3VMuZqC3nEW
nh7kVrdBKGTS1gbxuEcoJAgEBEJ4ZLMG2azHyIjJ+PidUpBKEY1KdHWpJBIwPj7OhQuDOM7s99fe
vS10d8/Um1ewalUDb3nLUh55ZAX79i2jqWnmTHQhBGNjYzQ3N1f1HYpRrpl1KfghJ9u2S6oIJZPJ
fBLjXI/pPmgeDWUi+Pc0YR44cIDW1lYOHDjAs88+y9jYGM8880zJYz/5yU9y9OhRUqkUzz///LTX
z58/zxve8AaWLVvG2972Nr7xjW/w4osv5ndXmUyGcDg8p+7XudSo/YoY4i8TlQvG7zGOY4WmXz4h
BK8efrTm3pe14t+vvMJtzSDc28Ghmw11x8rWhbKcuThzr8lFEZOJOKTrFF+vBu2qyZrgGIqRwoh3
4qFge2C4ct7iSzoyXpXEVy0WSGkWRSWOjIXzm5LNDRlecYsWb+GxNaajKw7nmOOm1cUYyYAhoDGQ
q930YRg5sffCDirDOtLFFG1XxlnRdxs3YyNJKuAiSQLXdZAkaTJr3cE0XXTdIpu1SaUsbLu6VmKB
AKxeHSKR8Mhkkly4cJtS2hebNiU4ebIyjWYARYFduzp55JFlvOUtXezduwRNm+rYq4boZoLruqRS
qbJGRSl4nodhGJimOaVRdDKZJBqN1q35Wjymudbsnkfcf4S5du1aXnrppXxvzH379nH27HS5qr6+
Pt773vfy0Y9+lE9+8pMlLUzXdbl582Ze8/bhhx/m+eefn1fC9It052JHZXou7whdZjBYmZW50+jF
DU0/tjET5f8++mTd46kGDa7F5p9c51qkk+sNc2PN7AinOHphdhfnlpYUJ5To/BLBJKKuwSbX5vJt
waAWZ12TjhJzeNWqr+azGjSgsy7ucnQsjF3kctzbnqE7W8baEYJ1YZ1gyOW4G8mt9HOBlAX9DkRk
WBQs7Xofy0BbmXGlLLhhwtk0HRdTLNN1LMviypUkExPlxijQNI9YTCYSkQmHJUIhiUAgF4KVZYEk
CRzHRFFkbNvD8xwMI+fGzWYtDMOmvV2hpSWAaaa5ePE24JHJ2JQXqnFRFEEwqBIMqmiagqrKqKpM
IKCiqgqJRICNG9vZtKmdhx9eyrp1bXieVzXRlYLjOKTT6ZrOI4SYIvouhCAej9dNmMUi7vc7Yd7T
McyBgQE6OnJ9EDs6OhgYKO0K+cAHPsCf//mfz1gqoijKFIH4WCxGJpPJdxm4F5pIz4SgrPAeo4E/
D1YWy3QlQalrXm+j6GqgCZcdVzKc+oiG9EAWbUwl+J8tzGD9N4xSobD5iZE4exYlOeTOo2vWsdmt
6Fy6FaLbiLOpI8NgVuLMeATGYW2jTiBm88o8EmfAM9nRYPNqMkT3WGlXtTdTuEGSOGNEwIAuLUtr
zKXXDuGpNVjClg03LXBlWKTBmpk9AcykuRsPwPoArAgzcKuRgVtZOOPCxWGWLJHo6HDxPJ2BgQw3
b3rkrEoJ21YYG4OxsVwiT2kEiv7fIxRyaG0NsXBhgEgkZ6WGQgpr1kiEQmk8TyYUSuO6KRzHI5PJ
kEya3L6dJpuVcF2FbBayZUt7LXp6+oA+oJeFC4O8+c0L2LOnmV/4hVV0ddVHmrWGlIpF31OpFKlU
qmLR93J4LSX8wD1AmPv37+f27dvTnv/EJz4x5XE5xZxvfOMbtLe3s23bNn7wgx9U/Lm+eMF8EqYk
SXMqOPwYLXxJn6A/PPME9GwbIYvpdDkHjaIrghBsHUkx8AmZ7t4EmpYluSDLpfMhdnw7zdHH1PqJ
owph88N9UdYumOAsc5MEVIh1IoU9ptIzfoeQY2GgYME8Ox6G8TAPNOqEYjYn5pI4HZvdjQZXM0EO
js1svScr/M2u2hGujkG7bLAsluWkG8TQZhdVWEyaJRGJy7LKwPIqFKQque9CKqxQYWkAltmwK8SN
QYkbPx6BXg1opLHRZulSj3DYYXw8y4ULGTwvR/iBgE1ra5CGhiDRaC571HUFEMQwJCYmYHRUkE4r
9PWVvr+2bVM5dkwCGpAkj5UrBU1NJolElqGhUZqaZFpbFWIxmVwemIvjWGQyOhMTWQYHM9j21Gtw
65bJV75yla985Sof+MBRVq2KsW/fIt785gU8/PAiOjoq98jMBTn5KkKQWyNN0ySZTKKq6qwa2JWM
6X4nz586Yb744otlX/NdsZ2dnfT399Pe3j7tmJ/85Cc8//zzfOtb38pLRL373e/mC1/4woyf64sX
LKyn+OsuobAl2K8ZYT4ZLq3i4kM2bYhOXxybs81z0ih6JjxgZBD/j83xf7mzU9606Tru5FQ7+t0Y
e5YmObS9PovPMCvf3HiSwtBYhOYmnVHmpqSj3U2zxICjN6f33rTKVPyfmyTOVYks4ajNSbeOmKHn
sTWWYdzS6BmvIPvW87hpVPdZg16IwWSIhGSxrSHNWU9hTJ76+0Vcgw0Rm7RQOF/60mcAACAASURB
VGNG6cvWsCDalWfEoiqwRIHFQRgwYVE7PCahXEgROzOO6gXwPJVEQmHjRhXbFjQ2uriuw8iIzrlz
Np5XvYcjFDI5c8ZPKc7pzF68CBABIshyM6tXC5qbbTKZFCdOjKHrMrklNj7559HUJNPSohCJQCDg
Icu5sWWzOqmUyfXrKT772fN89rPnAY/Nm5t4+OFF7Nu3gIceWkhDQ/n5O5cyfZDLro1EIvmylOyk
2exn11byWa81C/OejmEeOHCAlpYWPvjBD/LMM88wPj5eNukH4KWXXuIv/uIvymbJFp/70UcfZffu
XOPkucpoLYTjONi2TThc3SLtxxAcx8FxHDzPy9dUWa7Dr0dvcHMGK1NLZ9kYOzf9vJc387/6dlb9
PSrBQteg4wWLY38ZozjZYvPm76KF2jl6Mle+oyguD/xhltOLay+zWJZMcS1Z3fs3NOucklWoxc04
iaBrsl2YHLsWwfBK7zeXdhpcz8xuka1MGDQkHHrNcFUxwweCKWRJ4Ux6FldnAVrlNMOR+uLHARy2
NRjccAVNYZmwAqf0ILpU5757xICOOhoej1ow4IAnwzDQY8EPJShxfTTNYdkyl+ZmGyGypFI2V6+a
GMbMJLpjh83Ro5Uv/IrismaNoKkp5948d24Uy6rkGgsaGqRJSzUXe82Rqo1lGSxcqLFpUwMPP7yU
Bx9cQDh8Z9x+G61YrL7rXC4JqVDQxXEcgsFgvrlEORiGgeu6RKM5j8N90jwa7scY5oc+9CGeeOIJ
Pve5z+XLSgBu3brFU089xTe/+c1p76l0N3M3mkhXAyFE3pKcTYLv3ekYfxou38lEK7HPkV34Tt/q
OR93wrNZf1Tn8H8Pc8uYbjU2N49y6tQEO/csyj/nugq3PxOi9ekMww01iL8LwXCy+l3rqdEwexel
6HZrIEzPY6uYoL8/zEG9vHUclHRupAMVycpdSoYgCSsSBo2JLL3mzMk2i6QUbSE4npxu1c6GzpjE
cJ3RAcuTSWdtQkIjAEzILrpc3xKiOjpeW6DC7q1l0ByAmJzrqCKAt3jwaBQu2PB9C67eIWPbVrl4
USXXRiZHLJLksnSpQ3u7g6bZpFJZbtzQmZi4k6xXrZXkugpnzlgEgxCJNNDZ2cjixaCqFuPjGYQw
UNUgsuyf15eiE4CCoshIkl+3mpsWoRCMjMC//Rt897ujwCjr1sHy5Q28+c2NbN4cnJNcrXJWYSnR
94mJCTRNK6t+9jML8zWCT33qUzQ0NPDLv/zLwNyWgPjwG0dHSijDwB2dWt/dKklSfgdWriWY4zjo
hs5TTYNcKVE2AtCQSrMifmHKcy3jbXzqlf9Q/5eahOq57Lie5fRHVFI3y1vQe/Yc59Chy+x54yYO
9U4l7DXrs1x6n4YbqI7AosIgcyNQmztTeGxdkua4U7lLeKVIERhTODMyu0W3pinF+RoFCpbHDZob
bI6aYVDuEFGzpLM65nFkNIRbYznOnrY0h+poTP6AlkRRFE4bBRscIVgXyaIF3Vy5Sg2r9XI5zZV6
6kAHspAS0KJC0yTBmQ7c0GHYBi0IlkT0okv7aZeQp6IooCoS4KJqal7lR5IEsiTldJiFgRbS0YIe
GSOL8FxUT0WVQpObW4Flga6rQAjblrAsCdMEXff/fJdsKQja220WLHAIhw0sK8voqM61a1mEqHwN
WrfO5syZ3AY7HPbYuTPMww838tBDCfbsaSAcrn5zWE15ihAC0zQxDCMvHxoIBPJrVzabRZKkvJft
ZxbmfYr5biJd7pyl+mZWI8EnSRKKrPCbZhMfC5WuBytlYfYNzFF2rBBsG88w+Ak4dHg2YhAMDfUB
4HnTv9v50xF2fzdFz79XqiK/Vs0lU2vsT5K5NBBhYUuGW8xs3TZ7OitNhyN9EUSFqjANUaDyctkp
uJIKcSUVYlnMoLVR54yhsKXJ48REiENjlbXkKgdH1GbDLVXStITgWLqEGpMkcUaPgp7LrG2LuRyt
MrO2SXW5UuXQFMMkPm6REQp2Rwg6iuZCUIVVcehyod+GQZ3M6iBXVkkwosAhi7YhaG6BWMhDCcsg
S5iOTFqXGBmXGBkPA60AbFuX5tiZGAjB4k6LzhYPzfMYH4erFyESVonFIBLxiMUEmgaaJpBkDwnf
cySwHYGhe+i6IJ32GBkRDA6GyMVBc6IFgUDO2m1qslEUnWQyzc2bqckSmqnfMxo1OX/+Tt9RXZd5
+WWTl18eAAYIhQS7d0d405sSvPGNCR58sDICrbbVmC/wXqgi5D9XLOJ+v1ubr1vCTCQS3Lp1K/94
rjNaCzFb38xqIYTg56RGvqCPcSE8nRyLbwnVkflO/6q6pfAeMLNI/6/DsX+qzDpbtqyPy5dNQEIu
I/Te880YOxdNcGRL5en0TQGZaxUfPR0pW6Uj66CFTGx5+rgU12YXOievRzjsVBd/lrT6fWK3UhIL
FNguZbEyQWzHq/vazdTSqxRaybAi5nEkFeF6RpmVrPOZtYrBioTBSTtApoKG1gFNhkq08j2PdVqG
mKZwSgQY76zAii9MEBo0c/HNMNAeZCirM3RLhV4V0jPHT7WA371Fom8gSF9BdZu2wKFziUNTTGCn
PW5egf4bd8QiZoQQhMI2sZhHNCqIRMhp2yoBFFUgS3ESDa1Eoy5IBppmImFhWSaDg2kaGhxeeWWm
+KHED3+o88Mf6vgEumtXhIceivPQQwkefLCRSGT6vKjFjep75/yyFNM0mZiYqLkf8L2K1y1hzlUT
6XLw45FCCLLZbD5pp16dWv+9siTzW2YzHwqPTDum+BZITHSiy5UniBRjgWvQ+Q2TY5+MkdsNV4bO
zj6uXfOzCstMNUnilefirDmQ5nxnZa654BxECi4mQ+wOJ+kpFGn3PLbKaYYHA3Sna8viHauuUcoU
KJ7NziaDyyNBuvviLG1RuT4cpiVgsaYzzaumSkqqITmmigzZuDDYkLA5ng7Tk67eqh10QwyOhYhK
Fnsa0lzyZIZnmHvWLJZ7u8iwMiy4bqmcceM5Rfiqu4BJuaSiDmDUhEEXYlFolWCFBcOjcEGBM1Eo
isnKssXZy+WXSdtROXtl6ustm0yWdXoEZUFqWHDprIyeLbHxkiQMI4BhwPCQTTxh0dAoiMUgHAYt
qKCoMqqm4XohDFsiawgyGUiZCv3XJJaucWhtcYiETIRrYBoCIyuhKBqKIlBVgSx7SFLuz3FcfvAD
l+99L42iTNDVpbB2bYitWwPs2pWguVmrO+5YKPqeTCYxTRPHceqq57xX8LolzLlO+ilM2nFdFyFE
fnJEIpE5UxAqHOc+uZF1+ihniqxMtYhQam0UHXct1h/TOfqxMP3ZamsYLS5durMVd5zy39+yFMY+
o9L0AZ2x+OwWnezNjeu853acXYtTHHYTdIkM8RQcH6yj3EXYXE9VHzOS3BxR9o0FONSXs5w0DPoy
GkgwYgU4eD1ARHHY25nmsicxKCpPlmqSs4x50RmJRvVMdiZMzmRDdKfqFIkHMiLAofFATrwinmRY
lktq1g6VmBeaY7IlYmMgc8oIMWjM4SLbHIRmCFkm4dsGY2jQ2gxdNuw24UYajsswWVe7cY3NK2er
S0wbS3kgezk3bSus2+8Sj40hhIRtGAQVgex5OI6Ma4fQMx6ZtIJjaximxFAajCHIZAS44RnDFddv
BLh+Y+pzquqweJFNS5OLqnmYhsvwkMP1axKiqKTm4MHcv3v3punuTrFqFWzeDBs3CvbsybJtm0Zz
c21Z5bIs57ujCCEwDCNPpvcr7t+R14liC7MWwizXXNrvACBJEul0et5cEpIk8VtmC38QHp7yvFrw
PcJW9Y2iVc9lR1+WMx9ROHSjtmL/9esvc/r0HRe3U6YEw8fQYIgNX9UZ/082YpYkILsOK24KJIkb
t2TeHOrjxwPtuFJ9CV/LEibXqCKBxbXZ0WQwMBHg8M2pJLWsweGiNdWazLoq3TdjqJLL9rYko4rE
VTE7uXVGXcbKzUHHZleDznUzWLNVPRNsSeFoOgHCY0ssg6V6nBE5qULVMbgpqbm56Xk8oGVp1CRO
GwGOWJO/4zwpChqBIMbSIEHPYYuSpr8PboRi0AHKZovo+BjahTRSKsmiBW1E4xrRWCDX4UwDFAkB
mLaLi4ZuQVqXSGYlMkaQEUlmxAOSk38lRMokyaW9waG1wyWx1ENFYJuQTEH/gIB0FC3gEA5CKCAI
BSCoCTQVNEWgKCDlmrEhCYEkQJ78wYQr4ToSui1jB2XCrRqrmlxiYZtw0AXPRU+5DA9r3Lguc+1a
Ljv34kW4eBG+9jUACzBYuVKwdavCtm3+X+Uk6scw/XXxfiZLeB0TZrGFWSkKM1sLk3bC4fBd9df7
bpOH5AY2Zkd5NXKHnBT5zhiC44srbxQtBFsnMgz/D4lDh+qzMkKh/imPHWd2xj51LMzerjTd/27m
mzFr1G9hNgudBxyP4+dVeiIddEQcFraNc04PkqqxX2VrA1yrJOHHddnelGU0pXH0ZunfuTlKbr0q
AUco9A5OklBbBivoccYur5cbC0rTz+V5bI2kmXA1Dmfmt6MLAJLMiUzOUlsTzBKLeIwpDklJY03Q
4JatcM6N5VyudxGmrNIjYrDAZYuawRrxODMUJdnexI5VQY6fb6c16KEFHFTJRnUlbN0jPSFI6wGU
gEJAA1WGFlnQLnkokos82QJN8luvTbY0k5AQXu7/hSdyVqft4ngSDhK2DEoAOhsklkjjREOCgOSB
52GbEqkUDA4LhscSBAMS8YhKNAKRsCAccIiEBImYTDwmEY9KxMKCaEQiHoFIWCIWVolFJaIRQTTk
ockGAVknFGxgbMxjbAwGBgzGxgTpdICxMYnRUcHYmMcLL7h88YuC8XGXxkbBxo0htm1T2LpVYetW
ldbW6RvOnyn9vEZQjUu2UETAT9pRFKUiV6t/3rmaKMXnkSSJp6xmfi88lH9NKfgex252VXTeVUYG
7f9zOf739S+ekUiGU6dGKfQBmmZlpkL316LsWJzi6APlCbtU4+hK0SKyrHY8jp0NcdBVWd6S5IqZ
4FZK41YqTEh12L00w5AruGJUV+6gabNcY89jUyxJRg/QW4Yo85ArSECTZE4M50jogcYskbjLMT00
TZhB1pQphLlaGUMJahwvUTc7J7BN4pJDgwYxRRBScu3LFAAvly2qjOgsljLIDTGGM0FiisxGKZtv
zSlJd1p1StIdmUep4DX/8Z1/Ra4lp/BypARIspS7R6WcRYgAT+RahAnuSG6KyT6dais8nBimNWsz
NppgR6dMypJImho3rQBpS8JBg7hEMGHTGbZJhAUB18MxBKkk3LotSOpVCv4Lj3jQpi0haE1ItMU9
WhPh3OMYk88L2uLQEvdoiRrEYoWxYYlkUicYDOK6FqZplpCzKzWeADB1HmSzTCkFKQXP8xgbsxkZ
8RgfFxw9ahKP6yxbJrNwYSy/Fv2MMF8jCIVCGMYdibliwiyMRxZmtlabtHM3BBH2yA1s18c4Fslt
z/0YZtwIztooutM1WfAtnWN/EaeWhrqlsHbtRXp7p/5GRoWEiSRx6u8irPiQzuXW6Tes5DkMpNWq
h9omsiy3HI6fj9Dt3pn2ba0KV24WjNNR6bmsghCsX6ATjrv0TgQRFWSZZspptXoeGxMZbF3h5EBl
2cBZr7oveG5S6H1JzGBBk06vEcJRcjv+tJu7Fl1qhsaA4HimEdwK57BtE5csEqogIgtCkkdAllBl
CQkZT0i5vp0OpB0p17DaUUhJQVIlFBzDwmRLk80xvZktLSF6kgkWaCZLYjZH9GBtYu9zhA7F5N2L
HN69KMDSaAjPc1EU8htkAMexGRkfYzRjY3oaSV1AME7agpQpk7YhaQiy2TE8CzJZGJsQjCcDxCIa
7ZOE2Br3aEsI2uISESVNZ7NKS1OMO1uA2rLnZVkmGAzm5ewymUzJ+shKzjMTZFmmpSVIS8vM53mt
CRe8bgmzGD6pmaaJ67p5OTpN0+rObJ1rFFutkiTxlNnMfwkPIkkSvl6IGF1a3k3n2aw/luXYx0Lc
ztTXIaEYhjFdTN80KycAw1AwP6sQf79JKjzVndymuQwqlWeKtoksXabD8QsRetzp2ZpltzKSxOnb
YbgNbTGLVQsznMvIjJYrM/E8+tJFv7UQrI+mEbbCq/1VuLg9j/50bZuXG+kQN9IhWoMmq9vTnDRk
TMtkd8zl8FiAEcNhsZYlqghCkkBFIAOKJOGh5Mkv40gkLYkJRyYlR6kqeFHqVhEuuxqzXMkE6R6f
tNwn41n9dpD+sSAdqsmyYIqjZgj3bhGnEDwU13l3p86jLSaRYIBgMIiiKHieh+d5WJaVV7mRZZmO
1kbamj2y2SyWZaFp+qQlV6jINZt34s5cSaUUgnPQwQeYsibMVB85EyHORz36awWve8L88Y9/TCqV
4k1vehNAvn9lOaWdanG3JPd2qA3s0cfoiTgoCGwhONi3fNpxiuey7Uaa8x9V6akxoWcmdHYOcvp0
iuIdclavbsd8sy/A5n/K8sqvuVMUZJo1wWAF728XKZYaHq9cjHG4BFH6uJ2a/RoPpQMMnQ+gyS47
l2RIyR7n0lNdbm3hDEP2HVJ8IJxC8xRevV29jF1jMMuINXNW62wYNoOYN2FjcxY55dGX9pB98ptZ
u38q5iDpZl04hSNpHJ6YumlIF1m5A06QgYkg7arJ8lCKo0YQR52f3okJyeGdC0x+a7HDxmYNCCNE
CMuyyGQyeUvNV93yPA/btoE7FmfO/emiaVpNlpyPuRRNLxWyKayP9OXsZmvbNZ/juZ9xd7ra1oHR
0VH279/PmjVr+Pmf/3nGx8dLHjc+Ps473vEO1q1bx/r16+nu7i55nGEYfOtb3+Kpp57i2LFjPP30
0/T19REK5ayWUtqt9xrKkfD7zOZcOQuCpmyMk8biOy8KwabRCRZ8JMORdzeQvFGDhmsFWL68j+nT
yiabrX6qvdId4cGfTNXMjc4S22sTKXbpScZejXDkXAOWW95SiwV0biQrb+5tewpHrkU5dyXOKmGy
K5FCE7mU3UVNufmyKpxmSzjDuYEYrw5HqiZLgIUJr6b3+VCFzd72FLIs0T3cxE/6WxgeiLIrYNLg
6TWft1osULNsT2Q4k41xITvdKzBklZ4Tg06QQ+NxGm3BbjlJwCmT/VQthGBz2OCvV6c4/xadv9ws
TZJlDn5PyHg8TiAQwDAM0uk0juPkSVKWZVzXxbIsbNvOk2RDQ0PeDToxMYGu6/MmhFL+681MvKqq
EovFaGhoQJIkkskkqVQK27anrCfzReD38ppaKe55C/OZZ55h//79HDhwgGeffZZnnnmmZMeS97//
/bz1rW/lH//xH/NdvosxNDTE6tWr2bx5M48//jgbN27kO9/5Tn6XNR8X9G6Kum9RE7wxOwYIMkNL
8s+vNDIEPu9w8itzb1FOhUdf381pz4bDCnqNU+3g38fYujDJ8ZW5xAStzG/ZKdIsNQS9FyIMVRj/
W97pcXK0NtfnxeEwDENjyGLtkgyaO8q2iMSx25GcyksdUykWFFP6aVYM4bCzXacvHaB7cKo1l3VV
uvtiRFWHvZ0pTlsKyTrELGZCBJPNTTa9Y2H6k6VVgoJeliE7OOOWfdgNMpwM0iybrApMcMIMYWqV
b3DynyUcfrnd4n1LHPa2KUiz6PH6VpkvMu5rpfrPSZKUJ0xVVbEsK6/cVa0lB/NrYZZCubZdvnV8
t8dzP+GeF19fu3YtL730Ur435r59+zh79uyUYyYmJti2bRuXL1+e9XwjIyO0TEaqf+mXfom//du/
paEhRyTZbDYfv5grzEfbMF3X0TQtX9Pkiya4rstJa4Ivauf43tmd6HaCJf+qc/TZKNP1f+YeDzxw
lXPneqc939KqMZKpXfg9GnVo/qDFjeYIu5UkPdfuZPUtIM0SQ9B7PoJTZaLMg+syHKzT0l4cSdMZ
BSF7SEGZm65Ev1PfOXcvTdMzVEWGruexuTlN2gtwOVlZfDei2Gzu1DntaCSluekRimuzq9ngSibI
sDOzK7UrlOaqWl0WcqNs8kDM5IQVxKhAdm9lwOS9i21+fbFHe6R220AIgW3bmKaJ53n5eKbvevVj
nX6JmSRJeUvUNE1M08znQpSqQxwfHycej9e17gghGBsbo6mpqWqSKm7bBRCNRutuRGHbNrquk0jk
7ldZlud0HZxn3J/i6wMDA3R0dAC5htIDA9MrgK9cuUJbWxu/8Ru/wYkTJ9ixYwd//dd/XbJLSEtB
WpcvXuAT5t0SYJ8LFNeDQs7lsjXczLcvN7LgaICjH4XBOU7omQmNjdOtS4BIJMRI+W5ksyKTUWn+
nEX4dw3MyRm7UEqzSJfoPR+mv0qi9GGUy2qtAO2RLF1xj6OXw/QNKixu1+m7GUaRXHatyNDnQb9V
G3GOV5EgtSqWJKipvDJWXYlI1tXovqkRVR0e7EzzqqWQkmsnznXhFLakTotTlkNTCK5W0TcaYNwL
cigZpFGx2BxM8aoZIFtEnLJw+YVmk99a6rK/Q55Mbqkt49R1XWzbzrteNU1DUZS8S9bzvPwGuzjO
6cc+Cy25dDqdV77xLdW5Ri3nLG7bNTExQTqdzlvHtYoNvBYtzHuCMPfv38/t29MzKz/xiU9MeVxO
GMBxHHp7e/n0pz/Nrl27+P3f/32eeeYZPv7xj8/4ucUdS+YDc0mY/k3seR6maSLLMoqi5Ju4+r/N
24wH+PMPxBDi7uk2KorOmTOl03FC4erdaMW4cS3C1q+n4ed0dhkKvefD3KqRKAHwPK6NVr+QNgWy
rG5yOX41TM9g7vYJyDo3k7nduCsUDl+Kokguu1dkuFEtcQqb66nZb8sFwQwL44KjQ7HKhL7LIOOo
HOyLEVMdHlyQ5lWrOr3aBUqGBTGJ3vHqkpu0SupMy2DcDdAzESAhWewOJDltB4kGJd690OY3lnos
iynUUiLle2p8kgTQNI1oNDrl/vL7P1qWha7r+dinqqpTmr8DeavTz07131Pc0aNeYpkrcvLzN+Lx
OLZtk0ql8mtMtST/M8KcJ7z44otlX/NdsZ2dnfT399Pe3j7tmMWLF7N48WJ27doFwDve8Y6Scc5i
3GtNpEuhlLKQJEl5qSkfvktWCMHatfCOd2T5h3+oXxO0UmzefI1jx0r/doEq+12Ww83TguaUA5s8
6s2nWNCcpb8KYYKYYrC+1eTktQg9o1M9F8taXS4kpy7QrlDoqYE4F0cN+maQu2tUdNY0O/QOR+gf
nr2LSKVIOyoHb1ROnBFMNsZ1jqXi9E/UMA5NLqtkVCmSIsAt3eP/WjrCO1cqxCPhmqyhQktSCIGm
aXlRknILvk+Shd05dF3PP+eXpfhuWb+Ou/A9hmGg63qeZOvBXJKTr4PtE30pkq+0nvO1lvRzz2fJ
PvbYYzz33HMAPPfcczz++OPTjuns7GTJkiWcP38egO9+97ts2LBh1nM3NDQwMXFHy+xeccn6MRPD
MMhkMti2nXfvRCKR/C6wcDdc2IA6EAjwkY94qOrd1BnrL/vKXMUtViwxOXcwzvHPCBaeHmJX6zhB
pUq/3iQWtlR28wYlk10dE8iGQs+lBnRn+ndpjJe/vj5xDl4NsTuUYYE2s2+6rQxXhjB5sD2FjUbP
UBxnnrwHPnEyovKgmiYuimpQXJtdDSnCqkRPqhG7RrELo87xt6g2/2NdiuNvtfk/tjYQCQbQdZ10
Oj0t67MUXNfFMAxSqRSZTAYhBOFwmHg8TjgcrjhT3ndnxmIxIpEIjuOQSqXyoih+roHfaNl35Wqa
RjweJx7PXfBkMpnPyK0Fc5moUwh/Y5BIJIhGo9i2zfj4ONlsdtYs4J9ZmD8FfOhDH+KJJ57gc5/7
HF1dXXz1q18F4NatWzz11FN885vfBOBTn/oU73rXu7Asi5UrV/L5z39+1nPXqic7Hyglv+fvSAsn
nZ9g4E9s3y3r74b9nWtnp8Ov/Zrgi1+c/xhmY+M4J09OlcIrhFpDZmMxmpuyHO+9s8jePBfh5jlo
7Bhh6y9onDNjjBuVJykEgjPfyKpks60jw6VbEQ5fmjm7WEizb4imWpzZSYtzeow9FJy6h5WEze42
nUupIAcH757HIDXpqo0XWJxLojYW0+spa8FwmZKS2RCTbH5npcH710FD8M58KLb2DMMgGAxOcSMW
bjB90qqGHGeD34nDj3Gm0+kpouOFQgiFCUKQ27ybppl3gYbD4Smvz4a5DPuUCn0Vxzn9LOCZkple
i4R5z2fJzie+/OUvMzo6ynvf+14ALMvKCxfMFRzHwbbtkrqMxfJ7qqrmibLwJvfdsoWTz3EcPM/L
N6G2bTtfL+ZP7Js3BVu3hjGM+d0X7dp1jMOHr5R//cG1HD6+vq7P2LttiO6flL8ugbDJ1sck+oJR
bqVmT15Zt9zgzNB0l6MkbHYu0Lk+GGIgWRkBb+jSOXW7uoQZRXLZscKcRpzbFmc4NhIFz2Nba5oR
Q+N6qV6K9cDRiase8YAgIkNQhaAMqizlBMMnRcEdT8JxJUKSTkDRsRoaueRIDFXRE7UUZNeAhIon
VT4vAzj81jKDP1jv0Rmd+X3+/eL3YVQUJe/29Ms/7kattU+OlmXlhQ78sfj3ted5GIZBY2Mjsiwj
hMCyrLyFWqkQQnFGaj1jnpiYoKmpqaJj/SzgUslMmUwmH/8E8uvbfYL7M0t2PpFIJLh69eqU5+Yr
o9WHT5I+4ZWS3/N3ooUuD79wOt9AWpaxrJzIMtwpSi6ckEuWwPveZ/LpT8/vZR4bK++OzaG+z29M
ZDhxbOZzWHqQnr8HpCzbfilNpiPK+ZHSC7ssmVwaKTqf57Bjgc7AqMbhi1UsOp5H33j11lLO4oxM
sziHsjLrGlJ4QubYaJlxOBZR2SIegIgmEZYhoAhUSULJaYjjeh6uA66QsV0Zw5bIWBJpUyLjBkih
zCp31xrOsqLFped2A7uWBTnUF0WVXHZ2ZBiVXC6L2hbnhSGHvgoTi2Th8wck6AAAIABJREFU8s7F
Jh9e77CiQaWSKJJPmP5955OTf5/NVW/a2eCTiC9Pp+s50Qi/XMMPpfi1nIVtsHxruTh2WG7sP43a
SVmWCYfDhEKhkvJ7r0UL83VPmMVJP/MBP37h38SldrmlSNJ3t/rHFMYr/TqwwuLqTCaTv9n89/y3
/+byP/+nQzo9P5d62bJbXLyoM1PWh6rVV8+1dlWW7h9X2qJM49gLABbrHkoT2BDhxGCEwoV2eYvJ
Jb9Th+extTNDMqlx9FL1rsa2RJahKruaFKKQOB/s6kf1LAy3EQnYGcvgeRKWI90hPEsibclkpBh1
VOrMiJhisnGhzfGBED23c/PGr/V3hMKR21EQgg0tGZSoxytGZIp84WxoiQj6ZguvC8EvtmX52EaH
Ta0asy1V/kbU97T4may+t8a3hgrdpHfL2vHdmcXWY2FyUakEId9TVIkQwk9TbKCU/J6fPVzoqn0t
kOfrmjDnool0KfiuFt+S9M9ZrFHrE2Shu7VYgstfBHxrtHAR8FEYOzEMA9M088TZ0aHyO79j8uyz
83OpOzuvc+3abDdC7Uk/8ZjOyeO1jF3mzI9C8COPJesHaHswyMnxBLan0taicOmGx8a2FLapcfxy
7TG5hc0SQ5WI286AREBndYdFz9VcBviO5To3jBmyaudp3VEkm12LDM6OBenun7oJSJlF94UkcWo0
CqPQFdNpb3bo1QM4FfReDSiifN9LIXhTk87/udHhwU6VmeaOnxznk6S/EY1EItMW50JrqJRe7Hws
5qXG58dVCwncJ3f/+cKyMb+eMxaL5d23yWRyWuuue0Wdx/d0ua5LMplE13Vs266rnvNewv3/DepA
qaSfWgmzsPzDJ0D/BvETEGBq+QeQP64w89WX3Sp0I1USc1EUhWg0Oo04/+t/Vfi7v7MZHZ1rlQ2L
K1em188Ww7ZrvwE3rsly8Mf1jfvG6Sg3TkPLohFWPxok4OpsaJJ49WqiLs1WgHDlJYvToGCzY2mW
MwMRjt64E6fsuRxDlV32LE9zTZe4XaMAQsUQLjsXZbmZCdB9u/TmYdgsfw2upsNcTUNLwGJNZ5rT
hsLEDCIIcpmSkq0xnY9tsHl0sYJUJr5ZioR8S63SrFZ/M+m7EYFpCUK1wk/e88dYbnx+P91iyzcQ
CExJEJpJCKFQ8H2uk37qhb/pj0QiuK5LJpPJCz/cz/gZYdbhki1VI+lPej/W4E/kQkvTL//wSbAw
QcEnyXqy94qJU1VNfvu3Pf7kT+Y2Y3bDhhucOjV7QaQnaiO8aNjg1Mm52/mP3Ayz/JVervRtpmuv
gYyKR33uYkfUMD7PY/OiCYbTYXqul87AdTyFQ5d84sxw1YABc46J0/PY0DqBLoU4MkMGbkjWGdAD
s1q2I1aAg9cDhGSHvR1p+oA+Md1dbRaVlKwI6BxYneadq4JoWulsy0pIqBoU6sUWZ9bW0m2k0B3s
S8BVEi8ttnyz2ewUy3c2IQSf9P3M+noJb67rOf3fwt+Q3O943RNmtS7ZcuUfhSQJ0y1J27bzMYlC
kiyU3ZqtWLpaFBLnb/5mhs98xmRwcO4ygMPh0lJ4xRCitmm2eX2Ggz+aq5vM48EHf4wQKxi4HWbg
X2DR4gxte9IcdxrL9g2dDcPFPTBnwZqWNIom80r/7FmI4BNnFE1x2duV5rIuMTgHFufqhiRaUOHU
6OzjWNzgcdGuop+pp9LdH0PCZVtbBiPgcca+0w5tzMnN74UBiw+uNflPywXCVdD1LJZ1J5u0kCT9
+uK5TtopLpfwSzv8RX6mJJtCwYNqSLLcOAot3+LSmHJCCH7sMJ1O47ou4+PjBIPBmscx14Tpn6uc
Stv9htc1YfqTczb4E7WYJIsbS/vH+fDdrZqm5YP9fumKv1OMRqPz7qZQFIWOjgRPP23ywQ/ODWGG
QhlOnRqu6Fi7isX2zvkNzp6aqxvMZc+e73PhwhDp9Jvzz97sC3GzDx5YP47YoHDeqa6biyKb3Bir
7BZqj2ZZ2io4cm1qAlKlsF2F7ksxNMVlT1eay7rMUIk6ztmwMJKmIyE4NhSDTGXjaIwCpbvqzQiB
wrGhHLmvadBJJByOZFQMB/5obZrffgAi2uTc0NR8Sy2/05Asy/NCkuVQzk1aWA5SSl82FovN2fhm
6pTiP18Y5yz0VPnkWkmNZDnMZSz0tZgle88r/dxNFFqYfiwxm82SzWbzmanRaJRwOJzPeivsjee6
bn6n6U9wPzPO3yX7n+HvmO+mT/+pp2SWLZub3oIbN15Dr7C1omlXP822rs8wViEZzQRVNdm+/dsc
OnSJlSsfKVmTeu50mPP/oLH19jALlMqFLJY1O7iz7DlDssmDyzMkzSBHrkWp95az3ZyrduJ2gL0N
aVoDlfUBawxk2blggkE7zLHheFX6s3PhSTs/Eeb0rTAfXpHmyFsd/mCjTEST8x4bX6XHFzT3a/cs
y5oSzrgb8N2kPhGm0+l870g/+zMajRKPx+eNzP3NdjQaJRqN4nle/vP9TPtCBSE/58EfW0NDA4qi
5Mfub9Rnw1yT3GtNGu91bWHCnYvoZ7ZCrs1XMalVWiMpSVLJpITCG6tUhtzd2EEHgzIHDpj8zu/U
38XeMCpzx+aOre67aZrJhbOzHzcbotE0XV3/Sm/vEJ2dzfT2LpjhaInjB6NomsOufcOcjUdIiZkt
uMaYC+kyLwqH3V0Gl4cDHLwy90k7lqfSfSlGUHHY25XmQlZmxC6hHCQbbO40eXUkypGh2gQHjDoV
FjXJ5Tc2GfzhG10WNkSnxSR9q6rYUiul3FNtfLFWFFuSfpcSuJPQcrdQaPkWZvj6Y/JrOYG8SIKv
FlStFuzPmkfPjNe10o8Qgv379+d1Zz/84Q8jhJiWlVqoyuGjVI2kH9ssrKGaaaL4xGnbdt4inY8b
sXCBMgyLRx5p4sKF2tVj2tuHGRr6AUJUNta2JW9laLjydNIdmwY52lNH+inQ3DxGc/N3uHgxpxW8
e/ev0NOzsOL3xxMWax926FXjuGUSg/asSXPo+vSklg0dKUxX42IV37leBBWHrcuyXMgqjDpRZGx2
LtS5mAwxWoVkYCks69C5lql+vki4PLHW5CNvdFjZqpR0Z1aaOekTp+u683avlJLO88fne4b8cQgh
8uO4W2RQnCEMd9zWvjercJ0qLEsp7nlZLs5ZrM5TK1zXJZVK0diYSzT0N0X3Ee5fpZ/R0VGefPJJ
rl27lteT9S9EIf70T/+UL33pS8iyzKZNm/j85z8/TebOdV1efvllvva1r/HP//zPpNNpNmzYwK/8
yq8QiUTyWWqFTZlL1UgWC5/7bthqMvd8108wGMxbnIFAoOJuADOheBfvS+Y1Nib46EcdJtUAa8KK
FTcYHKx8scpmK/8uimJx42p9burFiwcQ4n9z8WJm8nE7R492VHWOVDLA4RcCLFiUoX1PihNu07TE
IN2ZOs4liQwtcTjeV12rq5rheYSVLIkQRDWPTBJWyDobG8YZlSP0DFaWWDTzZ5jcylbpkxWCX1yh
89GHbDZ2yti2QyqVzZNkLXH7wlrjufTOFJNkuVpnmJog5BOnaZp3bbNbnCEMTBnHbJ1SSmnBFgsh
3Cv1nPcq7gsL88CBA7S2tnLgwAGeffZZxsbGprXvunr1Ko888ghnzpwhGAzy5JNP8ta3vpX3vOc9
U44zDIP9+/fz6KOP8va3v50Pf/jD/M3f/A3Nzc14noeu6/ldmSRJU8TN/R1ysazdXBU++4XJjuPU
RJylatT8MU7N4BW88Y0Kr7xSyy7So6vrW1y9Wmks1EaK/ErFmbJ7to1w6Ce1B81WrbrO6Oj3GB01
88/t3PkER45UR5jFWLMuC+tlznuTJOR5NLfajGaDJAIm6xbaHL0exqm1R6fnEZIzNEYk4kEIaRJB
FRQpF/X0PAnbFhiWIGvJpA2ZiayM7fm7dpudqw0GdY3r4yEUyWXLMpOs4nA2Fas5C3hxLEMfFbqU
heChRQYfe8hk50IvH1fzk1XmMgO80DtTrXJP8X3iE0kt93FhtrtPnPXmJZTLwC2+jwvhOE4+3ltI
4IUhpELBd/81393tJzHqup7Xr60Hxdq2/ne4j3D/WpjPP/88L730EgDvec972Ldv3zTCTCQSaJpG
NptFURSy2SyLFi2adq5QKMTLL7+cfxyNRhkfH8+32VEUJT/5/Qtcq5BAtSgs9PXT22cjzmJJMJ8g
w+Fw2ZtLliU++lGLJ5+snjBXrerj4sXKE4dCIRmjQrKUJIsbV6seUh4bN17gypUfkMncCbp1dS3k
6NHW2k86ifNnInBGsGXPCEOLNfSwzHg2yN6uNKf7Qxy6WuDJ8DyCcpbGMMSDEpEAaEquBaQECCFh
O2DaEllTIq1LTJgShhPjdlpidimIO5Akm52rdG5lAhzpv1NL6QqF3qsREIIHOg1iDS6940GEVN2i
1ZYQ9CVnP25zc5YPvyHLvqU5V6EQc9sJpBillHsKBc6LP7NewYNyKBVf9MdRbXZqoWhJtRm4/ua4
VIbvTEII/m/oCyH460m9Ig4/szB/imhqamJsbAzIXYjm5ub840J85jOf4emnnyYcDvPoo4/yxS9+
cdZzP/7446RSKT7+8Y+zZcsWhBBcv36d1tbWfCzAJ8+70eGgEIWCBoXE6U/8amOmhRBC8HM/J9Pd
XV1savfuH9PTM1Dx8c3NKqP6YxUdu2vrCIcP1rYL3bnzVU6c+BHFVULbt7+T3t62ms5ZDqrqsufR
M8iLOzEjTbiejDVJfildYiIrYTravLplFdlm+yqdG6kAt1OVbXw6YibLF9qcSqukvMres7crQ/dw
eQtzZcLgD3ZO8B9Wu8iylJ+ndzMpBu4Qomma+RILPymm2J05F4o+M43Db4pQifRecfPqwrWm3nH4
/Tf95EU/q7a4PWBhnHNiYiIfrw0GgzVfS9/qjsVi+c/5mYU5h9i/fz+3b0/fW3/iE5+Y8rhcAeyl
S5f4q7/6K65evUpDQwO/+qu/ype//GXe9a53zfi5//Iv/8Lx48f53d/9XTKZDDdv3mTHjh186Utf
QlGUKTu+uy3r5O9e/ZhDMpnMT+ZaYqaFkCSJj33M5hd/MUSl4qSybHL+fHXCqZFomNFKyk+Exe2+
2vZne/b0cOjQUYq/x6pVS+ntbanpnOXhsXNnD0qqmZc/s5BNO7PYiy3OWHGQC+bHPHGlqljsWG1y
dTzA4VvVdQsZSAcZOB8krDrs6Upzy5a4MYt6kFdmbi0Mm7x/e5J3b4XIpDejsAnA3U6I8ZNK/M4f
fvnF3a7lrER6b777cvrjKFYDKjWO4jgnQCwWQwgxq+D7THitZsneM4T54osvln2to6OD27dv09nZ
SX9/P+3t7dOOOXLkCG94wxtoacktkG9/+9v5yU9+MiNhep7H+973Pr7+9a+zevVq3vSmN3Hr1i1C
oRD9/f0sX758mgLI3UxtL5WQ4Mc3ivtm1oJ9+1QeecTg+9+vzMrcvPkqx49XR2rBYGWxkJ1b0hw5
VG3cxGP37pc4dOgspRgqGn2IuSw1DoUybNjwI4TwsKzFCKHwyuE4HIYlS7N0bLE4LYXIirnPjg2o
JttXW1waDXKor74GzrqjcuhiDPDYsjSDo3mcSkVLxjmTRY2emzSL392e5j/vgobo1M2ab0WUSkSZ
z/ulVMyvsE+s3wLvp0HghUk2fg2nv+GdT+H3UuPw45y+EEKh4Lvruui6nnfd+u7gQsH3aoQQXqsu
2XuGMGfCY489xnPPPccHP/hBnnvuOR5//PFpx6xdu5Y//uM/zgetv/vd77J79+4ZzyvLMo8++ih/
9Ed/xJIlS/LPHzx4kKeffpolS5Zw4MABFi1aNMXSm8+FoNhFU+rGmstxfOxjFt//fmVWpizfqvr8
wXAFJOhZDA+6VDcdLXbv/jd6eq5QauyrVy/nxInmKs43MxYuHCAUeplz5zJoWgtr107Nvr5xPcKN
6xEiEZudeyYYbJS47tTXzBcgpJlsXWVzYSRA9436iHI6ZE5cz1mYK1oMWpsdescDOH4ZjedxM537
bSOKzX/ZqvOBN0BTdOYNQXFGqx+Ln8tM0nIxv+IM3EAgUJXk3VyiMG7q10oWNoO/myGechKA/rpS
qGNduEGXJGmK4Hs6nS7ZLLrUd38tWpj3RQxzdHSUJ554guvXr08pK7l16xZPPfUU3/zmNwH4sz/7
M5577jlkWWb79u189rOfrctv/v3vf58/+ZM/Yf369Tz99NN0dOQyLQtrwmabOLPBv/GLSbKSmKlP
nK7r1kWc73wnvPDCzEXt8fg4hvFd7CpVe7ZuX8bxMztmPGb7plF6eyony0DAYMOG/82xY+UI3GPd
undx5kz9yT4Amzad59q1HpJJh717F9LdbbB79z56embKvBWs25QmsNrjhBWBKpNtIgGTzasczg0F
GNPvXuynOWKxaqHBBV0BWZAJhXKiAw95LEjUtr8uzGitl7AKN5RAVbWc9WTWVopyZSCFa8TdGMdM
8Ncby7LyeRp+olKh9J7PDYXldP4mwHd5lxNCKK7n9Dsy3UcouZDeF4T504QQgm9/+9s888wz7Nmz
h/e///00N+csF78Q2A+QV0qchS6kwp1drYlFhQReC3GePOnw4INRhCg/oXfuPM6RI5erGhfAjt2r
OHpyc/kDPI+VS0a4dLEyjdt4PMWSJf/K6dPldWzXrXuAM2f2///tnWdYVOfWhu+hV8WOgjWxoCKC
DT2W2HtJrChYozlpxkSN0XMSWxJLLNEkfonHWGMv2GvsRhEQW1DRKBgsWBDpMDDzfj/IHodhgKHM
DOq+ryvXOc7AnjXD7P3sd71rPYuibySqadkylKCgcIRQUK2aPQ8e2JGZqaBx485cumTYCrZipVSq
+6Rz09qG+Hzcg5xs0/F8I5Nrj22ITzOyUKozsbNIxdlO4GArsLMW2FiBjbUFjtZKmtRKYnSnstQq
XzyJKGlFqFQqCyQU+kbeFaUITzuOwlS06qJtkak9rSSvNhDp96QCobwqfIsDSeiUSmW2vnHp89dX
qJSXEQKg2RvVZ4Sg3ScLsmC+dgghCAwMZMGCBXTo0IGPPvpI02OkLZzaQ111fz83p5Pi6k8rysp3
1CjYsiX3i3m9ege5ccMw31JtmraoS+iVBrk+36j+M65cMOxiVb58LM7OB4mMzMvvVU29eiO5caNg
Ruq6SPuVFy481BzXy8uNy5ez9sPq1u1ORETBUq7W1pk0apFKfEU1f6U7Z9szdLZNo+EbKv6MsSVR
afjF20KdTCk7NU524GAjsLFWYGeVdWgLi39WNEKBSg3pGVn/JadDitKCxHTL7C5GQuD7RjrDW2fS
v5nAyd44FzjdCk59gpWf605xxVGQilbd39U9n7X7TQsah/Zea3HP5pSEXHvepr5ja4uqrpOR9vQl
qX5Cep9SpkupVGr2OVNTUzU370ChPhczIwtmcaBSqdi0aRNLly6ld+/evPfeezg6vvDHlKrRpKoy
7RPfGCKpj4IIp3SSXL+eRtu2FcjMzHmRdHd/xL17ZyjMiq15qwYEX6yr/0m1mro14oiIyH8lVbXq
Q5TKQzx6lJbnz3l6NuDq1Q4FjlMbN7dH2Nqe5s6dF0axXl5luHwZpM+gSpU+PHhQWHtBQe16KZSu
r+aORQZ1a2TyMMkGC0sr7KzB1kpgZflC9MQ/gqfMVKBUQaoyq4UlIU1BWqZ1gYzU9VHOUcmQFhkM
b62iYTXTlTXoCpZk76a9h1acxiB5xWGoYBUlJWxIHNK5K5nQF2Y2p+5qVxLygrScSfuculaEhhoh
QNY1UJroJAvma05mZiZr1qxh+fLlDBo0iFGjRmnurKTp4kC29IypUxK5pYxza+L+9FNrVq/O2WbQ
smUI585FFyqGlm19OBdSQ+9znh5xXA3L/zN58807PHlynPj4/Eaxqaldewy3buX0dzUU7f1KCQsL
NVWrVuHuXcmwQY29fX9SU4vmhmJtnY73vx6jti9LZnk1f6bbkGlZfPNK80KBirfqKhnqm0bn+qk4
2FkbNSWYG5Joau+nmbOXU59g6a68jLHa1aUg3rn6CqAKu9rVRRJfafUofUd09zmlFae0z/n8+XNN
C6CdnZ1JxhgWM7JgGoP09HSWLVvGsmXLqF69OqGhoXzzzTf4+fkBaL7ABZ1LV5xI45OkyjXtu3ft
O8/oaBVeXvakp2vHqaRy5YM8fJip/+D50LJtC86F5HRcQq2mXq2n3Lied8Wlp+cN/vrrFKmp6jx/
DsDb24eLF/9VqDiz9itDCAq6hhDZz5UWLSpx/vwLsba1VZGe7kdR90h9fa+SrKrK1RtZvsiODhnU
88pAVFIRrrQh3aL4xbNKqXT8/5WJ/79UvOGa9XfW1/RvzFVdbjds2pW15jA310ban5NEXHvPz9Tm
JfoES3rOWKtdXfTt+0ozQvUZISQkJGTr53RxcTHb9a+QlGzjgpeRP//8k5kzZ3L48GEaN26Mq6sr
3t7e2aakS43DkmVfUQsMCoK2bZ5ardbcGWqnhrVP/qpVLXn33XR++ulFfPXr3+PatcKJZVYM+k9e
jzrPuH41b0Fo2vQyly6dI9Ogl1fz/HnjggcI2NomU7/+Sc6de4zueVK6tFWO9+/i4sSjR0W7aLq7
PyUs7ClV676heSw5xZoL/zgd2dll4uOVgoWrmmuZ1qQoCi+elhYqujVIJ6B1Jt29LLCyskD71Nft
1dPX5F5U8jIRLwm9nFKMuh6z0ogx6cbXmFsp+pDGdNna2qJUKjVtHVK8xjA90IfUSiJdz6SeUu10
r24/JxhXxM2BLJhFwM7Ojq5du7Js2TIqVMiyX0tMTGTJkiV06dKFDz/8kH79+mm+VNJAaqnc2lh3
gnlNUdFOO6Wnp+coUpo0Sc2aNZkkJWV9NRwdDZ97qQ9VLoKpUKvJfYWmxtf3PEFBl/L4mew0adKC
CxcKPncya7/yFBcvJut9vnbt8oSGZvfOLV26FI8MdwfUg5oyZf7i3j0F8Yn6U2ZpaVaEnc/6G9hY
Z9LYKwXrKmpuqC1JxLC901rlslaTw/6lwr2cFfmd7tKNlJWVVQ7BKoxw5lY9aojrjil6OaUY8xNy
W1tbzQpL26PVVCIgxSjN45QeUygUmupTcxgyaM8qlW5otIu0pDT7qyKWIKdkjUZcXBwLFy7kxIkT
TJgwge7du2sESyp0KK4TT59I5lcsoTvbT1s4Z84UzJ/viI1NCtbWB0nWryUG4dOiPWFXso+ZqlMr
lpvhVugXw0x8fU8TFKTfvUc/aqpWHUd0dMGKcLL2K8+TkKB/QnLNmnZERdnlmPvp5VWTy5fzNsXI
iyZNbnPhQjSQiaVLO1Qqw9tHrKxU1GuQiq1bJrcsbEgge2WzrWUmvRorGdE6k/YNLDWVsoVBt/jD
kJVeYSZtGEJx9nJqi6R2YYx25Wdev2uKVpD8+jnNPZtTilG7VQXg6dOnWFtbU61aNVJSUti3bx9b
t25l4sSJvPXWWy+TgYG8h2kOnjx5wrx58wgJCWHSpEl06NChWIRTn21eYSoK9VX3JiYqaNTIgVq1
bnLhwo0Cv2dtGvh0IPx69tmljeo85crlnAUzCoUSb+8jhIUVrMCoWbNWhITkbY6Qndz3K7V/xsOj
Mtev5yw0atasPiEhngWKUcLBIRlHx1CePBGUKi1IULcv1HEALCxUeDRMx7m6mvQKMKgN+LVSU6F0
8SeOdItQtJvVc3PdMUYqrrC9nMUt5MbY9y1MjHlVtBoD7ayBrpALIVi9ejX//e9/qVWrFhkZGQwe
PBg/Pz9q1ar1Mokl5CKYL1WdryFER0fTvn17GjRoQMOGDVm6dCkAW7dupUGDBlhaWhIWFmayeCpU
qMCCBQvYuHEjBw8epG/fvvzxxx+ak8zZ2RkLCwuSk5NJSUnR5P71oT26JykpSXPX7+zsjIODQ6HS
ZtpjhOzs7P5Jr6Tx0UfJKJUFt8LTJT09+1esdo04rlzOuaKytU3Fy+tAgcXSwgLu3cu9z1MXO7tk
fHwOc+7c9TzEEnx8KugVSwBLy8K2k0CjRrd48iTrPtSlTOGPA1n7w+FXHLj1hy2BnwnGd7cwilhC
VorU0dERR0dH1Go1iYmJpKSkkJqaSlJSEikpWQOiHR0dcXZ2NtqWg7SXpn3eJCcnk5nLRrfUI5iY
mKjZd3N0dMTJyalIq1QpNSkdRzovpRWfoUgClJqaqonRwsICJycng2KU0rK6fxvtfcSiohtjWloa
lpaWODs74+joiLW1NeHh4Xz11VesWbOGESNG0KZNG+Li4jh+/DjR0dEvm1jmyiu3woyJiSEmJobG
jRuTlJREkyZN2Llzp2bD/r333mPhwoX4+PiYJb67d+8ya9YsHj58yNSpU2nSJGtlpH3nrJ1y0h1a
La0ijVXFKK04nzxJ4osvrrN9ezxFqQatXqc7d7VSpd71nnLxYvbVZenS8VSufIgbN54V+PgtWrTl
/Hkvg362SpUYrK1Pcfdu3gYM1taCChUq8eCB/ouwr28rgoKq6n0uL2rVekRUVDhqddYFsL6nC9ei
CleopM3/LU5kuJ9p9om0V5LSBVkaPmyOvSp95gOS6bq2M5C06jJm5a/uSi+/Obba7kXFNdZL+9gF
XYUXJEYhBPfv32fr1q3s27ePWrVqERAQQMeOHTVFjUqlki1btmBtbc3gwYOL/L5MzOtRJevq6oqr
qyuQNabGw8ODBw8e0LFjRzNHlkX16tX59ddfuXXrFjNmzCA5OZlp06bRsGFDzaRz6U5OOtmkQglT
bO5LK87KlV1YsaIpAQEPmD49UuNwU1BS017EW7NaPBcvZl9dVqr0FDu7Q9y4kZd7j36srS2IjPQw
6GcbNLhOdHQICQn533U3bVqFc+dyf79KZWEuapnY2NzWiCWAvUPRp5q0ap7IoLczEMJ4YpDXOCrJ
tSc5Odksvqja6dD09HRSUrJuhqTCOmObHmjHoa9QSfvm1xRjvSB2hUmJAAAgAElEQVR7Ras01NpQ
JyPtfUl9McbHx7Nr1y62bduGra0tfn5+HD58WDP3UhsbGxv8/f2L7X2VBF45wdQmKiqKixcv0qJF
C3OHkoPatWuzfv16/vzzT6ZPn05ycjJ16tTh8OHDzJ49m/bt22tWe6aebAAvUk6dOlWnTRtXVq+O
Yt68v3n8uGBpnpSUFzGXccokkheCWaPGfVJTj3D3bt7uPbnh4/MW5/MdCZZVcXv+/I08U7AS5ctb
celS3jcHGRkFT6U2b36H4ODs1bYKy6KdfjY2KhbNyaqeLO7Rc/r2yPVdcBUKRba2B1MKp742EHv7
rL+N9hgrUxfDSHNspdFY0s2vKcd6gWGzOSGnhZ5ujOnp6Rw8eJDNmzfz5MkT3nnnHX777TcqVar0
yqRaDeWVFcykpCQGDBjAkiVL9N79lARu3brF5s2buXbtGnFxcSQlJeHr64uHhwcODlnVj9onXX5p
HmMgpd2GDXOjZ89yLFnyN7/++hil0pAYMklJzbpoVndL4GLYi6+bh8cd7t8/TkJCfu49+rG1teLm
zTfz/Bk7u2Tq1z9NUFAMhqaVa9SoSGho3gKeWsDpIS4uiURE5NwPtrIumjHBhPfT8GxgC9hmG/lW
2O+JPgEy9OKub1VjjL5jff6o+vo5pf5JU/dyascofZbSza40aEFywDEV+lpBUlNTNS5G2pXC0ueo
VqsJCgpi8+bNXLx4ka5du/LNN99Qt27d104ktXklBTMjI4P+/fvj7++vd3ZmSeHq1aukpaWxevVq
mjdvjkKh4OzZs0ycOJHq1aszefLkbLM4TTXEWt9MTnt7e5ycnPjuu/KMGhXLl19GcOhQAnkJka2d
JenqrK9YxbJK7v6VtRr08rpORMRp0tIKX5Tg7d2eoKDcBcfN7TE2NicJCzO8J6ZuXSdCQ1PJT1wT
Ewt22rz5ZgShoTkfFxQ+JftGzXQ+nyCQYrW0tMTR0bHAfYuGCpChaK9qpL7jghqb5xajtgBpX9xz
w1S9nFKM+ipctXtOpf3W4vhMCoNUx2FlZaXZnwQICQmhbt26uLu7c/PmTTZv3szRo0dp0qQJw4cP
5+eff37ZfGCNxitX9COEYMSIEZQrV47FixfneL59+/YsWLBAU2xTUjl69Chff/01np6efPbZZ1Ss
WBEovhmYuugTybz8MrPGnv3Nl1/+xY0b+leJZcta8yy1N+6VE3gQpUattqB58zBCQ8+jVhc+ZkdH
WywsRpKYqD8d26jRTaKisvvB5o+aunWrEBGhzOfnMrGxGYhSaZiPbJ06f3Pz5m30ibBPq8aEXXXJ
+Uv5IQSBGxPp0iF34ZZEIjMzM4dIGDKzsbgobPuFMfo5i7OXU0KKUalUavb/DblJMcZ0ktzQnn+p
W7yjUqmYPn06K1euxMXFhTp16vDBBx/Qo0cPzaSR15TXow/zzJkztG3blkaNGmm+gN9++y3p6el8
/PHHPH36lNKlS+Pt7c2BAwfMHG3eCCHYv38/c+fOxdfXN9ssTm3hLOwQ64KKpD6Uykx+/vkv5s27
y/Pn2b8ubu6O3I/tSrNGsYSct8TX9xxBQVcougdrN4KCaut5Rk3z5ucICYnIYTaQH02bliM0NP+v
u6MjJCcbVvGnUCipXv08UVH6jRE8fJpw/ZZzgeIEGNAvhTU/G/azkkhIFZNSarC4DAUMRbfRXp9I
mKqfs6hVpLoCVNgq3OKYTpLXsbWLd6TRXtK5nZyczJ49e9i6dSuZmZn07duXmJgYfv31V7y9vfnu
u+9o0MDwdq1XkNdDMItCdHQ0w4cP5/HjxygUCsaNG8f48eN59uwZgwcP5u7du9SoUYMtW7bg4lKI
lUEhEUKwY8cOFi5cSMeOHfnwww+zzeLUPuHyE87iEEl9PHmSyuzZ11m9+hEqVdZxar1ZhpSMZjy5
l06zZqcJCrpZ6ONLlC7tQGbmCJKTs6+upP3KsLCYAh/T3h6cnCrw5Il+YdPG3b0U9+51N+i4vr7X
CAp6nOvzbnWac/9h3gOldXEpnUnIiRSqVM4/Lay7SpMeM9SezhjoEwkrK6ts30ntSRvGHuuV31xO
CcmXOTcBKiraafHCpo31ZQ60519mZmZy4sQJNm3axN27d+nduzdDhw6latWqmveQlpbGb7/9RuvW
ralXr16R39dLjCyY+ZFbD+eqVasoX748n3/+OfPmzSMuLo65c+eaPD5pFucPP/ygmcUpFQflNspL
+j1jiKQ+rlx5xhdfhHPyZDL16leidKkaqDJPERpauPFguvj69iYoqEa2x9zcHmFjc4rIyMJ5+LVs
WTnPNhJt6tatTERE23x/rmLFOJKSLmWrEtbFsVIrklMKlvZaPCeRcaNyXw3lt0orrh69oqK98gWy
CZapi0pyGyQN5CiCMvZ8Tu3pJIaMOdOXuta2+VOr1Vy+fJlNmzYRFBTEW2+9hb+/f7YMnIxeZMEs
KP369eOjjz7io48+4uTJk1SqVImYmBjeeustbtwommVcUcjIyGDNmjX873//Y/DgwYwaNQpbW9sc
d+9SwYOpZvhJCCHYtSua//16j8cxd7l2LbZYjlu2rDMpKf6kpb1YBRRuv/IFlSvb8OyZE+kGtpl6
edXg8uX825R8fELyLDiytskgw6YTFOBv0bxJGkf3qPT6w+Y26im3VZr26srUbSCS96j2vmlRV1fF
FZ8knNJ1USowMuYeoz7yu7HJa+9UCMHdu3fZsmULBw8exMPDg4CAANq1a/dKGaEbGVkwC0JUVBTt
2rXjzz//pFq1asTFxQFZJ1XZsmU1/zYn6enp/O9//2PdunUMHz6cJk2asGvXLtq0aYOPjw9CCM0d
s6lPeICMjEyOHIlk48Yb7N8fXaSqWABf335aDjtqWrYMJigob4u7/PDxqUxYmOGmDM2bNyQ4OO+9
nUaN7nLlyh3y2qut6GrJ4+Q2Br+upaWKUweTaez54mZB14mlMDdF+szEi7sNRHf2pXaaUBvtQqXi
KsoxNEbtGw6p71kyFDfX+SPFpr36tbS01LSn6O6dPnv2jMDAQAIDA3F2dmbo0KH07t1bk4WSKRCv
h9NPcZCUlET//v1ZsmQJzs7ZizJM3UOVF7a2tnTo0IGYmBhmz56NUqmkU6dOvPPOO5q4pVStUqk0
+RBra2srevSoTffub/LkSQK7dt1i27bbnD37uMBVshUruhAWVhkAe/tkPDxOc+6c4f2V+vDwcCIs
LK1Ax8jPR9baOo3Y2L/zPWZpFwceFyCD/P6YVBp7WhW7W4y+NpCiCqehsy910W74l7xZjSmc+lbl
jo6O2VZh2iOsTNnLqY3UDqJSqTQp22PHjtG/f38yMjI4ePAgW7ZsIT4+ngEDBrBlyxbKly9v0hhf
F+TmGh2kHs6AgABND6eUigV4+PChpsXD3Kxfv54uXbqQlJTEjh07iIyMxNPTk08++YSdO3dq7kKd
nJw0lntJSUm5GlUXJ9KdcXJyMgkJCTg6WjFiRCMOHBjIxYuD+e9/G1O/fikMTWLUrNkRpdIKd/fH
uLruL1RxT3ZUpKc7UVDBFSLvPcemTW9x/37+xUMOjobvXVZ1S+fzCVkCkpiYmM10397evlj21LSH
AVhbW5OSkqL5rhhiJi6JpGTrKK1YJYPuggiNhYWFpu9XoVBozN2150EWFkmMExMTSU5ORgiheS19
frjaxuaSo1JaWlqxGZvrQ1qVp6SkkJCQQEZGBjY2NpQqVYpSpUoRGxvLjz/+SN26dfHx8eHatWss
WLCAY8eO8eGHH5ZIsRw9ejSVKlXC0/PFlJ9nz57RuXNn6tSpQ5cuXXj+/LkZIzQMOSWrRW49nJ9/
/jnlypVjypQpzJ07l+fPn5ul6EcXaX9D9+47Li6OBQsWcOrUKSZMmEC3bt001lySRZYxhljrS7/l
1t8n7aFdvHifwMC77NwZyf37qXqP6+ZWgZiYgTRocJvIyGASE4su+M2alSckpOAXvSZNOnDhQgW9
z7m7P+Hx4z8NckFq/i83gq/oa43RQQhW/BhD357GLzjJ/rL590/qKzDSrnAtzlgMrWbN670UR4Wr
MXo5pRjz6jsVQnD9+nU2bdrEyZMn8fX1pVGjRuzevZuQkBDGjx/P1KlTS0z2S5fTp0/j5OTE8OHD
uXr1KpB1XS0JxZS5IO9h5oe+Hs45c+bQvHlzBg0axN9//22WtpLC8uTJE+bOnUtoaCiTJ0+mffv2
OWZxFlU4c3OKMXTPR7rgpqSkEhT0iJ07o9i9OyqbKDZt2h9r67+LvF8p4eSkwMqqbI6+UUNo2LAb
f/5ZWs8zajw9g7l61TBfXN+2bxB0Mf+JJ906xbN+hcrklogS+ualSi0KugVGpigaMnR4s77vZW57
p4WhuKqNcyvWkoztY2Ji2LJlC3v37qVatWr4+/vTpUsXrK1f2DOGh4dz9OhRxo8fX+T3ZUyioqLo
3bu3RjDr1atXooopdZAF83Xl/v37fPPNN9y6dYspU6bQqlUrIPsFqKDDePXtURkysT43tO/clUo1
v/9+ny1bbhERkUzZsuUIC3tUqOPqw9e3MkFBhZu+UrNmLyIjHXM83qTJbS5cMLx1xrddXYL+2ZPN
DSfHTM79nkilipnF7uxUUKSCHOnCrn2jZY42EH2rXylOSSSlFgtjFuwUZvWrbx9au1grISFBMxHE
ysqKIUOG8Pbbb2t6r19WdAWzTJkyJbKY8h/koh9jM3r0aPbt20fFihU1X4rLly/z73//m+TkZGrU
qMH69etzFBIZGzc3N5YtW0ZUVBSzZs1i8eLFTJ06FR8fH81FWHtEk76m9txEsrga4KV9K2kYb48e
VenbtxbPnyvZvTsae/tMzp59WuQVZvXqdoSEFKzQR5uEhJzv1cEhmb//vleg42Sq8jdwnzYpjVo1
c5qrm0o49U0scXBw0NxopaammqWCVDv1K8Uh3fhLImkqYwaFQpHNdD43n9j8jO2VSiVHjhxh06ZN
PHz4kLfffpu1a9fi6upaYtOsxUlJKqbMC3mFWYzoy9M3a9aMRYsW0aZNG1atWkVkZCSzZs0ya5w3
b95kxowZpKamMnXqVBo2bAhkv1uWSta1L5qWlpYms1PTt1d0/34SO3ZEsX17JBcuxFFw0VPTqJEb
V64UbnUJmVhYDEKtzi52vr6XCAoqWMFCgyaNCb+Ze1rfq2E6Jw9kYG2d/XM2lpewhL4Le257p1IF
qTlWv7pmHJIpA5i/DURa/UpFd9JjutsVarWa0NBQNm/eTGhoKJ06dcLf35/69eu/FOJRUPSlZE+c
OIGrqysPHz6kffv2ckr2dUP3S+Hi4qKp/oqOjqZbt26Eh4ebM0QN0ixOKysrpk2bRu3atUlLSyM6
OhpXV1fUarXmbt5czeTawqkdR0TEU7ZvjyQw8C7XriVhiHg2auTClSsKg35WH6VKWZCQMDDbY7Vq
xRAVdS3bYGhDqOXZnDtR+vvjFAoVx/ak0Lxp7ulxXXP1ouxxFtWM3VTCmV8qUyqcMZeIQ/ZCKMnF
SKFQEBYWRosWLbCzs+P27dts3ryZI0eO0LhxY/z9/WnduvUrPxFE99pYUosp/0FOyZqDBg0asGvX
Lvr27cvWrVuJji4ei7jioGHDhmzfvp2goCDGjh2LWq3mr7/+om/fvnz//fdYWlpqqgsBs4imdqpW
exivq6s1EyY0YPLkxty48ZzAwLvs2BHJrVspuRxHTVycDVD4CtsyZUqTkKD9SCZWVn8VWCwB4vWk
diXeHZ6Wp1jCi55F3dFVhgqnJC7a+32FTbHnNkarOAqVCjKjU6FQaGLRnoVpijmyuiYSNjY2ODk5
YWlpSVpaGkuWLOHSpUuUKlUKDw8PRo4cyVdffYWtbdFmopqSJUuWsGLFCoQQjB07lk8++cTg3/Xz
8+PkyZM8ffqUqlWrMmvWLL744gsGDRrEr7/+qimmLOnIK8xiRvcuKiIigvHjxxMbG0ufPn1YunQp
T58+NXOUWcTHxzNx4kR27txJ3bp1adasGbdv36ZKlSpMnjyZKlWqADlXeaas2NTXqiJd7G1tbbPF
IoTgwoVHbN9+l8DASKKjX6RefX0rERRUuGHVEg0auBMe/i/Nv5s3v0FwcGH6QZVYlO6AWp3zftW1
kpLQk+mUcSlYxWVe47wk9DnaGKMNxJBY8qI4x48VNZa8yG/Fm5KSwr59+9i6dStpaWm89dZbXLp0
iRMnTvDee+8xefLkl6LaHrKyUX5+foSEhGBtbU23bt34+eefeeONN8wdmrGQV5jmoG7duhw6dAjI
2jvct2+fmSN6gbOzM97e3kyfPp2qVV+0OBw9epSxY8fSqFEjPv30UypWrJhjlWdM4cytn1PbKUat
VuuNpWlTV5o2deXbb5tz9uwDtm27y/Hj9wgPL3rvpq3tC5cfF5dEIiIKZ55Q2sWGeJX+U+/br9Io
41Lw01LbJSctLY2kpCSNQGh/nqDf0aY4KYxjj74Vb3EU7xS3e5Buu4ruild7Ishff/1F7969+fHH
H6levbrmu3vnzh2+//57gwwhSgo3btzQpJQB2rVrx44dO5g8ebKZIzMt8gqzmNFdYT558oQKFSqg
VqsZOXIkHTp0YOTIkeYN0gCEEOzbt4958+bRsmVLPvnkE8qUKQNkv2svrn2iwvZzGrKXl5mp4tSp
R+zcGcPu3Y948qRw4unr60VQUNbIoyZNQrhwoXDTUWrUsifqSU4D907tUti5SRTbuCipOAjIJhKm
LijJrdnfVMYHucViaCtVbmIufTeFEFy9epVNmzbxxx9/0KZNGwICAmjcuPErU7xz48YN+vbty7lz
57Czs6Njx440b96cJUuWmDs0YyEX/Rgb7Tx9pUqVmDlzJklJSfz0008A9O/fn2+//dbMURYMtVrN
jh07WLRoEZ06deKDDz7Q9IMVtWJTN/UmTYYoTD+noSKemani5MlH7Nz5kD17HhdIPJs3b0ZwcC3q
1v2biIjbFLZ4qIFXWcLvNMr2mJ1dJkG/p1D7zcInffSlCCWzblMbmucWn1SFLcWgPf/SlJM0DDEe
kERSn5gLIYiOjmbLli0cOHCA2rVrExAQQPv27U3q12xKVq5cybJly3B0dKRBgwbY2tpmc0R7xZAF
s6Sjr48zODiYjz76SHNHvGzZMpo1a2by2FQqFRs3buTHH3+kT58+jBs3LtssTqky0c7OLs9VobZI
ahebFNeqoiCr34wMbfF8xNOneXuVNm/empCQCtSsGcydO4VP8TZpUZkL1+pme+zLKYl88WnBBcPQ
NhBjWboZiq6YS20VUt+vucZO6boHSW0gSqVSr5jHxcWxc+dOtm/fjqOjI35+fvTt2xdHx5xmFq8y
06ZNo1q1avz73/82dyjGQhbMko6+Ps633nqLqVOn0rVrVw4cOMD8+fM5fvy42WLMyMhg9erVrFix
ItssTsh9iHVuFZnGTL0VdPWbkaHi+PEYAgMfsG/fY2Jjc/rM+vh0wtr6EefPPy5SbC3aVOf8pZqa
f9ernc7Z3zOwtTXssyiKHaEphTM/Mdd1yTGXcEoCKXnNKhQK4uLicHd3x9LSkvT0dA4dOsTmzZt5
9uwZ/fv3Z8iQIVSoUOGVSbkawuPHj6lYsSJ///03Xbt25fz58y+9+1AeyEU/JZ02bdoQFRWV7bHK
lSsTHx8PwPPnz3FzczNDZC+wtrZm7NixDB8+nOXLl9OtWzdGjBjBsGHDNMUkKpWK1NRUjcm7SqUq
UttCYbC0tNTEkpdDzovKUSW+vs60auXBd9814MyZZ+zeHcPevY+JjVX9c8wkrl59RFFGigGohfZp
p2bx3HRsbfM+FXNLX+c3MksX7TYdpVJJUlJSsQ6QLshoL12XnOTkZKPM5MwrTu2bDkmwMzIyCAgI
IDMzk8qVK/P06VO6d+/OvHnzqF279ksjknPmzOG3337DwsICT09PVq1aVaQ2lgEDBhAbG4u1tTXL
li17lcUyV+QVZglDt2jo7t27tG7dWpPCOnfuXLaKVnOTkpLCTz/9xPbt2xk7dizVq1dn+/btDBky
hLp1X6Qdi2sMVWHRXnFKkyqkC3texSZKZSbHjj1i166HREZacvp00VpTAJq3aUDwpayJJ0MHJvDL
Egu9NxH5TbAoDorDRLy44jTFMGvdOHWLd27cuMHmzZs5fvw4devWJTQ0FGtra6ZOncqgQYNemv3J
qKgoOnTowPXr17G1tWXw4MH06NGDESNGmDu0lwV5hfkyMmbMGJYuXcrbb7/N1q1bGT16NEeOHDF3
WBrs7e3p2LEjDx48YNKkSTg4ONC1a1cqVqxIqVKlsk27kFYU5jDstrCwwM7OTtPMDmi8UfO6CNrY
WNGtmxvdurmRkaHi1Knn7NkTy9698Tx8WLj7SclHtlxZJV9+nkZSklrTAiLdGEmGEQqFwqhtINLn
Inn4Sn7ChginJD7acTo5ORVazLWHWWdkZJCamprraLGCkFecQggePXrEtm3b2L17N25ubgwbNoyv
v/5a05Jz+PBh5syZQ9OmTalTp06hYjA1pUqV0sw1tbS0JCUlxezZqVcBeYVZwtBdYZYqVYqEf+xl
hBC4uLhoUrQlgXnz5vHLL78wePBgBg8eTNWqVVm4cCGnT5/m008/pWvXrtlmcUoTJuzs7Exyt67r
OSqtKKSVlSGFSvpQq9UEBcWze3cse/c+JzLS8Nma9XyacuOWE8sWJTJiqKWmd1Ja7QIaL19Tt4Fo
7yvqE05tMZe8Uo0VpyEzOXMjvziTkpLYvXs327ZtA2Dw4MG88847lC6tb3Tby8ny5cuZOHEi9vb2
dO3alXXr1pk7pJcJuejnZUBXMH18fFi8eDHt2rXj6NGjfPHFF4SEhJg5yhekpqZqZiRq8/jxY+bO
nUtYWJhmFie8uAhK+5vG2K/Sd7HUdmDRJrdCpYIghODixQT27Illz57nXL+eQV77nG51WlCzBuzf
lqlJC0sVo9KKXFppmasFRDs9amFhobGb0+doY4pYtGdy5vZ30ldkpD0oOiMjg+PHj7Np0ybu3btH
37598fPzw83N7aXZlzSU27dv07t3b06fPk3p0qUZOHAgAwYMYNiwYeYO7WVBFsySjm4f56xZs/D0
9OTDDz8kPT0de3t7li1bhre3t7lDNRhpFudff/3FlClTaNmyJZBzv6qoFZL52ZTlR3EIp8S1a/Hs
3h3H3r3PuXgxneznnhoXd192bUyg9hsvxFx75ZSb4bwp0RUfeJG+1R5ebOqYpBYm6e8kedjmZqOn
VqsJCwtj8+bNBAcH06FDB/z9/WnYsOErJ5LaSObuK1asAGDdunUEBQVpesJl8kUWTBnzERUVxcyZ
M3n8+DHTpk3TiH5hh1hDlrBIlY4qlSrPUVSGIBWFFJdwAkRGJrF79zN2737G+fNpWNuoeH+8DzP/
Y5VvnKYWzrw8XAGjFuQUBOnmSBJOqchI+nyEEERGRrJlyxYOHTpEw4YNCQgIoE2bNmbr9zQ1ly9f
ZtiwYYSEhGBnZ8fIkSNp3rw5H374oblDe1mQBfNVR5/xwZAhQ4iIiACy2lJcXFy4ePGi2WKMiIhg
5syZpKamMm3aNBo0aAAYLpz6fGYld6DiWjHormSk/daiuBhZWVnx9Gkmh488Z9hQdxwcDL9wG1M4
C1rhauxK1rzQjhPQxBgTE0O3bt0YNWoU9vb27N+/nzJlyjB06FB69eqFvb19PkcuGURERDBkyBDN
v+/cucPs2bMZP358oY43f/581qxZg4WFBT4+PqxYscJs2YGXEFkwX3X0GR9oM2nSJFxcXPjvf/9r
huiyc/XqVaZPn46NjQ3Tpk3jzTffBHIWnUj7o8U1vaIgFFQ4jd0GUpzCqU98CmJPp70XLaVqjbGn
mV+qPTU1lf3797N7926uX79OdHQ0EyZMYNKkSTg7OxdrLKZErVbj5uZGcHBwiWoje42QBfN1QLdo
SEIIQfXq1Tl+/HiJGskTGhrKjBkzKF++PFOmTKF69eoAGg9Paf+sKD6zRUW36ERbOPUZiGunB41B
YYXTGBWu+qqfiyqc+TkEqVQqzpw5w6ZNm4iIiKBnz54MGzaMmjVrEh4ezrfffsuZM2e4devWSzVv
UpvDhw8za9Yszpw5Y+5QXlfkPsySghCC5ORknJycTPaap0+fplKlSiVKLAGaNm3K3r17OX36NOPH
j8fJyQkHBwcOHTrEiRMnqFKlimavUqVSmWXfTBJBqVJUEk7JxUhqVzHmyCxttN16pJFVec3AlERS
qsS1t7cvttWgtulDUXon83MIEkIQHh7Opk2bOH36NK1ateKjjz6iSZMm2d5zw4YN2bBhA8+ePXtp
xRJg06ZNDB061NxhyOggC6YZGD9+PD/99BMzZ87k888/N8mJvXHjxhJ7Al64cIHt27cTHh6Og4MD
b775JkOHDsXZ2Vkzf097nqGph1hLSKtJKR61Wp2tctQcZgy6wimtGqVVr7TPW9Tm//zQFU7JqCKv
180thS3ZJwohuH//Plu3bmXfvn3UrFmTgIAA5s+fn++NU9myZY3yPk2BUqlkz549zJs3z9yhyOgg
C6aJSU5OZuPGjfz+++8cOXKEDh06sHbtWqOu/DIzMwkMDCQsLMxor1EU9uzZg4uLC8eOHaNevXqa
WZz+/v60atWK8ePHU6ZMGZMOsZbQrsTVXaEBmnSkUqk0u4uRZBQuOdrY2toW2Gu2qGgLZ25pbO0U
NuQcaB0fH8+uXbvYtm0btra2DBkyhEOHDr3Ue5IF4cCBAzRp0oQKFSqYOxQZHWTBNDGfffYZ7dq1
o0OHDrRt25Z+/fppnHzWrVtHQEAAQhTPEGGJ33//HQ8PD6pUqVJsxyxOZsyYke3fCoWCXr160aNH
D7Zv387AgQPp3LkzH3zwAc7Ozjg4OGjGeCUmJhbbEGsJfXtoua2U9KUjTeVilJs3qmQgnp6ejlqt
NssMTN00dmpqquZxaf9UOzWsVCo5ePAgmzZt4smTJ7zzzt4uAJAAABw1SURBVDv89ttvVKpU6ZXu
l9THxo0b8fPzM3cYMnqQi35MSHx8PK6urpw7d47GjRtz9OhR1qxZw2effUZUVBRDhgzR3JEXBsn4
IDY2looVKzJr1ixGjRrFqFGjaNmyJePGjSvGd2M6VCoVGzZs4KeffqJv376MHTtWM4uzqEOsJfLq
QSzIPpwp7P8MrXA19wxM3RsPS0tLhBAcOXKE1NRUBg4cqDEVuHjxIl26dMHf35+6deu+diIpkZyc
TPXq1YmMjHxtVtQlFLlK1tyMGjWK33//HXd3d3x8fPjrr79o0qQJ3377Ld7e3nz66acMHz4cQLNX
ZuqVgb5eToAffviBZcuWYWlpSc+ePc2yv6I9i3PIkCGMHDlSs/+rLZyG7ikaa06nMez/iuJkZOoZ
mNJnmpvzTmBgIAsXLuTvv/+mcePGfPXVV7Rt29ZsNoBF4fnz57z77ruEh4ejUChYuXIlvr6+5g5L
pujIgmlO7t+/j6enJ8+ePSMhIYGVK1dSv359unTpwrZt25gyZQq3b98mNTWV+/fvZ+tLNOXdtr5e
zuPHj/Ptt9+yf/9+rK2tefLkiVn3V9LT0/nll19Yv349I0eOZNiwYRpBkvompVSkrnDqpjHzGu1V
VIoqnPm1VxQUYwmnvtYa7c9UCMGTJ0/Yvn07u3btolKlSgwdOhQHBwfmzJnDvXv3WLJkCT179ixy
LKZmxIgRtGvXjtGjR5OZmUlycvIrZeD+GiMLpjl5//33efToETt27MjxXI0aNZg3bx6DBw8mKCiI
jz/+mDp16vD1119Ts2ZNIOuiBJhEPHV7OQcNGsS///1vOnToYPTXLggpKSn8+OOP7Nixg/fee48B
AwZo0pK63rAWFhaalCsUvFG/KBTEN1ffYOPidjIqLuHUFkntSTDSe0tOTmbPnj1s27aNjIwMBg8e
zIABA3Bxccl2nFOnTmFjY/PSrczi4+Px9vbmzp075g5FpviRBdPcKJVKzaw/yLpo//LLLyxbtozL
ly+jUqmIiIigTp06bNy4kZCQEJYuXaq5sJkKXcH09vamb9++HDx4EDs7OxYsWEDTpk1NFk9+JCQk
sHjxYg4dOsTHH39Mnz59UCgUREVFUa5cOU16W9tyzxx7ZLkJp77UsPZgY2NRGOHU7evUTQ1nZmZy
4sQJNm3aRFRUFH369GHo0KFUrVr1lduXvHTpEu+99x7169fn8uXLNGnShCVLlmj212VeamTBNBcq
lQpLS0tN35425cqVIzAwEDc3NxYvXkx4eDhqtZq+ffuycuVKrly5wrJly6hVqxbdu3cH0OwFGWvP
R1cwPT096dChA0uWLCEkJITBgweXyLvqZ8+eMXPmTPbv30/p0qW5c+cO+/fvx8PDQ2O5VxwDiYuK
FIsUD2DU1HB+5Cec+a161Wo1ly9fZtOmTQQFBdGuXTv8/f3x8vJ65URSm9DQUFq2bMnZs2dp1qwZ
EyZMoFSpUsyaNcvcockUHdnpx1xIKSrdC2FwcDC1a9embdu2LF26FCEEx48f5+HDh3h5eeHn56fp
sTtw4AA9evQAyLHiNPY+p7u7O++88w4AzZo1w8LCgtjYWMqVK2e01ywo+/bt46effuKPP/6gQ4cO
uLi4UKpUKZ49e6b5rHSb6k3V/qGN7l6fhYWFxsHIHLZ/oN8AQYonMzMz26pX23nn7t27bNmyhYMH
D1KvXj0CAgL4/vvvX5uJIO7u7ri7u9OsWTMABgwYwNy5c436mqauaZDJjiyYZqR58+acPXsWyErX
Xr9+nbS0NP766y/s7e356KOPADh48KBmdblz506OHz9OQECAJi0q+WsaY+o9QL9+/Th27Bjt2rXj
5s2bKJXKEiWWAElJSfj7+7NlyxaN5eD9+/f5+uuv+f777/niiy/w9fU1S9+kvgpX7R5EKVWbnJxc
4BFnxYkkikA2UU9JScHV1RXIWsUHBgYSGBiIs7Mzfn5+fP75569lGtLV1ZWqVaty8+ZN6tSpw++/
/66ZvlPcPH78mHXr1tG2bVuNQMuYHjkla0akVC1AYmIiX331Fc+fP2fbtm34+fmxfPlyzf5c+/bt
KV26NH5+fnz99de0bduW2NhYLl26RP/+/Yvtgq+vl9Pf35/Ro0dz6dIlbGxsWLhwIW+99VaxvJ4p
iIyMZObMmTx9+pSpU6dmm8WpXcVa1CHW2hSmwlV3UouphDM3U3aFQsG5c+cYNGgQXbp0IT4+nvT0
dAYMGMDgwYMpX7680WMrbmrUqEGpUqWwtLTE2tqa4ODgIh3v8uXLvPvuuyiVSt544w1WrVpVrFWy
2teIQYMG0bt3b4YMGSKP6TI+8h5mSUU7zfL8+XN+/fVX+vfvT40aNYAs79lr167h4+ND7dq1GTt2
LEuWLOHOnTs4ODgQGBjIvHnz6Nu3r+ZY0l6TzAsiIiKYMWMGaWlpuc7iLIpwFof5gXQc3RFnxmp5
0bb8k1yCpIzF2bNn2bx5M3fu3MHCwoKwsDBGjRrFlClTNCvOl42aNWty4cKFEus1K7Xo6GaLbt26
xXfffUeVKlUYN25ciXXteoWQBbMko2tUIN1Z/v333wwaNIjY2Fh27dpF/fr1WblyJb/++ivp6emc
PXuW0NBQtm/fzsKFCzWVuNrHLQnmBzNmzGDFihWa/s05c+bQrVs3k8YlceXKFWbMmIGtrS1Tp07N
1vNqyBBrbYw5A7O4hVOfoGsX7wghuH79Ops3b+bEiRP4+vri7++v2bd++PAh8+bNIyIiggMHDhTp
vZmLmjVrEhoaWuK2FPQRHx+PjY0NgwYNIikpSTOeb9u2bXJa1vjIgvkyIAncgwcPiI2N5f/+7/9Q
KBT06NGDnj17kpqaysKFC3F1dUUIwcqVK4mJiaFz584sX76c+fPnc+DAAaZMmWI2QdJnfjBz5kyc
nZ357LPPzBKTPkJCQpg5cyYVKlRgypQpVKtWDTBMqCSRlIzOjTkDUyoUUiqVBe6bzE/QhRDExMSw
detW9uzZQ7Vq1fD396dLly65pv3McRNWXNSqVYvSpUtjaWnJe++9x9ixY80Wi0qlAsh2U5aens7B
gwdZtWoVVlZWzJo1i48++ohjx44B0KtXL/r06UNAQAD29vZmifs1Qa6SfRmQLkSPHj1i1KhRtGjR
gvnz52v2Rezt7UlKSuLZs2d8/vnnjB07lq1btwJZhQHff/89vXr1YsWKFQQFBeUwNjfFxa5NmzZE
RUXleDyfmzOT06xZs2yzOGvVqsXkyZOpXLkydnZ2OcZmSRM4tBv1TTEDU6qUtrGxQalUauLJSzj1
+c06OTlpfj4hIYFdu3axfft2LC0tGTJkCAcOHKBUqVIGxfOy8scff1C5cmWePHlC586dqVevHm3a
tDFLLNL3Rq1Wa9Kvx48fZ8yYMSxatIjhw4ezbds2GjVqRExMDK6urvTq1YsLFy7Qs2dP3NzczBL3
64wsmCUUb29vLl26REpKCg4ODtmErm3btsycOZPKlSszcOBABg4cCMDixYtp2LAhy5cvB7KcViC7
SOqmfE3JDz/8wNq1a2natCkLFy7M4fhiLtq0acOhQ4f4/fffGTNmDN7e3kyYMIEKFSqQkJBAYmIi
FSpUQKlUYmFhoddyzxRoC6e2kEvCqa8a18HBQbMflpGRwaFDh9i0aRMPHz7k7bffZtWqVVSpUuW1
aVWoXLkyABUqVODtt98mODjYJIKpr4r91KlTrFq1ipCQEIYPH46fnx9t27alatWqmi0a6edv376N
q6sr3t7efPnll/Tv318WTDPw8t4qviZI5frad/U9evRg/vz5bNy4kYCAAO7fv09MTAybN2/mq6++
ArJ6NR0dHTW/m5KSwpo1azh06BCAycXy/fffJzIykkuXLlG5cmUmTpxo0tfPD4VCQefOnTl+/Dit
WrWia9eutGvXjkaNGnHo0CHs7e1xcnLCysqKtLQ0jV+tOZD6Jp2cnBBCkJiYqBF2aWqLs7Mz9vb2
KBQKQkJCmDhxIp06dSI0NJQZM2Zw+vRpJk6ciJub22sjlikpKSQmJgJZN5OHDx/G09PTJK8tFVNd
vnyZ6OhoIGvsXs+ePbl48SJhYWEsWLAABwcHBg0aREhICACdOnWiYsWKzJkzh/3797NhwwYaNGig
MZGQMS3yHuZLhq6n7L1793B3d2fatGlcuHCBQ4cOZau6lVaSH374IQkJCdy/fx9HR0cWLlxInTp1
jBanrluQoc+Zk4iICGbPns3evXtp0aIF9evXJzQ0lI4dO/L+++9rxi1pO+OYYoi1LrrFO9LNz717
91i7di0TJkwgISGBzZs3c+TIEby8vPD396dNmzYvXTpVpVLRtGlT3N3d2bNnT5GOFRkZydtvvw1k
eQ0PGzaMqVOnFkeYGnLL3Bw+fJiZM2eSkJDAN998Q8+ePVGpVOzbt48ffviBhIQE7ty5w7Nnzzh7
9ixz587lf//7H5UqVSI1NZXly5dz9OhRunXrRkBAgDz6y/jIe5ivArpC6O7uDkD37t0ZNmwYkHVB
l05aaZjw+fPn+eCDDxg9ejQbNmxAoVBw48YNrK2teeONNzTHN1aq9uHDh5p0WGBgoMnu7AuCpaUl
LVq0YOHChVSqVAnI+jzWr19Pnz59ePvttxk7diz29vbY29trUqOJiYlGF87cinekgiTp+cjISDw9
PalSpQpffPEFX331lWYE2svIkiVLqF+/vmZlWBRq1qzJpUuXiiGqnEjnjb5zJyUlhcDAQKZNm5Zt
IktsbCzr169n2rRpdOrUCTc3Nw4cOEDnzp1RKBTs2rWLcePGYW9vz8cff8wnn3xilNhlDOflut2U
0aB7YrZp00bTV6j9nFRZuXLlSoKCgjhz5gxDhw6ldu3azJ8/n82bN/P8+fNcj1sY/Pz8aNWqFRER
EVStWpWVK1cyZcoUGjVqhJeXFydPnmTx4sVFfp3i5s033+Tjjz/WiCVkfR7Dhw/nzJkzlC1blh49
erB8+XJNz6aDgwOOjo6o1WoSExNJT08v1uImac5nUlKSxpnI0dERJycnbG1tSUtLY+vWrQwePJip
U6fSo0cPTp8+Tbt27Zg8eTILFy4stlhMzb1799i/fz/vvvtuiSsYU6vVmipXeHHenDhxgvHjx5OS
kqJ5zsLCgj179uDj4wOgGRJ/4sQJnJ2d8fX15cGDB9ja2rJo0SKsrKz49NNP6dy5c7ZjyJgfOSX7
ihMREcHt27fp0aMH+/btY+HChRw4cIAjR46wa9cuRo4cyb/+9S8Ahg8fzvLly7GzswPMN8S6JJOW
lsYvv/zChg0bcszi1B5ibWtrq3HLKSj5DYvOzMzk9OnTbNq0iVu3btG7d2+GDRtG9erVs73enTt3
OH/+PH5+fsX2/k3JwIEDmTZtGgkJCSxYsKDIKdniIDcLyvv379O7d2+8vb1p3bo1I0eO1PxMamoq
77//Pl27ds32t7h27RqrV6/myJEjlCpVihEjRlC1atVsQiljNvSeuPKV8BXn6dOnTJkyhdGjRxMX
F0d4eDi2trYcPnwYLy8vzT7m1KlTCQ8Px87OjpCQEB49eoSFhYWm+tLUjB49mkqVKulN3S5cuBAL
CwuePXtm8rjs7Oz45JNPOHbsGAkJCXTt2pUtW7Zo0uCOjo44ODiQmZlJYmKixm4uP7T9ZPUV71ha
WnL16lWmTZtGx44dOXr0KBMmTODs2bP85z//oUaNGjku4rVq1XppxXLv3r1UrFgRb29vs68ub9++
Tfv27TX/VigU3Lx5k88//5wZM2Zw79493NzcyMjIwNXVlVGjRmX7W9jZ2dGxY0fmzp1LXFwc586d
Y8KECbi7uzN79mxmzZrFwYMHGT16tCyWJRx5hfmaILkAtW/fnnr16vHxxx/z3nvv0bp1a4QQlC1b
ljNnzlCnTh3NxaF58+ZMmjRJY8OlUqk0EzaMjT7zA4Do6GjGjh1LREREibA4k7x+Dx8+zMcff0zv
3r01F0vdIda6rSj5WekJIbh37x5btmxh//791K5dm4CAANq3b//K2x5OmzaNdevWaaqSExIS6N+/
P2vXrjXJ6+uuJB0cHAgODqZhw4acOXOGRYsW0atXL54/f87FixeZPXs2+/fvZ//+/ezdu1evNeXs
2bM5e/YsKSkpdO/enQkTJmiyOTIljtwNn/P4T+YlJyMjI8djycnJomPHjuLUqVNCCCFGjhwpunfv
LoQQYu3ataJOnTri8uXLYubMmWLAgAEiIiJCJCQkmDRuIYSIjIwUDRs2zPbYgAEDxOXLl0WNGjVE
bGysyWPKjdjYWPHFF1+INm3aiB07doikpCSRnJwskpKSRHx8vHj06JGIiYkRcXFxIj4+Xjx9+lQ8
fPhQPHr0SDx79kwkJiaK5ORkkZycLO7fvy9++ukn0aFDB9GrVy+xfv16kZSUZO63aDZOnDghevXq
ZZLXyszMzPZv6fwZM2aMGDdunBBCiJUrV4pZs2aJ0NBQ0a1bN+Hr6ytCQkJEZGSk8PT0FI8fPxZC
CKFWq7P9rxCiRH1nZfJErya+2repMlhZWWn+2FI1pb29PR06dGD69Ol4eXmxZs0abt26RXx8PIcP
H2bSpEk0atQIyDIb2L59O/v27aN169Z88803Zpt3uGvXLtzd3TWxlSTKli3LnDlzePToEXPmzGHp
0qV8/vnntGvXDisrK2JjYylfvjypqalAVlrP3t5eYz+Xnp7O4cOH2bx5M7GxsfTv35+NGzdSoUKF
16ZPMi+M9Rno7tNL3+29e/dy5coV+vXrR/369Rk3bhx9+/bll19+4d69e6xatYo///yT999/nz59
+miO5eHhwZo1a5g0aZImTa8du7kzIjJFJDclFfIK85UnLS1NLFmyRIwZM0YIIcSvv/4qBgwYINLT
04UQQowYMUJ88sknIiEhQYSFhYl+/fqZdKWpvcJMTk4WzZs3F/Hx8UIIIWrUqCGePn1qslgKSnR0
tBgxYoTw9PQUTZs2FWXKlBFXr14Vz58/F3FxcWL69OmiSZMmYvHixWLMmDGiWbNm4ssvvxQRERHZ
ViQvC6mpqaJ58+bCy8tLeHh4iC+++MLcIeWLvs/57t27wtfXVwwePFisWbNGNGzYUMTExAghhHB3
dxfBwcFi48aN4tNPPxUPHjwQQmSdR3v37hVKpVKsW7dOTJ061aTvQ8YoyCtMmSzEPyOEbG1tGT9+
PEIIkpKSOHToEO3bt8fGxoaTJ09y//59/vvf/+Lo6IhCocDW1pbo6Gjq169v8phv375NVFQUXl5e
QFbLQZMmTQgODqZixYomjycv9u3bx4oVKzh27BitW7fGxcWFypUrk5CQgJWVFRERESQnJ1OpUiW+
/vprqlWrxvfff0/btm3NHXqhsbOz4/jx45qCp9atW3PmzBlat25t7tCArMHXVlZWlCpVSmPsoVAo
uHPnDhs2bKB+/fr07NmTatWqsWXLFuzs7Ni9ezfXrl1j+fLlfPnllwwdOpQff/yRNWvWcPXqVUaM
GEHdunU5ffo0Hh4etG7dGn9/f3O/VRljkpuSCnmF+cqjUqmESqXS/Pv58+ea/9+tWzcxf/58oVKp
RHJysliwYIF49913TRqfvj1MiZK2h6nN999/L1auXJnt87x+/boYMGCAcHd3FwMHDhS7du0S6enp
IiMjQ6xatUrUqFFDzJs3z4xRFx/JycmiadOmIjw83KxxpKSkiLVr14rOnTuLZs2aiYCAALFx40bN
PuXatWtFp06dxOLFi8XYsWPFzJkzhRBCXLt2TbRq1Up8/fXX4pdffhGenp5CiKzVp62treb4+/bt
E4sWLRKRkZEmf28yRkevJsqCKSOEEBrhzMzMFKmpqeK7774Tt27dEkIIERYWJt555x1NkZApGDJk
iKhcubKwsbER7u7uYuXKldmer1mzZokVzLx48uSJ3sfT09NfyvejjUqlEl5eXsLJyUlMnjzZrLGo
1Wphb28v+vTpIw4ePChUKpX4+eefRdOmTcVPP/0khBBi0aJFYs+ePeLmzZuiZcuWonPnzuLu3bti
w4YNYtSoUUIIIeLi4oRCoRAHDx4UQgjRunVrERwcbLb3JWMy9Gqi3FYikyfp6enMmTOHmzdvsmHD
BnOHI/MSEB8fT9euXZk7dy5vvfWW2eLo2rUr/fr14/3339dM7Fm/fj0LFy7k8OHDjBs3jj///JOG
DRsyePBgBg0ahEKhYNWqVZw6dYr69evz8OFD/vjjDyZNmqSZCiTzWiAPkJYxDN2ZmXfv3iU9Pd2o
Zu3GYPTo0ezbt4+KFStqejm//PJLdu/ejUKhoFy5cqxevZqqVauaOdJXj9mzZ2Nvb8+kSZPMFsOe
PXuYOHEiN2/ezNYXWb58eYKDg1mwYAF16tRhwoQJAMTFxXH37l0aNGjA+vXr2bp1K2PGjKFfv36y
29XrhyyYMgVHaE0+ednQZ36QmJiomfTwww8/cPnyZVasWGHOMF8Jnj59ipWVFS4uLqSmptK1a1em
T59Ox44dzRpXuXLlOHv2LHXr1iUtLQ07Ozs6d+6Mv78/jRs3Zv78+bi4uODi4sKePXvo2LFjifQ5
ljE5sjWeTMF5WcUSsgzpy5Qpk+0x7bFISUlJlC9f3tRhvZI8fPiQDh060LhxY1q0aEHv3r3NLpYA
PXv25IcffgCyKnnj4+NRq9WUKVMGLy8vFi1aRPXq1bGysmLr1q2yWMrkibzClHml0Td78z//+Q/r
1q3DwcGBoKAgXFxczBih6YmOjmb48OE8fvwYhULBuHHjGD9+vLnDMgrBwcEMGjSIqKgoUlJSWLly
JWFhYfz888/Y2NiYOzyZkouckpV5/chrWPXcuXOJiIhg1apVZojMfMTExBATE0Pjxo1JSkqiSZMm
7Ny5Ew8PD3OHZhRcXFyoV68eKpWKatWq8Z///EczaktGJhfkAdIyMtoMHTqUHj16mDsMk+Pq6oqr
qysATk5OeHh48ODBg1dWMJcuXUpiYiKjR4/G3t7e3OHIvMTIginzWnHr1i1q164NZHnTent7mzki
8xIVFcXFixdp0aKFuUMxGsOHDzd3CDKvCLJgyryy+Pn5cfLkSZ4+fUrVqlWZOXMm+/fvJyIiAktL
S9544w3+7//+z9xhmo2kpCQGDBjAkiVLcHJyMnc4MjIlHnkPU0bmNSQjI4NevXpp5jLKyMhkQ24r
kZEpDKNHj6ZSpUp4enpqHps8eTIeHh54eXnxzjvvEB8fb8YIC4YQgjFjxlC/fn1ZLGVkCoAsmDIy
+TBq1CgOHjyY7bEuXboQHh7O5cuXqVOnDnPmzDHKa+sT66Lyxx9/8Ntvv3H8+HG8vb3x9vbO8f5k
ZGRyIqdkZWQMIK/2lMDAQLZv385vv/1W7K+rz61IRkbG6MgpWRkZY7By5UqjtafocyuSkZExD7Jg
ysgUgW+++QYbGxuGDh1q7lBkZGSMjNxWIiNTSFavXs3+/fs5evSouUORkZExAbJgysgUgoMHD/Ld
d99x8uRJ7OzszB2OjIyMCciv6EdG5rVHoVBsBNoB5YFHwHRgKmADPPvnx84JIT4w0uvXAPYIIYqv
VFZGRqbAyIIpI1OC0RLrcsBj4CshxOvlFi8jU0KQBVNGRkZGRsYA5CpZGRkZGRkZA5AFU0ZGRkZG
xgBkwZSRkZGRkTEAWTBlZGRkZGQM4P8BF5MLE8eyu2kAAAAASUVORK5CYII=
"&gt;
&lt;/img&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Looks pretty good to me. This isn't a major point, but notice that I plotted the State-Value on the z-axis, not an action value. I calculated the state value by simply taking the largest action value for a state from our state-action lookup table. Thus, the value of a state is equivalent to the average rewards following the best action.&lt;/p&gt;
&lt;p&gt;Below I've used our action-value lookup table to build a crappy looking table that displays the optimal actions one should take in a game of blackjack given you're in a particular state. The left column are the possible player totals (given no useable ace) and the top row is the possible dealer cards. So you can lookup what's the best action to take if I have a total of 16 and the dealer is showing a 7 (the answer is "hit"). You can compare to wikipedia's article on blackjack that has a similar table: &lt;a href="https://en.wikipedia.org/wiki/Blackjack#Basic_strategy"&gt;https://en.wikipedia.org/wiki/Blackjack#Basic_strategy&lt;/a&gt;  As you can tell, ours is pretty accurate.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;table&gt;&lt;tr&gt;&lt;th&gt;&lt;td&gt;Dealer&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Player&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;2&lt;/td&gt;&lt;td&gt;3&lt;/td&gt;&lt;td&gt;4&lt;/td&gt;&lt;td&gt;5&lt;/td&gt;&lt;td&gt;6&lt;/td&gt;&lt;td&gt;7&lt;/td&gt;&lt;td&gt;8&lt;/td&gt;&lt;td&gt;9&lt;/td&gt;&lt;td&gt;10&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;12&lt;/td&gt;&lt;td style="background-color:red;"&gt;H&lt;/td&gt;&lt;td style="background-color:red;"&gt;H&lt;/td&gt;&lt;td&gt;S&lt;/td&gt;&lt;td&gt;S&lt;/td&gt;&lt;td&gt;S&lt;/td&gt;&lt;td&gt;S&lt;/td&gt;&lt;td style="background-color:red;"&gt;H&lt;/td&gt;&lt;td style="background-color:red;"&gt;H&lt;/td&gt;&lt;td style="background-color:red;"&gt;H&lt;/td&gt;&lt;td style="background-color:red;"&gt;H&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;13&lt;/td&gt;&lt;td style="background-color:red;"&gt;H&lt;/td&gt;&lt;td&gt;S&lt;/td&gt;&lt;td&gt;S&lt;/td&gt;&lt;td&gt;S&lt;/td&gt;&lt;td&gt;S&lt;/td&gt;&lt;td&gt;S&lt;/td&gt;&lt;td style="background-color:red;"&gt;H&lt;/td&gt;&lt;td style="background-color:red;"&gt;H&lt;/td&gt;&lt;td style="background-color:red;"&gt;H&lt;/td&gt;&lt;td style="background-color:red;"&gt;H&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;14&lt;/td&gt;&lt;td style="background-color:red;"&gt;H&lt;/td&gt;&lt;td&gt;S&lt;/td&gt;&lt;td&gt;S&lt;/td&gt;&lt;td&gt;S&lt;/td&gt;&lt;td&gt;S&lt;/td&gt;&lt;td&gt;S&lt;/td&gt;&lt;td style="background-color:red;"&gt;H&lt;/td&gt;&lt;td style="background-color:red;"&gt;H&lt;/td&gt;&lt;td style="background-color:red;"&gt;H&lt;/td&gt;&lt;td style="background-color:red;"&gt;H&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;15&lt;/td&gt;&lt;td style="background-color:red;"&gt;H&lt;/td&gt;&lt;td&gt;S&lt;/td&gt;&lt;td&gt;S&lt;/td&gt;&lt;td&gt;S&lt;/td&gt;&lt;td&gt;S&lt;/td&gt;&lt;td&gt;S&lt;/td&gt;&lt;td style="background-color:red;"&gt;H&lt;/td&gt;&lt;td style="background-color:red;"&gt;H&lt;/td&gt;&lt;td style="background-color:red;"&gt;H&lt;/td&gt;&lt;td style="background-color:red;"&gt;H&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;16&lt;/td&gt;&lt;td style="background-color:red;"&gt;H&lt;/td&gt;&lt;td&gt;S&lt;/td&gt;&lt;td&gt;S&lt;/td&gt;&lt;td&gt;S&lt;/td&gt;&lt;td&gt;S&lt;/td&gt;&lt;td&gt;S&lt;/td&gt;&lt;td style="background-color:red;"&gt;H&lt;/td&gt;&lt;td style="background-color:red;"&gt;H&lt;/td&gt;&lt;td style="background-color:red;"&gt;H&lt;/td&gt;&lt;td style="background-color:red;"&gt;H&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;17&lt;/td&gt;&lt;td&gt;S&lt;/td&gt;&lt;td&gt;S&lt;/td&gt;&lt;td&gt;S&lt;/td&gt;&lt;td&gt;S&lt;/td&gt;&lt;td&gt;S&lt;/td&gt;&lt;td&gt;S&lt;/td&gt;&lt;td&gt;S&lt;/td&gt;&lt;td&gt;S&lt;/td&gt;&lt;td&gt;S&lt;/td&gt;&lt;td&gt;S&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;18&lt;/td&gt;&lt;td&gt;S&lt;/td&gt;&lt;td&gt;S&lt;/td&gt;&lt;td&gt;S&lt;/td&gt;&lt;td&gt;S&lt;/td&gt;&lt;td&gt;S&lt;/td&gt;&lt;td&gt;S&lt;/td&gt;&lt;td&gt;S&lt;/td&gt;&lt;td&gt;S&lt;/td&gt;&lt;td&gt;S&lt;/td&gt;&lt;td&gt;S&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;19&lt;/td&gt;&lt;td&gt;S&lt;/td&gt;&lt;td&gt;S&lt;/td&gt;&lt;td&gt;S&lt;/td&gt;&lt;td&gt;S&lt;/td&gt;&lt;td&gt;S&lt;/td&gt;&lt;td&gt;S&lt;/td&gt;&lt;td&gt;S&lt;/td&gt;&lt;td&gt;S&lt;/td&gt;&lt;td&gt;S&lt;/td&gt;&lt;td&gt;S&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;20&lt;/td&gt;&lt;td&gt;S&lt;/td&gt;&lt;td&gt;S&lt;/td&gt;&lt;td&gt;S&lt;/td&gt;&lt;td&gt;S&lt;/td&gt;&lt;td&gt;S&lt;/td&gt;&lt;td&gt;S&lt;/td&gt;&lt;td&gt;S&lt;/td&gt;&lt;td&gt;S&lt;/td&gt;&lt;td&gt;S&lt;/td&gt;&lt;td&gt;S&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Conclusion-&amp;amp;-What's-Next"&gt;Conclusion &amp; What's Next&lt;a class="anchor-link" href="#Conclusion-&amp;amp;-What's-Next"&gt;¶&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Here we've covered Monte Carlo reinforcement learning methods that depending on stochastically sampling the environment and iteratively improving a policy $\pi$ after each episode. One disadvantage of Monte Carlo methods is that we must wait until the end of an episode to update our policy. For some types of problems (like blackjack), this is okay, but in a lot of cases, it makes more sense to able to learn at each time step (immediately after each action is taken).&lt;/p&gt;
&lt;p&gt;The whole point of the Monte Carlo simulations were to build an action-value table. The action-value table basically &lt;em&gt;is&lt;/em&gt; our $Q(s,a)$ function. You give it a state and an action and it just goes and looks up the value in the table. The most important thing to learn from all of this is that in essentially any RL method, our goal is to find an optimal $Q$ function. Most of the differences between RL algorithms revolve around differences in determining Q-values. The policy function is straightforward, just pick the best action using $Q(s,a)$. We might throw in a softmax or something to add in some randomness, but there's not a lot more to $\pi(s)$.&lt;/p&gt;
&lt;p&gt;In the next part, I will abandon tabular learning methods and cover Q-learning (a type of temporal difference (TD) algorithm) using a neural network as our $Q$ function (what we've all been waiting for).&lt;/p&gt;
&lt;p&gt;This was a pretty meaty post so please email me (outlacedev@gmail.com) if you spot any errors or have any questions or comments.&lt;/p&gt;
&lt;h3 id="Download-this-IPython-Notebook"&gt;Download this IPython Notebook&lt;a class="anchor-link" href="#Download-this-IPython-Notebook"&gt;¶&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;&lt;a href="https://github.com/outlace/outlace.github.io/blob/master/ipython-notebooks/rlpart2.ipynb"&gt;https://github.com/outlace/outlace.github.io/blob/master/ipython-notebooks/rlpart2.ipynb&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="References:"&gt;References:&lt;a class="anchor-link" href="#References:"&gt;¶&lt;/a&gt;&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Blackjack"&gt;https://en.wikipedia.org/wiki/Blackjack&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Monte_Carlo_method"&gt;https://en.wikipedia.org/wiki/Monte_Carlo_method&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;"Reinforcement Learning: An Introduction" Sutton &amp; Barto&lt;/li&gt;
&lt;li&gt;&lt;a href="https://inst.eecs.berkeley.edu/~cs188/sp08/projects/blackjack/blackjack.py"&gt;https://inst.eecs.berkeley.edu/~cs188/sp08/projects/blackjack/blackjack.py&lt;/a&gt; (Adapted some code from here)&lt;/li&gt;
&lt;li&gt;&lt;a href="http://waxworksmath.com/Authors/N_Z/Sutton/WWW/Chapter_5/op_bj_results.html"&gt;http://waxworksmath.com/Authors/N_Z/Sutton/WWW/Chapter_5/op_bj_results.html&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: 'center'," +
        "    displayIndent: '0em'," +
        "    showMathMenu: true," +
        "    tex2jax: { " +
        "        inlineMath: [ ['$','$'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        " linebreaks: { automatic: true, width: '95% container' }, " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }" +
        "    } " +
        "}); ";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;
</content><category term="Monte-Carlo"></category><category term="RL"></category></entry><entry><title>Reinforcement Learning - Part 1</title><link href="/rlpart1.html" rel="alternate"></link><published>2015-10-19T00:00:00-07:00</published><updated>2015-10-19T00:00:00-07:00</updated><author><name>outlace</name></author><id>tag:None,2015-10-19:/rlpart1.html</id><summary type="html">&lt;p&gt;The first part in a series introducing the theory, math and implementation details of reinforcement learning algorithms using Python. Here we introduce the topic with a very simple RL problem, the n-armed bandit problem.&lt;/p&gt;</summary><content type="html">&lt;style type="text/css"&gt;/*!
*
* IPython notebook
*
*/
/* CSS font colors for translated ANSI colors. */
.ansibold {
  font-weight: bold;
}
/* use dark versions for foreground, to improve visibility */
.ansiblack {
  color: black;
}
.ansired {
  color: darkred;
}
.ansigreen {
  color: darkgreen;
}
.ansiyellow {
  color: #c4a000;
}
.ansiblue {
  color: darkblue;
}
.ansipurple {
  color: darkviolet;
}
.ansicyan {
  color: steelblue;
}
.ansigray {
  color: gray;
}
/* and light for background, for the same reason */
.ansibgblack {
  background-color: black;
}
.ansibgred {
  background-color: red;
}
.ansibggreen {
  background-color: green;
}
.ansibgyellow {
  background-color: yellow;
}
.ansibgblue {
  background-color: blue;
}
.ansibgpurple {
  background-color: magenta;
}
.ansibgcyan {
  background-color: cyan;
}
.ansibggray {
  background-color: gray;
}
div.cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  border-radius: 2px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  border-width: 1px;
  border-style: solid;
  border-color: transparent;
  width: 100%;
  padding: 5px;
  /* This acts as a spacer between cells, that is outside the border */
  margin: 0px;
  outline: none;
  border-left-width: 1px;
  padding-left: 5px;
  background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%);
}
div.cell.jupyter-soft-selected {
  border-left-color: #90CAF9;
  border-left-color: #E3F2FD;
  border-left-width: 1px;
  padding-left: 5px;
  border-right-color: #E3F2FD;
  border-right-width: 1px;
  background: #E3F2FD;
}
@media print {
  div.cell.jupyter-soft-selected {
    border-color: transparent;
  }
}
div.cell.selected {
  border-color: #ababab;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%);
}
@media print {
  div.cell.selected {
    border-color: transparent;
  }
}
div.cell.selected.jupyter-soft-selected {
  border-left-width: 0;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%);
}
.edit_mode div.cell.selected {
  border-color: #66BB6A;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%);
}
@media print {
  .edit_mode div.cell.selected {
    border-color: transparent;
  }
}
.prompt {
  /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */
  min-width: 14ex;
  /* This padding is tuned to match the padding on the CodeMirror editor. */
  padding: 0.4em;
  margin: 0px;
  font-family: monospace;
  text-align: right;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
  /* Don't highlight prompt number selection */
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
  /* Use default cursor */
  cursor: default;
}
@media (max-width: 540px) {
  .prompt {
    text-align: left;
  }
}
div.inner_cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
@-moz-document url-prefix() {
  div.inner_cell {
    overflow-x: hidden;
  }
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_area {
  border: 1px solid #cfcfcf;
  border-radius: 2px;
  background: #f7f7f7;
  line-height: 1.21429em;
}
/* This is needed so that empty prompt areas can collapse to zero height when there
   is no content in the output_subarea and the prompt. The main purpose of this is
   to make sure that empty JavaScript output_subareas have no height. */
div.prompt:empty {
  padding-top: 0;
  padding-bottom: 0;
}
div.unrecognized_cell {
  padding: 5px 5px 5px 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.unrecognized_cell .inner_cell {
  border-radius: 2px;
  padding: 5px;
  font-weight: bold;
  color: red;
  border: 1px solid #cfcfcf;
  background: #eaeaea;
}
div.unrecognized_cell .inner_cell a {
  color: inherit;
  text-decoration: none;
}
div.unrecognized_cell .inner_cell a:hover {
  color: inherit;
  text-decoration: none;
}
@media (max-width: 540px) {
  div.unrecognized_cell &gt; div.prompt {
    display: none;
  }
}
div.code_cell {
  /* avoid page breaking on code cells when printing */
}
@media print {
  div.code_cell {
    page-break-inside: avoid;
  }
}
/* any special styling for code cells that are currently running goes here */
div.input {
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.input {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_prompt {
  color: #303F9F;
  border-top: 1px solid transparent;
}
div.input_area &gt; div.highlight {
  margin: 0.4em;
  border: none;
  padding: 0px;
  background-color: transparent;
}
div.input_area &gt; div.highlight &gt; pre {
  margin: 0px;
  border: none;
  padding: 0px;
  background-color: transparent;
}
/* The following gets added to the &lt;head&gt; if it is detected that the user has a
 * monospace font with inconsistent normal/bold/italic height.  See
 * notebookmain.js.  Such fonts will have keywords vertically offset with
 * respect to the rest of the text.  The user should select a better font.
 * See: https://github.com/ipython/ipython/issues/1503
 *
 * .CodeMirror span {
 *      vertical-align: bottom;
 * }
 */
.CodeMirror {
  line-height: 1.21429em;
  /* Changed from 1em to our global default */
  font-size: 14px;
  height: auto;
  /* Changed to auto to autogrow */
  background: none;
  /* Changed from white to allow our bg to show through */
}
.CodeMirror-scroll {
  /*  The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/
  /*  We have found that if it is visible, vertical scrollbars appear with font size changes.*/
  overflow-y: hidden;
  overflow-x: auto;
}
.CodeMirror-lines {
  /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */
  /* we have set a different line-height and want this to scale with that. */
  padding: 0.4em;
}
.CodeMirror-linenumber {
  padding: 0 8px 0 4px;
}
.CodeMirror-gutters {
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.CodeMirror pre {
  /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */
  /* .CodeMirror-lines */
  padding: 0;
  border: 0;
  border-radius: 0;
}
/*

Original style from softwaremaniacs.org (c) Ivan Sagalaev &lt;Maniac@SoftwareManiacs.Org&gt;
Adapted from GitHub theme

*/
.highlight-base {
  color: #000;
}
.highlight-variable {
  color: #000;
}
.highlight-variable-2 {
  color: #1a1a1a;
}
.highlight-variable-3 {
  color: #333333;
}
.highlight-string {
  color: #BA2121;
}
.highlight-comment {
  color: #408080;
  font-style: italic;
}
.highlight-number {
  color: #080;
}
.highlight-atom {
  color: #88F;
}
.highlight-keyword {
  color: #008000;
  font-weight: bold;
}
.highlight-builtin {
  color: #008000;
}
.highlight-error {
  color: #f00;
}
.highlight-operator {
  color: #AA22FF;
  font-weight: bold;
}
.highlight-meta {
  color: #AA22FF;
}
/* previously not defined, copying from default codemirror */
.highlight-def {
  color: #00f;
}
.highlight-string-2 {
  color: #f50;
}
.highlight-qualifier {
  color: #555;
}
.highlight-bracket {
  color: #997;
}
.highlight-tag {
  color: #170;
}
.highlight-attribute {
  color: #00c;
}
.highlight-header {
  color: blue;
}
.highlight-quote {
  color: #090;
}
.highlight-link {
  color: #00c;
}
/* apply the same style to codemirror */
.cm-s-ipython span.cm-keyword {
  color: #008000;
  font-weight: bold;
}
.cm-s-ipython span.cm-atom {
  color: #88F;
}
.cm-s-ipython span.cm-number {
  color: #080;
}
.cm-s-ipython span.cm-def {
  color: #00f;
}
.cm-s-ipython span.cm-variable {
  color: #000;
}
.cm-s-ipython span.cm-operator {
  color: #AA22FF;
  font-weight: bold;
}
.cm-s-ipython span.cm-variable-2 {
  color: #1a1a1a;
}
.cm-s-ipython span.cm-variable-3 {
  color: #333333;
}
.cm-s-ipython span.cm-comment {
  color: #408080;
  font-style: italic;
}
.cm-s-ipython span.cm-string {
  color: #BA2121;
}
.cm-s-ipython span.cm-string-2 {
  color: #f50;
}
.cm-s-ipython span.cm-meta {
  color: #AA22FF;
}
.cm-s-ipython span.cm-qualifier {
  color: #555;
}
.cm-s-ipython span.cm-builtin {
  color: #008000;
}
.cm-s-ipython span.cm-bracket {
  color: #997;
}
.cm-s-ipython span.cm-tag {
  color: #170;
}
.cm-s-ipython span.cm-attribute {
  color: #00c;
}
.cm-s-ipython span.cm-header {
  color: blue;
}
.cm-s-ipython span.cm-quote {
  color: #090;
}
.cm-s-ipython span.cm-link {
  color: #00c;
}
.cm-s-ipython span.cm-error {
  color: #f00;
}
.cm-s-ipython span.cm-tab {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);
  background-position: right;
  background-repeat: no-repeat;
}
div.output_wrapper {
  /* this position must be relative to enable descendents to be absolute within it */
  position: relative;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  z-index: 1;
}
/* class for the output area when it should be height-limited */
div.output_scroll {
  /* ideally, this would be max-height, but FF barfs all over that */
  height: 24em;
  /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */
  width: 100%;
  overflow: auto;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  display: block;
}
/* output div while it is collapsed */
div.output_collapsed {
  margin: 0px;
  padding: 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
div.out_prompt_overlay {
  height: 100%;
  padding: 0px 0.4em;
  position: absolute;
  border-radius: 2px;
}
div.out_prompt_overlay:hover {
  /* use inner shadow to get border that is computed the same on WebKit/FF */
  -webkit-box-shadow: inset 0 0 1px #000;
  box-shadow: inset 0 0 1px #000;
  background: rgba(240, 240, 240, 0.5);
}
div.output_prompt {
  color: #D84315;
}
/* This class is the outer container of all output sections. */
div.output_area {
  padding: 0px;
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.output_area .MathJax_Display {
  text-align: left !important;
}
div.output_area 
div.output_area 
div.output_area img,
div.output_area svg {
  max-width: 100%;
  height: auto;
}
div.output_area img.unconfined,
div.output_area svg.unconfined {
  max-width: none;
}
/* This is needed to protect the pre formating from global settings such
   as that of bootstrap */
.output {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.output_area {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
div.output_area pre {
  margin: 0;
  padding: 0;
  border: 0;
  vertical-align: baseline;
  color: black;
  background-color: transparent;
  border-radius: 0;
}
/* This class is for the output subarea inside the output_area and after
   the prompt div. */
div.output_subarea {
  overflow-x: auto;
  padding: 0.4em;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
  max-width: calc(100% - 14ex);
}
div.output_scroll div.output_subarea {
  overflow-x: visible;
}
/* The rest of the output_* classes are for special styling of the different
   output types */
/* all text output has this class: */
div.output_text {
  text-align: left;
  color: #000;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
}
/* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */
div.output_stderr {
  background: #fdd;
  /* very light red background for stderr */
}
div.output_latex {
  text-align: left;
}
/* Empty output_javascript divs should have no height */
div.output_javascript:empty {
  padding: 0;
}
.js-error {
  color: darkred;
}
/* raw_input styles */
div.raw_input_container {
  line-height: 1.21429em;
  padding-top: 5px;
}
pre.raw_input_prompt {
  /* nothing needed here. */
}
input.raw_input {
  font-family: monospace;
  font-size: inherit;
  color: inherit;
  width: auto;
  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;
  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0em 0.25em;
  margin: 0em 0.25em;
}
input.raw_input:focus {
  box-shadow: none;
}
p.p-space {
  margin-bottom: 10px;
}
div.output_unrecognized {
  padding: 5px;
  font-weight: bold;
  color: red;
}
div.output_unrecognized a {
  color: inherit;
  text-decoration: none;
}
div.output_unrecognized a:hover {
  color: inherit;
  text-decoration: none;
}
.rendered_html {
  color: #000;
  /* any extras will just be numbers: */
}



.rendered_html :link {
  text-decoration: underline;
}
.rendered_html :visited {
  text-decoration: underline;
}






.rendered_html h1:first-child {
  margin-top: 0.538em;
}
.rendered_html h2:first-child {
  margin-top: 0.636em;
}
.rendered_html h3:first-child {
  margin-top: 0.777em;
}
.rendered_html h4:first-child {
  margin-top: 1em;
}
.rendered_html h5:first-child {
  margin-top: 1em;
}
.rendered_html h6:first-child {
  margin-top: 1em;
}








.rendered_html * + ul {
  margin-top: 1em;
}
.rendered_html * + ol {
  margin-top: 1em;
}


.rendered_html pre,



.rendered_html tr,
.rendered_html th,

.rendered_html td,


.rendered_html * + table {
  margin-top: 1em;
}

.rendered_html * + p {
  margin-top: 1em;
}

.rendered_html * + img {
  margin-top: 1em;
}
.rendered_html img,

.rendered_html img.unconfined,

div.text_cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.text_cell &gt; div.prompt {
    display: none;
  }
}
div.text_cell_render {
  /*font-family: "Helvetica Neue", Arial, Helvetica, Geneva, sans-serif;*/
  outline: none;
  resize: none;
  width: inherit;
  border-style: none;
  padding: 0.5em 0.5em 0.5em 0.4em;
  color: #000;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
a.anchor-link:link {
  text-decoration: none;
  padding: 0px 20px;
  visibility: hidden;
}
h1:hover .anchor-link,
h2:hover .anchor-link,
h3:hover .anchor-link,
h4:hover .anchor-link,
h5:hover .anchor-link,
h6:hover .anchor-link {
  visibility: visible;
}
.text_cell.rendered .input_area {
  display: none;
}
.text_cell.rendered 
.text_cell.unrendered .text_cell_render {
  display: none;
}
.cm-header-1,
.cm-header-2,
.cm-header-3,
.cm-header-4,
.cm-header-5,
.cm-header-6 {
  font-weight: bold;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
}
.cm-header-1 {
  font-size: 185.7%;
}
.cm-header-2 {
  font-size: 157.1%;
}
.cm-header-3 {
  font-size: 128.6%;
}
.cm-header-4 {
  font-size: 110%;
}
.cm-header-5 {
  font-size: 100%;
  font-style: italic;
}
.cm-header-6 {
  font-size: 100%;
  font-style: italic;
}
&lt;/style&gt;
&lt;style type="text/css"&gt;.highlight .hll { background-color: #ffffcc }
.highlight  { background: #f8f8f8; }
.highlight .c { color: #408080; font-style: italic } /* Comment */
.highlight .err { border: 1px solid #FF0000 } /* Error */
.highlight .k { color: #008000; font-weight: bold } /* Keyword */
.highlight .o { color: #666666 } /* Operator */
.highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */
.highlight .cp { color: #BC7A00 } /* Comment.Preproc */
.highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */
.highlight .cs { color: #408080; font-style: italic } /* Comment.Special */
.highlight .gd { color: #A00000 } /* Generic.Deleted */
.highlight .ge { font-style: italic } /* Generic.Emph */
.highlight .gr { color: #FF0000 } /* Generic.Error */
.highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.highlight .gi { color: #00A000 } /* Generic.Inserted */
.highlight .go { color: #888888 } /* Generic.Output */
.highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.highlight .gs { font-weight: bold } /* Generic.Strong */
.highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.highlight .gt { color: #0044DD } /* Generic.Traceback */
.highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: #008000 } /* Keyword.Pseudo */
.highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: #B00040 } /* Keyword.Type */
.highlight .m { color: #666666 } /* Literal.Number */
.highlight .s { color: #BA2121 } /* Literal.String */
.highlight .na { color: #7D9029 } /* Name.Attribute */
.highlight .nb { color: #008000 } /* Name.Builtin */
.highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.highlight .no { color: #880000 } /* Name.Constant */
.highlight .nd { color: #AA22FF } /* Name.Decorator */
.highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */
.highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
.highlight .nf { color: #0000FF } /* Name.Function */
.highlight .nl { color: #A0A000 } /* Name.Label */
.highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */
.highlight .nv { color: #19177C } /* Name.Variable */
.highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.highlight .w { color: #bbbbbb } /* Text.Whitespace */
.highlight .mb { color: #666666 } /* Literal.Number.Bin */
.highlight .mf { color: #666666 } /* Literal.Number.Float */
.highlight .mh { color: #666666 } /* Literal.Number.Hex */
.highlight .mi { color: #666666 } /* Literal.Number.Integer */
.highlight .mo { color: #666666 } /* Literal.Number.Oct */
.highlight .sb { color: #BA2121 } /* Literal.String.Backtick */
.highlight .sc { color: #BA2121 } /* Literal.String.Char */
.highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.highlight .s2 { color: #BA2121 } /* Literal.String.Double */
.highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
.highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */
.highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
.highlight .sx { color: #008000 } /* Literal.String.Other */
.highlight .sr { color: #BB6688 } /* Literal.String.Regex */
.highlight .s1 { color: #BA2121 } /* Literal.String.Single */
.highlight .ss { color: #19177C } /* Literal.String.Symbol */
.highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */
.highlight .vc { color: #19177C } /* Name.Variable.Class */
.highlight .vg { color: #19177C } /* Name.Variable.Global */
.highlight .vi { color: #19177C } /* Name.Variable.Instance */
.highlight .il { color: #666666 } /* Literal.Number.Integer.Long */&lt;/style&gt;
&lt;style type="text/css"&gt;
/* Temporary definitions which will become obsolete with Notebook release 5.0 */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-bold { font-weight: bold; }
&lt;/style&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h1 id="Reinforcement-Learning"&gt;Reinforcement Learning&lt;a class="anchor-link" href="#Reinforcement-Learning"&gt;¶&lt;/a&gt;&lt;/h1&gt;&lt;h3 id="Part-1---Action-Value-Methods-and-n-armed-bandit-problems"&gt;Part 1 - Action-Value Methods and &lt;em&gt;n&lt;/em&gt;-armed bandit problems&lt;a class="anchor-link" href="#Part-1---Action-Value-Methods-and-n-armed-bandit-problems"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h5 id="Introduction"&gt;Introduction&lt;a class="anchor-link" href="#Introduction"&gt;¶&lt;/a&gt;&lt;/h5&gt;&lt;p&gt;I'm going to begin a multipart series of posts on Reinforcement Learning (RL) that roughly follow an old 1996 textbook "Reinforcement Learning An Introduction" by Sutton and Barto. From my research, this text still seems to be the most thorough introduction to RL I could find. The Barto &amp; Sutton text is itself a great read and is fairly approachable even for beginners, but I still think it's worth breaking down even further. It still amazes me how most of machine learning theory was established decades ago yet we've seen a huge explosion of interest and use in just the past several years largely due to dramatic improvements in computational power (i.e. GPUs) and the availibility of massive data sets ("big data").  The first implementations of neural networks date back to the early 1950s!&lt;/p&gt;
&lt;p&gt;While really neat results have been achieved using supervised learning models (e.g. Google's DeepDream), many consider reinforcement learning to be the holy grail of machine learning. If we can build a general learning algorithm that can learn patterns and make predictions with unlabeled data, that would be a game-changer. Google DeepMind's Deep Q-learning algorithm that learned to play dozens of old Atari games with just the raw pixel data and the score is a big step in the right direction. Clearly, there is much to be done. The algorithm still struggles with long timespan rewards (i.e. taking actions that don't result in reward for a relatively long period of time), which is why it failed to learn how to play Montezuma's Revenge and similar games. Q-learning is something that was first described in 1989, and while DeepMind's specific implementation had some novelties, it's largely the same algorithm from way back then.&lt;/p&gt;
&lt;p&gt;In this series, I will be covering major topics and algorithms in RL mostly from the Barto &amp; Sutton text, but I will also include more recent advances and material where appropriate. My goal (as with all my posts) is to help those with limited mathematical backgrounds to grasp the concepts and be able to translate the equations into code (I'll use Python here). As a heads-up, the code presented here will (hopefully) maximize for readability and understandability often at the expense of computational efficiency and quality. I.e. my code will not be production-quality and is just for enhanced learning. My only assumumptions for this series is that you're proficient with Python and Numpy and have at least some basic knowledge of linear algebra and statistics/probability.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="n-armed-bandit-problem"&gt;&lt;em&gt;n&lt;/em&gt;-armed bandit problem&lt;a class="anchor-link" href="#n-armed-bandit-problem"&gt;¶&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;We're going to build our way up from very simple RL algorithms to much more sophisticated ones that could be used to learn to play games, for example. The theory and math builds on each preceding part, so I strongly recommend you follow this series in order even though the first parts are less exciting.&lt;/p&gt;
&lt;p&gt;Let's consider a hypothetical problem where we're at a casino and in a section with some slot machines. Let's say we're at a section with 10 slot machines in a row and it says "Play for free! Max payout is \$10!" Wow, not bad right! Let's say we ask one of the employees what's going on here, it seems too good to be true, and she says "It's really true, play as much as you want, it's free. Each slot machine is gauranteed to give you a reward between 0 and \$10. Oh, by the way, keep this on the down low but those 10 slot machines each have a different average payout, so try to figure out which one gives out the most rewards on average and you'll be making tons of cash!"&lt;/p&gt;
&lt;p&gt;What kind of casino is this?! Who knows, but it's awesome. Oh by the way, here's a joke: What's another name for a slot machine? .... A one-armed bandit! Get it? It's got one arm (a lever) and it generally steals your money! Huh, well I guess we could call our situation a 10-armed bandit problem, or an &lt;em&gt;n&lt;/em&gt;-armed bandit problem more generally, where &lt;em&gt;n&lt;/em&gt; is the number of slot machines.&lt;/p&gt;
&lt;p&gt;Let me restate our problem more formally. We have &lt;em&gt;n&lt;/em&gt; possible actions (here &lt;em&gt;n&lt;/em&gt; = 10) and at each play (&lt;em&gt;k&lt;/em&gt;) of this "game" we can choose a single lever to pull. After taking an action $a$ we will receive a reward $R_k$ (reward at play &lt;em&gt;k&lt;/em&gt;). Each lever has a unique probability distribution of payouts (rewards). For example, if we have 10 slot machines, slot machine #3 may give out an average reward of \$9 whereas slot machine \#1 only gives out an average reward of \$4. Of course, since the reward at each play is probabilistic, it is possible that lever #1 will by chance give us a reward of \$9 on a single play. But if we play many games, we expect on average slot machine #1 is associated with a lower reward than #3.&lt;/p&gt;
&lt;p&gt;Thus in words, our strategy should be to play a few times, choosing different levers and observing our rewards for each action. Then we want to only choose the lever with the largest observed average reward. Thus we need a concept of &lt;em&gt;expected&lt;/em&gt; reward for taking an action $a$ based on our previous plays, we'll call this expected reward $Q_k(a)$ mathematically. $Q_k(a)$ is a function that accepts action $a$ and returns the expected reward for that action. Formally,
$$Q_k(a) = \frac{R_1  +  R_2  +  {...}  +  R_k}{k_a}$$
That is, the expected reward at play &lt;em&gt;k&lt;/em&gt; for action $a$ is the &lt;em&gt;arithmetic mean&lt;/em&gt; of all the previous rewards we've received for taking action &lt;em&gt;a&lt;/em&gt;. Thus our previous actions and observations influence our future actions, we might even say some of our previous actions &lt;em&gt;reinforce&lt;/em&gt; our current and future actions. We'll come back to this later.&lt;/p&gt;
&lt;p&gt;Some keywords for this problem are exploration and exploitation. Our strategy needs to include some amount of exploitation (simply choosing the best lever based on what we know so far) and some amount of exploration (choosing random levers so we can learn more). The proper balance of exploitation and exploration will be important to maximizing our rewards.&lt;/p&gt;
&lt;p&gt;So how can we come up with an algorithm to figure out which slot machine has the largest average payout? Well, the simplest algorithm would be to select action $a$ for which this equation is true:
$$Q_k(A_k) = max_a(Q_k(a))$$
This equation/rule states that the expected reward for the current play &lt;em&gt;k&lt;/em&gt; for taking action $A$ is equal to the maximum average reward of all previous actions taken. In other words, we use our above reward function $Q_k(a)$ on all the possible actions and select the one that returns the maximum average reward. Since $Q_k(a)$ depends on a record of our previous actions and their associated rewards, this method will not select actions that we haven't already explored. Thus we might have previously tried lever 1 and lever 3, and noticed that lever 3 gives us a higher reward, but with this method, we'll never think to try another lever, say #6, which, unbeknownst to us, actually gives out the highest average reward. This method of simply choosing the best lever that we know of so far is called a "greedy" method.&lt;/p&gt;
&lt;p&gt;Obviously, we need to have some exploration of other levers (slot machines) going on to discover the true best action. One simple modification to our above algorithm is to change it to an $\epsilon$ (epsilon)-greedy algorithm, such that, with a probability $\epsilon$, we will choose an action $a$ at random, and the rest of the time (probability $1-\epsilon$) we will choose the best lever based on what we currently know from past plays. So most of the time we play greedy, but sometimes we take some risks and choose a random lever and see what happens. This will of course influence our future greedy actions.&lt;/p&gt;
&lt;p&gt;Alright, I think that's an in-depth enough discussion of the problem and how we want to try to solve it with a rudimentary RL algorithm. Let's start implementing this with Python.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In [579]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;#imports, nothing to see here&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;scipy&lt;/span&gt; &lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="n"&gt;stats&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;random&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plt&lt;/span&gt;
&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="k"&gt;matplotlib&lt;/span&gt; inline
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In [595]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;
&lt;span class="n"&gt;arms&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rand&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;eps&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.1&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Per our casino example, we will be solving a 10-armed bandit problem, hence &lt;em&gt;n&lt;/em&gt; = 10. I've also defined a numpy array of length &lt;em&gt;n&lt;/em&gt; filled with random floats that can be understood as probabilities. The way I've chosen to implement our reward probability distributions for each arm/lever/slot machine is this: Each arm will have a probability, e.g. 0.7. The maximum reward is \$10. We will setup a for loop to 10 and at each step, it will add +1 to the reward if a random float is less than the arm's probability. Thus on the first loop, it makes up a random float (e.g. 0.4). 0.4 is less than 0.7, so reward += 1. On the next iteration, it makes up another random float (e.g. 0.6) which is also less than 0.7, thus reward += 1. This continues until we complete 10 iterations and then we return the final total reward, which could be anything 0 to 10. With an arm probability of 0.7, the &lt;em&gt;average&lt;/em&gt; reward of doing this to infinity would be 7, but on any single play, it could be more or less.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In [590]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;reward&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;prob&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;reward&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;&lt;&lt;/span&gt; &lt;span class="n"&gt;prob&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;reward&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;reward&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;The next function we define is our greedy strategy of choosing the best arm so far. This function will accept a memory array that stores in a key-value sort of way the history of all actions and their rewards. It is a $2\ x\ k$ matrix where each row is an index reference to our arms array (1st element) and the reward received (2nd element). For example, if a row in our memory array is [2, 8] it means that action 2 was taken (the 3rd element in our arms array) and we received a reward of 8 for taking that action.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In [596]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;#initialize memory array; has 1 row defaulted to random action index&lt;/span&gt;
&lt;span class="n"&gt;av&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;randint&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,(&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;#av = action-value&lt;/span&gt;

&lt;span class="c1"&gt;#greedy method to select best arm based on memory array (historical results)&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;bestArm&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;bestArm&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="c1"&gt;#just default to 0&lt;/span&gt;
    &lt;span class="n"&gt;bestMean&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;u&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;avg&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;where&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;u&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])][:,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="c1"&gt;#calc mean reward for each action&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;bestMean&lt;/span&gt; &lt;span class="o"&gt;&lt;&lt;/span&gt; &lt;span class="n"&gt;avg&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;bestMean&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;avg&lt;/span&gt;
            &lt;span class="n"&gt;bestArm&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;u&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;bestArm&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;And here is the main loop for each play. I've set it to play 500 times and display a matplotlib scatter plot of the mean reward against plays. Hopefully we'll see that the mean reward increases as we play more times.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In [597]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xlabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Plays"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ylabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Avg Reward"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;500&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;&gt;&lt;/span&gt; &lt;span class="n"&gt;eps&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="c1"&gt;#greedy arm selection&lt;/span&gt;
        &lt;span class="n"&gt;choice&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;bestArm&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;av&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;thisAV&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([[&lt;/span&gt;&lt;span class="n"&gt;choice&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;reward&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;arms&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;choice&lt;/span&gt;&lt;span class="p"&gt;])]])&lt;/span&gt;
        &lt;span class="n"&gt;av&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;concatenate&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;av&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;thisAV&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="c1"&gt;#random arm selection&lt;/span&gt;
        &lt;span class="n"&gt;choice&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;where&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;arms&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;choice&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;arms&lt;/span&gt;&lt;span class="p"&gt;))[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="n"&gt;thisAV&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([[&lt;/span&gt;&lt;span class="n"&gt;choice&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;reward&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;arms&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;choice&lt;/span&gt;&lt;span class="p"&gt;])]])&lt;/span&gt; &lt;span class="c1"&gt;#choice, reward &lt;/span&gt;
        &lt;span class="n"&gt;av&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;concatenate&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;av&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;thisAV&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;#add to our action-value memory array&lt;/span&gt;
    &lt;span class="c1"&gt;#calculate the percentage the correct arm is chosen (you can plot this instead of reward)&lt;/span&gt;
    &lt;span class="n"&gt;percCorrect&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;av&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;where&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;av&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argmax&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;arms&lt;/span&gt;&lt;span class="p"&gt;))])&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;av&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="c1"&gt;#calculate the mean reward&lt;/span&gt;
    &lt;span class="n"&gt;runningMean&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;av&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;scatter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;runningMean&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;&lt;div class="prompt"&gt;&lt;/div&gt;
&lt;div class="output_png output_subarea "&gt;
&lt;img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAYMAAAEPCAYAAACgFqixAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"&gt;
&lt;/img&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;As you can see, the average reward does indeed improve after many plays. Our algorithm is &lt;em&gt;learning&lt;/em&gt;, it is getting reinforced by previous good plays! And yet it is such a simple algorithm.&lt;/p&gt;
&lt;p&gt;I encourage you to download this notebook (scroll to bottom) and experiment with different numbers of arms and different values for $\epsilon$.&lt;/p&gt;
&lt;p&gt;The problem we've considered here is a &lt;em&gt;stationary&lt;/em&gt; problem because the underlying reward probability distributions for each arm do not change over time. We certainly could consider a variant of this problem where this is not true, a non-stationary problem. In this case, a simple modification would be to weight more recent action-value pairs greater than distant ones, thus if things change over time, we will be able to track them. Beyond this brief mention, we will not implement this slightly more complex variant here.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h4 id="Incremental-Update"&gt;Incremental Update&lt;a class="anchor-link" href="#Incremental-Update"&gt;¶&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;In our implementation we stored each action-value (action-reward) pair in a numpy array that just kept growing after each play. As you might imagine, this is not a good use of memory or computational power. Although my goal here is not to concern myself with computational efficiency, I think it's worth making our implementation more efficient in this case as it turns out to be actually simpler.&lt;/p&gt;
&lt;p&gt;Instead of storing each action-value pair, we will simply keep a running tab of the &lt;em&gt;mean&lt;/em&gt; reward for each action. Thus we reduce our memory array from virtually unlimited in size (as plays increase indefinitely) to a hard-limit of a 1-dimensional array of length &lt;em&gt;n&lt;/em&gt; (n = # arms/levers). The index of each element corresponds to an action (e.g. 1st element corresponds to lever #1) and the value of each element is the running average of that action.&lt;/p&gt;
&lt;p&gt;Then whenever we take a new action and receive a new reward, we can simply update our running average using this equation:
$$Q_{k+1} = Q_k + \frac{1}{k}[R_k - Q_k]$$
where $Q_k$ is the running average reward for action $a$ so far and $R_k$ is the reward we received right now for taking action $A_k$, and $k$ is the number of plays so far.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In [720]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;
&lt;span class="n"&gt;arms&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rand&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;eps&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.1&lt;/span&gt;

&lt;span class="n"&gt;av&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ones&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;#initialize action-value array&lt;/span&gt;
&lt;span class="n"&gt;counts&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;#stores counts of how many times we've taken a particular action&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;reward&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;prob&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;total&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;&lt;&lt;/span&gt; &lt;span class="n"&gt;prob&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;total&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;total&lt;/span&gt;

&lt;span class="c1"&gt;#our bestArm function is much simpler now&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;bestArm&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argmax&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;#returns index of element with greatest value&lt;/span&gt;
    
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xlabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Plays"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ylabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Mean Reward"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;500&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;&gt;&lt;/span&gt; &lt;span class="n"&gt;eps&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;choice&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;bestArm&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;av&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;counts&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;choice&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
        &lt;span class="n"&gt;k&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;counts&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;choice&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="n"&gt;rwd&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;  &lt;span class="n"&gt;reward&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;arms&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;choice&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
        &lt;span class="n"&gt;old_avg&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;av&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;choice&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="n"&gt;new_avg&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;old_avg&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;rwd&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;old_avg&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;#update running avg&lt;/span&gt;
        &lt;span class="n"&gt;av&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;choice&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;new_avg&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;choice&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;where&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;arms&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;choice&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;arms&lt;/span&gt;&lt;span class="p"&gt;))[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="c1"&gt;#randomly choose an arm (returns index)&lt;/span&gt;
        &lt;span class="n"&gt;counts&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;choice&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
        &lt;span class="n"&gt;k&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;counts&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;choice&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="n"&gt;rwd&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;  &lt;span class="n"&gt;reward&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;arms&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;choice&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
        &lt;span class="n"&gt;old_avg&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;av&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;choice&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="n"&gt;new_avg&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;old_avg&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;rwd&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;old_avg&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;#update running avg&lt;/span&gt;
        &lt;span class="n"&gt;av&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;choice&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;new_avg&lt;/span&gt;
    &lt;span class="c1"&gt;#have to use np.average and supply the weights to get a weighted average&lt;/span&gt;
    &lt;span class="n"&gt;runningMean&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;average&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;av&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;counts&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;counts&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;j&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;counts&lt;/span&gt;&lt;span class="p"&gt;))]))&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;scatter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;runningMean&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;&lt;div class="prompt"&gt;&lt;/div&gt;
&lt;div class="output_png output_subarea "&gt;
&lt;img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAYMAAAEPCAYAAACgFqixAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"&gt;
&lt;/img&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;This method achieves the same result, getting us better and better rewards over time as it learns which lever is the best option. I had to create a separate array &lt;code&gt;counts&lt;/code&gt; to keep track of how many times each action is taken to properly recalculate the running reward averages for each action. Importantly, this implementation is simpler and more memory/computationally efficient.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Softmax-Action-Selection"&gt;Softmax Action Selection&lt;a class="anchor-link" href="#Softmax-Action-Selection"&gt;¶&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Imagine another type of bandit problem: A newly minted doctor specializes in treating patients with heart attacks. She has 10 treatment options of which she can choose only one to treat each patient she sees. For some reason, all she knows is that these 10 treatments have different efficacies and risk-profiles for treating heart attacks, and she doesn't know which one is the best yet. We could still use our same $\epsilon$-greedy algorithm from above, however, we might want to reconsider our $\epsilon$ policy of completely randomly choosing a treatment once in awhile. In this new problem, randomly choosing a treatment could result in patient death, not just losing some money. So we really want to make sure to not choose the worst treatment but still have some ability to explore our options to find the best one.&lt;/p&gt;
&lt;p&gt;This is where a softmax selection might be the most appropriate. Instead of just choosing an action at random during exploration, softmax gives us a probability distribution across our options. The option with the largest probability would be equivalent to our best arm action from above, but then we have some idea about what are the 2nd and 3rd best actions for example. This way, we can randomly choose to explore other options while avoiding the very worst options. Here's the softmax equation:&lt;/p&gt;
&lt;p&gt;&lt;div style="font-size:20px;"&gt;
$$\frac{e^{Q_k(a)/\tau}}{\sum_{i=1}^n{e^{Q_k(i)/\tau}}}$$
&lt;/div&gt;
$\tau$ is a parameter called temperature the scales the probability distribution of actions. A high temperature will tend the probabilities to be very simmilar, whereas a low temperature will exaggerate differences in probabilities between actions. Selecting this parameter requires an educated guess and some trial and error.&lt;/p&gt;
&lt;p&gt;When we implement the slot machine 10-armed bandit problem from above using softmax, we don't need our &lt;code&gt;bestArm()&lt;/code&gt; function anymore. Since softmax produces a weighted probability distribution across our possible actions, we will just randomly (but weighted) select actions according to their relative probabilities. That is, our best action will get chosen more often because it will have the highest softmax probability, but other actions will be chosen at random at lesser frequency.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In [781]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;
&lt;span class="n"&gt;arms&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rand&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;av&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ones&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;#initialize action-value array, stores running reward mean&lt;/span&gt;
&lt;span class="n"&gt;counts&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;#stores counts of how many times we've taken a particular action&lt;/span&gt;
&lt;span class="c1"&gt;#stores our softmax-generated probability ranks for each action&lt;/span&gt;
&lt;span class="n"&gt;av_softmax&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;av_softmax&lt;/span&gt;&lt;span class="p"&gt;[:]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.1&lt;/span&gt; &lt;span class="c1"&gt;#initialize each action to have equal probability&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;reward&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;prob&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;total&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;&lt;&lt;/span&gt; &lt;span class="n"&gt;prob&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;total&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;total&lt;/span&gt;

&lt;span class="n"&gt;tau&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;1.12&lt;/span&gt; &lt;span class="c1"&gt;#tau was selected by trial and error&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;softmax&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;av&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;probs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;softm&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;av&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;tau&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;av&lt;/span&gt;&lt;span class="p"&gt;[:]&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;tau&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;probs&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;softm&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;probs&lt;/span&gt;

&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xlabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Plays"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ylabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Mean Reward"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;500&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="c1"&gt;#select random arm using weighted probability distribution&lt;/span&gt;
    &lt;span class="n"&gt;choice&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;where&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;arms&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;choice&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;arms&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;av_softmax&lt;/span&gt;&lt;span class="p"&gt;))[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;counts&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;choice&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
    &lt;span class="n"&gt;k&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;counts&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;choice&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;rwd&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;  &lt;span class="n"&gt;reward&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;arms&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;choice&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="n"&gt;old_avg&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;av&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;choice&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;new_avg&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;old_avg&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;rwd&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;old_avg&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;av&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;choice&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;new_avg&lt;/span&gt;
    &lt;span class="n"&gt;av_softmax&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;softmax&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;av&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;#update softmax probabilities for next play&lt;/span&gt;
        
    &lt;span class="n"&gt;runningMean&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;average&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;av&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;counts&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;counts&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;j&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;counts&lt;/span&gt;&lt;span class="p"&gt;))]))&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;scatter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;runningMean&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;&lt;div class="prompt"&gt;&lt;/div&gt;
&lt;div class="output_png output_subarea "&gt;
&lt;img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAYMAAAEPCAYAAACgFqixAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"&gt;
&lt;/img&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Softmax action selection seems to do at least as well as epsilon-greedy, perhaps even better; it looks like it converges on an optimal policy faster. The downside to softmax is having to manually select the $\tau$ parameter. Softmax here was pretty sensitive to $\tau$ and it took awhile of playing with it to find a good value for it. Obviously with epsilon-greedy we had the parameter epsilon to set, but choosing that parameter was much more intuitive.&lt;/p&gt;
&lt;h3 id="Conclusion"&gt;Conclusion&lt;a class="anchor-link" href="#Conclusion"&gt;¶&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Well that concludes Part 1 of this series. While the &lt;em&gt;n&lt;/em&gt;-armed bandit problem is not all that interesting, I think it does lay a good foundation for more sophisticated problems and algorithms.&lt;/p&gt;
&lt;p&gt;Stay tuned for part 2 where I'll cover finite Markov decision processes and some associated algorithms.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Download-this-IPython-Notebook"&gt;Download this IPython Notebook&lt;a class="anchor-link" href="#Download-this-IPython-Notebook"&gt;¶&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;&lt;a href="https://github.com/outlace/outlace.github.io/notebooks/rlpart1.ipynb"&gt;https://github.com/outlace/outlace.github.io/notebooks/rlpart1.ipynb&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="References:"&gt;References:&lt;a class="anchor-link" href="#References:"&gt;¶&lt;/a&gt;&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;"Reinforcement Learning: An Introduction" Andrew Barto and Richard S. Sutton, 1996&lt;/li&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Artificial_neural_network#History"&gt;https://en.wikipedia.org/wiki/Artificial_neural_network#History&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Q-learning"&gt;https://en.wikipedia.org/wiki/Q-learning&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: 'center'," +
        "    displayIndent: '0em'," +
        "    showMathMenu: true," +
        "    tex2jax: { " +
        "        inlineMath: [ ['$','$'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        " linebreaks: { automatic: true, width: '95% container' }, " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }" +
        "    } " +
        "}); ";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;
</content><category term="RL"></category><category term="bandit"></category></entry></feed>